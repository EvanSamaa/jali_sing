{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICED = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW', \"ER\"])\n",
    "CMU2VISEME = {\"AA\":\"Ah\", \"AO\":\"Ah\", \"AY\":\"Ah\", \"AW\":\"Ah\",\"AE\":\"Aa\",\n",
    "              \"EY\":\"Aa\",\"UH\":\"Uh\", \"UW\":\"U\",\"IH\": \"Ih\",\"IY\": \"Ih\",\"EH\": \"Eh\",\"HH\": \"Eh\",\"UH\": \"Eh\",\"AH\": \"Eh\",\n",
    "              \"ER\": \"Eh\",\"OW\":\"Oo\",\"OY\":\"Oh\",\"R\":\"R\",\"D\":\"LNTD\",\"T\": \"LNTD\",\"L\":\"LNTD\",\"N\":\"LNTD\",\"NG\":\"LNTD\",\n",
    "              \"F\":\"FV\",\"V\":\"FV\",\"B\":\"BP\",\"M\":\"M\",\"P\":\"BP\",\"CH\":\"ShChZh\",\"SH\":\"ShChZh\",\"ZH\":\"ShChZh\",\n",
    "              \"S\": \"SZ\", \"Z\": \"SZ\",\"DH\":\"Th\", \"TH\":\"Th\",\"G\":\"GK\", \"K\":\"GK\",\"Y\":\"Y\",\"JH\":\"J\",\"W\":\"W\",}\n",
    "VOWELS_SLIDERS_JALI = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\"])\n",
    "CONSONANTS_SLIDERS_JALI = set([\"M_pointer\", \"BP_pointer\", \"JY_pointer\", \"Th_pointer\", \"ShChZh_pointer\", \"SZ_pointer\", \"GK_pointer\", \"LNTD_pointer\", \"R_pointer\", \"W_pointer\", \"FV_pointer\"])\n",
    "CONSONANTS_SLIDERS_NOJAW_JALI = set([\"Ya_pointer\", \"Ja_pointer\", \"Ra_pointer\", \"FVa_pointer\", \"LNTDa_pointer\", \"Ma_pointer\", \"BPa_pointer\", \"Wa_pointer\", \"Tha_pointer\", \"GKa_pointer\"])\n",
    "JALI_SLIDERS_SET = set.union(VOWELS_SLIDERS_JALI, CONSONANTS_SLIDERS_JALI, CONSONANTS_SLIDERS_NOJAW_JALI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMU_phonemes_dicts():\n",
    "    def __init__(self):\n",
    "        self.vocabs = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G',\n",
    "                  'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH',\n",
    "                  'UW', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "        self.vowels = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', \n",
    "                  'IH', 'IY', 'OW', 'OY', 'UH', 'UW', ])\n",
    "        self.voiced = set(['M', 'N']).union(self.vowels)\n",
    "        self.consonants = set(['B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L', 'M', 'N', 'NG', \n",
    "                              'P', 'R', 'S', 'SH', 'T', 'TH', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "        self.consonants_no_jaw = self.consonants\n",
    "        self.lip_closer = set([\"B\", \"F\", \"M\", \"P\", \"S\", \"V\"])\n",
    "        self.lip_rounder = set([\"B\", \"F\", \"M\", \"P\", \"V\"])\n",
    "        self.nasal_obtruents = set(['L', 'N', 'NG', 'T', 'D', 'G', 'K', 'F', 'V', 'M', 'B', 'P'])\n",
    "        self.fricative = set([\"S\", \"Z\", \"ZH\", \"SH\", \"CH\", \"F\", \"V\", 'TH'])\n",
    "        self.plosive = set([\"P\", \"B\", \"D\", \"T\", \"K\", \"G\"])\n",
    "        self.lip_heavy = set([\"W\", \"OW\", \"UW\", \"S\", \"Z\", \"Y\", \"JH\", \"OY\"])\n",
    "        self.sibilant = set([\"S\", \"Z\", \"SH\", \"CH\", \"ZH\"])\n",
    "class JALI_visemes_dicts():\n",
    "     def __init__(self):\n",
    "        self.vowels = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\"])\n",
    "        self.voiced = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\", \"LNTD_pointer\", \"LNTDa_pointer\"])\n",
    "        self.consonants_no_jaw = set([\"Ya_pointer\", \"Ja_pointer\", \"Ra_pointer\", \"FVa_pointer\", \"LNTDa_pointer\", \"Ma_pointer\", \"BPa_pointer\", \"Wa_pointer\", \"Tha_pointer\", \"GKa_pointer\"])\n",
    "        self.consonants = set([\"M_pointer\", \"BP_pointer\", \"JY_pointer\", \"Th_pointer\", \"ShChZh_pointer\", \"SZ_pointer\", \"GK_pointer\", \"LNTD_pointer\", \"R_pointer\", \"W_pointer\", \"FV_pointer\"]) \n",
    "        self.lip_closer = set([\"M_pointer\", \"BP_pointer\", \"FV_pointer\", \"SZ_pointer\"])\n",
    "        self.lip_rounder = set([\"M_pointer\", \"BP_pointer\", \"FV_pointer\"])\n",
    "        self.vocabs = self.consonants.union(self.vowels).union(self.consonants_no_jaw)\n",
    "        self.sibilant = set([\"SZ_pointer\", \"ShChZh_pointer\"])\n",
    "        self.nasal_obtruents = set([\"LNTD_pointer\", \"GK_pointer\", \"FV_pointer\", \"M_pointer\", \"BP_pointer\"])\n",
    "        self.fricative = set([\"FV_pointer\", \"SZ_pointer\", \"ShChZh_pointer\", \"Th_pointer\"])\n",
    "        self.plosive = set([\"BP_pointer\", \"LNTDa_pointer\", \"GK_pointer\"])\n",
    "        self.lip_heavy = set([\"Oh_pointer\", \"W_pointer\", \"Wa_pointer\", \"U_pointer\", \"SZ_pointer\", \"JY_pointer\",\n",
    "                             \"Ya_pointer\", \"Ja_pointer\"])\n",
    "        self.lip_rounder_to_no_jaw_dict = {\"M_pointer\":\"Ma_pointer\", \"BP_pointer\":\"BPa_pointer\", \"FV_pointer\":\"FVa_pointer\"}\n",
    "cmu_sets = CMU_phonemes_dicts()\n",
    "jali_sets = JALI_visemes_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_basic_viseme_curve(start, end, value, sustain=1, decay = 0.75, onset=0.1, offset=0):\n",
    "    if end - start < 0.1:\n",
    "        end = start + 0.1\n",
    "    interval = []\n",
    "    interval.append([start-onset, 0])\n",
    "    # second point is when the belting starts \n",
    "    interval.append([start, 1 * value])\n",
    "    # third point emphasizes decay, it happens 75% down the interval\n",
    "    if sustain < 1:\n",
    "        interval.append([start + sustain * (end - start), decay * value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    elif sustain == 1:\n",
    "        interval.append([end, value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    return interval\n",
    "def get_kth_neighbour(input_list, i, k):\n",
    "    if i+k < 0 or i+k >= len(input_list):\n",
    "        return None\n",
    "    return input_list[i+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.SongDataStructure import *\n",
    "from util.pitch_interval_estimation import *\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "PraatError",
     "evalue": "Cannot open file “E:\\MASC\\Structured_data\\rolling_in_the_deep_adele\\audio.wav”.\r\nSound not read from sound file “E:\\MASC\\Structured_data\\rolling_in_the_deep_adele\\audio.wav”.\r",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPraatError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EVANSA~1\\AppData\\Local\\Temp/ipykernel_11512/1149389850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"E:/MASC/Structured_data/rolling_in_the_deep_adele\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_name_template\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"audio\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n\u001b[0m\u001b[0;32m      5\u001b[0m                                                                                              os.path.join(dir, \"audio_full.TextGrid\"))\n",
      "\u001b[1;32m~\\Desktop\\jali_sing\\util\\SongDataStructure.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, audio_path_file, transcript_path, txt_grid_path, pitch_ceiling)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilence_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.007\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# obtain sound related data using Praat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msound_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m44100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msound_arr_interp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msound_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPraatError\u001b[0m: Cannot open file “E:\\MASC\\Structured_data\\rolling_in_the_deep_adele\\audio.wav”.\r\nSound not read from sound file “E:\\MASC\\Structured_data\\rolling_in_the_deep_adele\\audio.wav”.\r"
     ]
    }
   ],
   "source": [
    "# load file for Jali\n",
    "dir = \"E:/MASC/Structured_data/rolling_in_the_deep_adele\"\n",
    "file_name_template = \"audio\"\n",
    "lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n",
    "                                                                                             os.path.join(dir, \"audio_full.TextGrid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Structured_data/let_her_go\"\n",
    "file_name_template = \"vocal_audio_1\"\n",
    "lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n",
    "                                   os.path.join(dir, \"vocal_audio_1_full.TextGrid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Structured_data/my_way_frank_sinatra\"\n",
    "file_name_template = \"audio_1\"\n",
    "lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n",
    "                                   os.path.join(dir, \"audio_1__full.TextGrid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"C:/Users/evansamaa/Desktop/vowel_model_dataset\"\n",
    "file_name_template = \"A_I_A_I_A_I\"\n",
    "lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n",
    "                                   os.path.join(dir, \"A_I_A_I_A_I.TextGrid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "if len(sentences) == 0:\n",
    "    sentences = [list(range(0, len(lyric.phoneme_list)))]\n",
    "# sentence stores the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_list = lyric.phoneme_list\n",
    "phoneme_interval = lyric.phoneme_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>', 'AY', '>', 'AY', '>', 'AY', '>']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using tanh function to get a smooth curve\n",
    "def Viseme_A(peak=None, lowest=None):\n",
    "    if not peak is None:\n",
    "        total = np.log((1+peak)/(1-peak))/2\n",
    "        b = np.log((1+lowest)/(1-lowest))/2\n",
    "        a = total-b\n",
    "    else:\n",
    "        peak = 0.99\n",
    "        lowest = 0.6\n",
    "        total = np.log((1+peak)/(1-peak))/2\n",
    "        b = np.log((1+lowest)/(1-lowest))/2\n",
    "        a = total-b\n",
    "    def fn(val, val_max, val_min, max_val = 10):\n",
    "        val = (val - val_min) / (val_max - val_min)\n",
    "        print(val)\n",
    "#         return (lowest + val * ((peak - lowest)))*max_val\n",
    "        return np.tanh((val)*a+b) * max_val\n",
    "#         return (np.exp(val * 8)/np.exp(8) * (peak-lowest) + lowest) * max_val\n",
    "    return fn\n",
    "viseme_A = Viseme_A()\n",
    "# plt.plot(np.arange(0, 1, 0.01), viseme_A(np.arange(0, 1, 0.01), 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">\n",
      "AY\n",
      ">\n",
      "AY\n",
      ">\n",
      "AY\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "SIBLANT_JALI = set([\"SZ\", \"ShChZh\"])\n",
    "VOWELS_JALI = set(['Ih', 'Ee', 'Eh', 'Aa', 'U', 'Uh', 'Oo', 'Oh', 'Schwa', 'Eu', \"Ah\"])\n",
    "NASAL_OBSTRUENTS_JALI = set([\"LNTD\", \"GK\", \"FV\", \"M\", \"BP\"])\n",
    "\n",
    "# animate only vowels and see how it goes\n",
    "viseme_list = []\n",
    "viseme_intervals = []\n",
    "pure_phoneme_list = []\n",
    "max_activation = 8\n",
    "# threshold_slope = 200 # for formants\n",
    "threshold_slope = 80 # for pitch\n",
    "\n",
    "\n",
    "for i in range(0, len(phoneme_list)):\n",
    "    print(phoneme_list[i])\n",
    "    if phoneme_list[i] != \"EOS_tag\" and phoneme_list[i] != \">\":\n",
    "        onset = 0.12\n",
    "        offset = 0.12\n",
    "        if CMU2VISEME[phoneme_list[i]] in VOWELS_JALI or CMU2VISEME[phoneme_list[i]] in SIBLANT_JALI:\n",
    "            viseme_jali = CMU2VISEME[phoneme_list[i]] + \"_pointer\"\n",
    "        else :\n",
    "            if CMU2VISEME[phoneme_list[i]] in NASAL_OBSTRUENTS_JALI and phoneme_interval[i][1] - phoneme_interval[i][0] > 1/20:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[i]] + \"_pointer\"\n",
    "            else:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[i]] + \"a_pointer\"\n",
    "        if viseme_jali in jali_sets.lip_heavy:\n",
    "            onset = 0.16\n",
    "            offset = 0.16\n",
    "        start = phoneme_interval[i][0]\n",
    "        end = phoneme_interval[i][1]\n",
    "        if (end - start) <= 0.1:\n",
    "            value = 6\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        elif (end - start) <= 0.3:\n",
    "            value = 6\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        else:\n",
    "            value = 8\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        if phoneme_list[i] in cmu_sets.lip_closer:\n",
    "            value = 10\n",
    "        viseme_curve = generate_basic_viseme_curve(start, end, value, sustain=sustain, decay=decay, onset=onset, offset=offset)\n",
    "        viseme_list.append(viseme_jali)\n",
    "        pure_phoneme_list.append(phoneme_list[i])\n",
    "        viseme_intervals.append(viseme_curve)\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce co-articulation rules of consonants\n",
    "viseme_list_final = []\n",
    "viseme_intervals_final = []\n",
    "i = 0;\n",
    "\n",
    "while i < len(viseme_list):\n",
    "    increment = 1\n",
    "    i_next = min(i + 1, len(viseme_list)-1)\n",
    "    if (viseme_list[i_next] == viseme_list[i] and viseme_intervals[i][-1][0] >= viseme_intervals[i_next][0][0]):\n",
    "        # remove repeated vowels or consonants\n",
    "        viseme_list_final.append(viseme_list[i_next])\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], [int_curr[1][0], max(int_curr[1][1], int_next[1][1])], \n",
    "                           [int_next[2][0], max(int_curr[2][1], int_next[2][1])], int_next[3]]\n",
    "        viseme_intervals_final.append(viseme_interval)\n",
    "        if viseme_list[i_next] in jali_sets.lip_rounder:\n",
    "            viseme_list_final.append(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i_next]])\n",
    "            viseme_intervals_final.append(viseme_interval)\n",
    "        increment = 2\n",
    "    elif viseme_list[i] in jali_sets.lip_heavy:\n",
    "        # if the viseme is a lip-heavy viseme, the it is voice simutaneously as nearby labial dental and bilabials \n",
    "        current_interval = viseme_intervals[i] \n",
    "        if not get_kth_neighbour(viseme_list, i, -1) is None:\n",
    "            if current_interval[0][0] <= viseme_intervals[i-1][-1][0] - lyric.dt and viseme_intervals[i-1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[0][0] = viseme_intervals[i-1][0][0]\n",
    "                current_interval[1][0] = viseme_intervals[i-1][1][0]\n",
    "        if not get_kth_neighbour(viseme_list, i, +1) is None:\n",
    "            if current_interval[-1][0] <= viseme_intervals[i+1][0][0] - lyric.dt and viseme_intervals[i+1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[2][0] = viseme_intervals[i+1][0][0]\n",
    "                current_interval[3][0] = viseme_intervals[i+1][1][0]\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(current_interval)\n",
    "        if viseme_list[i] in jali_sets.lip_rounder:\n",
    "            viseme_list_final.append(jali_sets.lip_rounder_to_no_jaw_dict[viseme_list[i]])\n",
    "            viseme_intervals_final.append(current_interval)\n",
    "    else:\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(viseme_intervals[i])\n",
    "        if viseme_list[i] in jali_sets.lip_rounder:\n",
    "            viseme_list_final.append(jali_sets.lip_rounder_to_no_jaw_dict[viseme_list[i]])\n",
    "            viseme_intervals_final.append(viseme_intervals[i])\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 3\n",
    "# set this up\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(list(jali_sets.vocabs))):\n",
    "    prev_slider_dict[list(jali_sets.vocabs)[i]] = -1\n",
    "viseme_list_final_final = []\n",
    "viseme_intervals_final_final = []\n",
    "i = 0  \n",
    "while i < len(viseme_list_final):\n",
    "    increment = 1\n",
    "    prev_viseme = viseme_list_final[i]\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[viseme_list_final[i]] != -1:\n",
    "        current_interval = viseme_intervals_final[i]\n",
    "        prev_interval = viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]]\n",
    "        if (current_interval[1][0] >= prev_interval[2][0] and current_interval[0][0] <= prev_interval[3][0]):\n",
    "            interval = prev_interval[:-1] + current_interval[1:]\n",
    "            viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        elif (current_interval[1][0] <= prev_interval[2][0]):\n",
    "            interval = prev_interval[0:-2] + current_interval[1:]\n",
    "            viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        else:\n",
    "            viseme_list_final_final.append(viseme_list_final[i])\n",
    "            viseme_intervals_final_final.append(viseme_intervals_final[i])\n",
    "                \n",
    "    else:        \n",
    "        viseme_list_final_final.append(viseme_list_final[i])\n",
    "        viseme_intervals_final_final.append(viseme_intervals_final[i])\n",
    "        \n",
    "    prev_slider_dict[viseme_list_final[i]] = len(viseme_list_final_final) - 1\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric.compute_self_vibrato_intervals()\n",
    "vib_ctrl_pts = []\n",
    "for k in lyric.vibrato_intervals:\n",
    "    if len(k) > 0:\n",
    "        for m in k:\n",
    "            vib_ctrl_pts.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ah_pointer', 'Ah_pointer', 'Ah_pointer'], [[[-0.04454296135109409, 0], [0.0754570386489059, 8], [0.9172593342532398, 6.0], [1.3178600994546845, 0]], [[1.5561014036241034, 0], [1.6761014036241033, 8], [2.3056231203369095, 6.0], [2.6354636925745116, 0]], [[3.0884255822893834, 0], [3.2084255822893835, 8], [3.6622668199195463, 6.0], [3.9335472324629337, 0]]]]\n"
     ]
    }
   ],
   "source": [
    "print([viseme_list_final_final, viseme_intervals_final_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_10260/418142628.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\EVANSA~1\\AppData\\Local\\Temp/ipykernel_10260/418142628.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    \"jaw\":[[0, 6]],\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "output ={\"viseme\":[viseme_list_final_final, viseme_intervals_final_final],\n",
    "#         \"brow\":[brow_movement, brow_ctrl_points, finer_brow_raise_ctrl_points, finer_brow_furrow_ctrl_points],\n",
    "#         \"blink\":[eye_movement, eye_ctrl_points],\n",
    "        \"vowel_mod\": vowel_mod_arr\n",
    "        \"jaw\":[[0, 6]],\n",
    "        \"lip\":[[0, 6]], \n",
    "        \"vib\":vib_ctrl_pts}\n",
    "jsonoutput = json.dumps(output)\n",
    "with open(os.path.join(dir, file_name_template+'_raw_jali.json'), 'w') as outfile:\n",
    "    json.dump(jsonoutput, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visemenet",
   "language": "python",
   "name": "visemenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
