{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7936683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.sound_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4350a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from util.sound_processing import *\n",
    "VOWELS = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW', \"ER\", \"N\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625b4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Structured_data/rolling_in_the_deep2_adale\"\n",
    "file_name_template = \"audio_vocals\"\n",
    "lyric = PraatScript_Lyric_Wrapper(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"), \n",
    "                                  sentence_textgrids_path=[dir+\"/audio_vocals_fixed.TextGrid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bc2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Structured_data/rolling_in_the_deep_adele\"\n",
    "file_name_template = \"audio\"\n",
    "lyric = combine_lyric_alignment_textgrids(dir, file_name_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec16514",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric.compute_self_pitch_intervals()\n",
    "lyric.compute_self_vibrato_intervals()\n",
    "lyric.compute_self_singing_style_intervals()\n",
    "lyric.write_textgrid(dir, file_name_template+\"_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d95f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation_ctrl_pts(start, end, value, sustain=1, decay = 0.75, onset=0.1, offset=0):\n",
    "    interval = []\n",
    "    interval.append([start-onset, 0])\n",
    "    # second point is when the belting starts \n",
    "    interval.append([start, 1 * value])\n",
    "    # third point emphasizes decay, it happens 75% down the interval\n",
    "    if sustain < 1:\n",
    "        interval.append([start + sustain * (end - start), decay * value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    elif sustain == 1:\n",
    "        interval.append([end, value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df495f1",
   "metadata": {},
   "source": [
    "## 1. Compute Eye Brow Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36d7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "# sentence stores the indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b5e4b",
   "metadata": {},
   "source": [
    "## 1.b Compute Eye Brow Movements\n",
    "This will change the data format for saving, and use more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a600ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "# sentence stores the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141cae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is mostly for word level i.e. long vowels in a word. It would also be necessary to explore\n",
    "# sentence level expressions (possibly from studying another song)\n",
    "# this will have array of either 3 or 4 control points. \n",
    "# i.e. [[[ctrl_pt_1]...[ctrl_pt_k]], [[ctrl_pt_1]...[ctrl_pt_k]]] \n",
    "brow_movement = []\n",
    "brow_ctrl_points = []\n",
    "eye_movement = []\n",
    "eye_ctrl_points = []\n",
    "for i in range(0, len(sentences)):\n",
    "    sentence = sentences[i]\n",
    "    has_belt_pitch_interval_id = -1\n",
    "    has_belt_word_id = -1\n",
    "    has_head_pitch_interval_id = -1\n",
    "    has_head_word_id = -1\n",
    "    only_has_pitch_interval_id = -1\n",
    "    only_has_head_word_id = -1\n",
    "    \n",
    "    for phone_id in sentence:\n",
    "        phone = lyric.phoneme_list[phone_id]\n",
    "        voice_qualities = lyric.coarse_voice_quality_lists[phone_id]\n",
    "        voice_intervals = lyric.coarse_voice_quality_intervals[phone_id]\n",
    "        # look to see if there are any parts that has belting\n",
    "        for voice_quality_id in range(0, len(voice_qualities)):\n",
    "            if (voice_qualities[voice_quality_id] == \"belt\" and has_belt_word_id < 0 and \n",
    "                voice_intervals[voice_quality_id][1] -  voice_intervals[voice_quality_id][0] >= 0.4):\n",
    "                has_belt_word_id = phone_id\n",
    "                has_belt_pitch_interval_id = voice_quality_id\n",
    "            elif (voice_qualities[voice_quality_id] == \"head\" and has_belt_word_id >= 0 and has_head_word_id < 0 and \n",
    "                 voice_intervals[voice_quality_id][1] -  voice_intervals[voice_quality_id][0] >= 0.2):\n",
    "                has_head_word_id = phone_id\n",
    "                has_head_pitch_interval_id = voice_quality_id\n",
    "            if has_belt_word_id > 0 and has_head_word_id > 0:\n",
    "                break\n",
    "                \n",
    "    # do a second pass looking for brow raises\n",
    "    if has_belt_word_id < 0 and has_head_word_id < 0:\n",
    "        for phone_id in sentence:\n",
    "            phone = lyric.phoneme_list[phone_id]\n",
    "            pitch_change_interval = lyric.pitch_intervals[phone_id]\n",
    "            pitch_change_slopes = lyric.pitch_slopes[phone_id]\n",
    "            # look to see if there are any parts that has belting\n",
    "            for vi in range(0, len(pitch_change_slopes)):\n",
    "                if pitch_change_slopes[vi] >= 100 and only_has_head_word_id < 0:\n",
    "                    only_has_head_word_id = phone_id \n",
    "                    only_has_pitch_interval_id = vi\n",
    "                    break\n",
    "            if only_has_head_word_id >= 0:\n",
    "                break\n",
    "                \n",
    "    # this section of the code deal with having head voice only segments and the eye\n",
    "    # brow raising in those \n",
    "    if only_has_head_word_id > 0:\n",
    "        value = 5\n",
    "        onset = lyric.pitch_intervals[only_has_head_word_id][0][0]\n",
    "        start = lyric.pitch_intervals[only_has_head_word_id][only_has_pitch_interval_id][0] # where belting starts\n",
    "        onset = start - onset\n",
    "        end = lyric.pitch_intervals[only_has_head_word_id][-1][1]\n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, onset)\n",
    "        brow_movement.append(\"raise\")\n",
    "        brow_ctrl_points.append(interval)\n",
    "        \n",
    "    # this section of the code deal with belting and the related physiological points of the eyes\n",
    "    if has_belt_word_id > 0 and has_head_word_id > 0:\n",
    "        # deal with the furrowing related movements\n",
    "        value = 8\n",
    "        start = lyric.voice_quality_intervals[has_belt_word_id][has_belt_pitch_interval_id][0] # where belting starts\n",
    "        end = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][0] # where head voice starts i.e. end \n",
    "                                                                                             # end of belting   \n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, 0.1)\n",
    "        brow_movement.append(\"furrow\")\n",
    "        brow_ctrl_points.append(interval)\n",
    "        \n",
    "        # deal with the eyebrow raise related movements\n",
    "         \n",
    "        value = 5\n",
    "        start = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][0]\n",
    "        end = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][1]        \n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, 0.1)\n",
    "        brow_ctrl_points.append(interval)\n",
    "        brow_movement.append(\"raise\")\n",
    "        \n",
    "        # deal with eye openning and closing\n",
    "        value = 10\n",
    "        start = lyric.voice_quality_intervals[has_belt_word_id][has_belt_pitch_interval_id][0] # where belting starts\n",
    "        end = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][0] # where head voice starts i.e. end \n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 1, 0.1)\n",
    "        eye_movement.append(\"closure\")\n",
    "        eye_ctrl_points.append(interval)\n",
    "        \n",
    "    elif has_belt_word_id > 0 and has_head_word_id < 0:\n",
    "        # if there is belting, but sentence do not end with the use of head voice\n",
    "        value = 8\n",
    "        start = lyric.voice_quality_intervals[has_belt_word_id][has_belt_pitch_interval_id][0]\n",
    "        start = min(start - 0.1, lyric.voice_quality_intervals[has_belt_word_id][0][0]) \n",
    "        end = lyric.phoneme_intervals[sentence[-1]][1]-0.1\n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, 0.05)\n",
    "        brow_movement.append(\"furrow\")\n",
    "        brow_ctrl_points.append(interval)\n",
    "        \n",
    "        value = 10\n",
    "        end = lyric.phoneme_intervals[sentence[-1]][1]-0.1 # end of this sentence if there is no next sentence\n",
    "        if i < len(sentences)-1:\n",
    "            # the end will be the first word from the next sentence if there are more than one sentence\n",
    "            start_of_next_sentence = -1\n",
    "            next_sentence = sentences[i+1]\n",
    "            for phone_id in next_sentence:\n",
    "                if lyric.phoneme_list[phone_id] in VOWELS:\n",
    "                    start_of_next_sentence = phone_id\n",
    "                    break\n",
    "            end = lyric.phoneme_intervals[start_of_next_sentence][0]\n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 1, 1, 0.05, 0.1)\n",
    "        eye_movement.append(\"closure\")\n",
    "        eye_ctrl_points.append(interval)\n",
    "brow_movement.append(\"raise\")\n",
    "brow_movement.append(\"furrow\")\n",
    "brow_ctrl_points.append([[lyric.phoneme_intervals[-1][1], 0]])\n",
    "brow_ctrl_points.append([[lyric.phoneme_intervals[-1][1], 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ebbe9",
   "metadata": {},
   "source": [
    "### 1.c Compute additional Eye Brow Movements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fff475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brow_ctrl_pts(max_mean, mean_min, prev_freq, next_freq, mean_freq, time_range):\n",
    "    max_fluctuation = 1\n",
    "    rtv_raise = []\n",
    "    rtv_furrow = []\n",
    "    prev_freq_relative = prev_freq - mean_freq\n",
    "    next_freq_relative = next_freq - mean_freq\n",
    "    if prev_freq_relative < 0 and next_freq_relative < 0:\n",
    "        rtv_furrow.append([time_range[0], abs(max_fluctuation * prev_freq_relative/mean_min)])\n",
    "        rtv_furrow.append([time_range[1], abs(max_fluctuation * next_freq_relative/mean_min)])\n",
    "    elif prev_freq_relative > 0 and next_freq_relative > 0:\n",
    "        rtv_raise.append([time_range[0], max_fluctuation * prev_freq_relative/max_mean])\n",
    "        rtv_raise.append([time_range[1], max_fluctuation * next_freq_relative/max_mean])\n",
    "    elif prev_freq_relative >= 0 and next_freq_relative <= 0:\n",
    "        slope = (next_freq - prev_freq)/(time_range[1] - time_range[0])\n",
    "        time_to_zero_crossing = prev_freq_relative/(next_freq - prev_freq) * (time_range[1] - time_range[0])\n",
    "        rtv_raise.append([time_range[0], max_fluctuation * prev_freq_relative/max_mean])\n",
    "        rtv_raise.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_furrow.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_furrow.append([time_range[1], abs(max_fluctuation * next_freq_relative/mean_min)])\n",
    "    elif prev_freq_relative <= 0 and next_freq_relative <= 0:\n",
    "        slope = (next_freq - prev_freq)/(time_range[1] - time_range[0])\n",
    "        time_to_zero_crossing = prev_freq_relative/(next_freq - prev_freq) * (time_range[1] - time_range[0])\n",
    "        rtv_furrow.append([time_range[0], abs(max_fluctuation * prev_freq_relative/mean_min)])\n",
    "        rtv_furrow.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_raise.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_raise.append([time_range[1], max_fluctuation * next_freq_relative/max_mean])\n",
    "    return rtv_raise, rtv_furrow\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c927f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "finer_brow_raise_ctrl_points = [[0, 0]]\n",
    "finer_brow_furrow_ctrl_points = [[0, 0]]\n",
    "\n",
    "\n",
    "freq = lyric.pitch.selected_array[\"frequency\"]\n",
    "xs = lyric.xs\n",
    "freq[freq == 0] = np.nan\n",
    "mask = np.isnan(freq)\n",
    "freq[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), freq[~mask])\n",
    "freq = savgol_filter(freq, 61, 1)\n",
    "f = interp1d(xs, freq, kind=\"linear\")\n",
    "for sentence in sentences:\n",
    "    all_pitch_intervals_slope = []\n",
    "    all_pitch_intervals_time = []\n",
    "    si = [lyric.phoneme_intervals[sentence[0]][0],\n",
    "          lyric.phoneme_intervals[sentence[-1]][1]]\n",
    "    fs = f(np.arange(si[0], min(si[1], xs[-1]), 0.01))\n",
    "    max_fs = fs.max()\n",
    "    min_fs = fs.min()\n",
    "    mean_fs = (max_fs * 0.7 + min_fs * 0.3)\n",
    "    # the starting point is always at \n",
    "    starting_freq = fs[0]\n",
    "                \n",
    "    for phone in sentence:\n",
    "        if len(lyric.pitch_slopes[phone]) == 0:\n",
    "            pitch_interval_time = lyric.phoneme_intervals[phone]\n",
    "            prev_freq = f(min(pitch_interval_time[0], xs[-1]))\n",
    "            next_freq = f(min(pitch_interval_time[1], xs[-1]))\n",
    "            raise_ctrl_pts_i, furrow_ctrl_pts_i = get_brow_ctrl_pts(max_fs-mean_fs, \n",
    "            mean_fs-min_fs, prev_freq, next_freq, mean_fs, pitch_interval_time)\n",
    "            finer_brow_raise_ctrl_points.extend(raise_ctrl_pts_i)\n",
    "            finer_brow_furrow_ctrl_points.extend(furrow_ctrl_pts_i)\n",
    "            \n",
    "        else:\n",
    "            for i in range(0, len(lyric.pitch_slopes[phone])):\n",
    "                pitch_interval_time = lyric.pitch_intervals[phone][i]\n",
    "                prev_freq = f(min(pitch_interval_time[0], xs[-1]))\n",
    "                next_freq = f(min(pitch_interval_time[1], xs[-1]))\n",
    "                raise_ctrl_pts_i, furrow_ctrl_pts_i = get_brow_ctrl_pts(max_fs-mean_fs, \n",
    "                mean_fs-min_fs, prev_freq, next_freq, mean_fs, pitch_interval_time)\n",
    "                finer_brow_raise_ctrl_points.extend(raise_ctrl_pts_i)\n",
    "                finer_brow_furrow_ctrl_points.extend(furrow_ctrl_pts_i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04829e",
   "metadata": {},
   "source": [
    "## 2. Bootleg Jali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ed0220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.CMU2JALI import *\n",
    "CMU_VOCABULARY = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G',\n",
    "                  'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH',\n",
    "                  'UW', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "LIP_HEAVY_VISEMES_JALI = set([\"Oh_pointer\", \"W_pointer\", \"U_pointer\", \"SZ_pointer\", \"JY_pointer\"])\n",
    "NASAL_OBSTRUENTS_JALI = set([\"LNTD_pointer\", \"GK_pointer\", \"FV_pointer\", \"MBP_pointer\", ])\n",
    "LABIAL_AND_DENTAL_JALI = set([\"MBP_pointer\", \"SZ_pointer\", \"FV_pointer\", \"W_pointer\"])\n",
    "LABIAL_AND_DENTAL = set([\"M\", \"BP\", \"FV\"])\n",
    "LABIAL_AND_DENTAL_NO_JAW_JALI = set([\"MBPa_pointer\", \"SZa_pointer\", \"FVa_pointer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5fc6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_list = lyric.phoneme_list\n",
    "phoneme_interval = lyric.phoneme_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91fa8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kth_neighbour(input_list, i, k):\n",
    "    if i+k < 0 or i+k >= len(input_list):\n",
    "        return None\n",
    "    return input_list[i+k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815b36a",
   "metadata": {},
   "source": [
    "### 2.0.b Bootleg Jali Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03079b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMU2VISEME = {\"AA\":\"Ah\",\n",
    "                    \"AO\":\"Ah\",\n",
    "                    \"AY\":\"Ah\",\n",
    "                    \"AW\":\"Ah\",\n",
    "\n",
    "                    \"AE\":\"Aa\",\n",
    "                    \"EY\":\"Ah\",\n",
    "\n",
    "                    \"UH\":\"Uh\",\n",
    "\n",
    "                    \"UW\":\"U\",\n",
    "\n",
    "                    \"IH\": \"Ih\",\n",
    "                    \"IY\": \"Ih\",\n",
    "\n",
    "                    \"EH\": \"Eh\",\n",
    "                    \"HH\": \"Eh\",\n",
    "                    \"UH\": \"Eh\",\n",
    "                    \"AH\": \"Eh\",\n",
    "                    \"ER\": \"Eh\",\n",
    "\n",
    "                    \"OW\":\"Oh\",\n",
    "                    \"OY\":\"Oh\",\n",
    "\n",
    "                    \"R\":\"R\",\n",
    "\n",
    "                    \"D\":\"LNTD\",\n",
    "                    \"T\": \"LNTD\",\n",
    "                    \"L\":\"LNTD\",\n",
    "                    \"N\":\"LNTD\",\n",
    "                    \"NG\":\"LNTD\",\n",
    "\n",
    "                    \"F\":\"FV\",\n",
    "                    \"V\":\"FV\",\n",
    "\n",
    "                    \"B\":\"BP\",\n",
    "                    \"M\":\"M\",\n",
    "                    \"P\":\"BP\",\n",
    "\n",
    "                    \"CH\":\"ShChZh\",\n",
    "                    \"SH\":\"ShChZh\",\n",
    "                    \"ZH\":\"ShChZh\",\n",
    "\n",
    "                    \"S\": \"SZ\",\n",
    "                    \"Z\": \"SZ\",\n",
    "\n",
    "                    \"DH\":\"Th\",\n",
    "                    \"TH\":\"Th\",\n",
    "\n",
    "                    \"G\":\"GK\",\n",
    "                    \"K\":\"GK\",\n",
    "\n",
    "                    \"Y\":\"Y\",\n",
    "                    \"JH\":\"J\",\n",
    "\n",
    "                    \"W\":\"W\",\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e76f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMU_VOCABULARY = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G',\n",
    "                  'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH',\n",
    "                  'UW', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "LIP_CLOSERS_CMU = set([\"B\", \"F\", \"M\", \"P\", \"S\", \"V\"])\n",
    "VOWELS_JALI = set(['Ih', 'Ee', 'Eh', 'Aa', 'U', 'Uh', 'Oo', 'Oh', 'Schwa', 'Eu', \"Ah\"])\n",
    "VOWELS_SLIDERS_JALI = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\"])\n",
    "CONSONANTS_JALI = set([\"M_pointer\", \"BP_pointer\", \"JY_pointer\", \"Th_pointer\", \"ShChZh_pointer\", \"SZ_pointer\", \"GK_pointer\", \"LNTD_pointer\", \"R_pointer\", \"W_pointer\", \"FV_pointer\"])\n",
    "CONSONANTS_NOJAW_JALI = set([\"Ya_pointer\", \"Ja_pointer\", \"Ra_pointer\", \"FVa_pointer\", \"LNTDa_pointer\", \"Ma_pointer\", \"BPa_pointer\", \"Wa_pointer\", \"Tha_pointer\", \"GKa_pointer\"])\n",
    "JALI_SLIDERS_SET = set.union(VOWELS_SLIDERS_JALI, CONSONANTS_JALI, CONSONANTS_NOJAW_JALI)\n",
    "ALL_CONSONANTS_JALI = set.union(CONSONANTS_NOJAW_JALI, CONSONANTS_JALI)\n",
    "SIBLANT_CONSONANTS_JALI = set([\"SZ_pointer\", \"ShChZh_pointer\"])\n",
    "SIBLANT_JALI = set([\"SZ\", \"ShChZh\"])\n",
    "NASAL_OBSTRUENTS_JALI = set([\"LNTD\", \"GK\", \"FV\", \"M\", \"BP\"])\n",
    "LIP_ROUNDER_CONSONANT_JALI = set([\"M_pointer\", \"BP_pointer\", \"FV_pointer\"])\n",
    "LIP_ROUNDER_CONSONANT_JALI_DICT = {\"M_pointer\":\"Ma_pointer\", \"BP_pointer\":\"BPa_pointer\", \"FV_pointer\":\"FVa_pointer\"}\n",
    "LIP_HEAVY_VISEMES_JALI = set([\"Oh_pointer\", \"W_pointer\", \"Wa_pointer\", \"U_pointer\", \"SZ_pointer\", \"JY_pointer\",\n",
    "                             \"Ya_pointer\", \"Ja_pointer\"])\n",
    "SEMIVOWELS_CMU = set([\"HH\"])\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(list(JALI_SLIDERS_SET))):\n",
    "    prev_slider_dict[list(JALI_SLIDERS_SET)[i]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc9b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_list = lyric.phoneme_list\n",
    "phoneme_interval = lyric.phoneme_intervals\n",
    "def get_kth_neighbour(input_list, i, k):\n",
    "    if i+k < 0 or i+k >= len(input_list):\n",
    "        return None\n",
    "    return input_list[i+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b04c01a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viseme_list = []\n",
    "viseme_intervals = []\n",
    "phoneme_list_pure = []\n",
    "prev_vowel = \"Uh\"\n",
    "next_vowel = \"\"\n",
    "# pass 1\n",
    "for i in range(0, len(phoneme_list)):\n",
    "    if phoneme_list[i] in CMU_VOCABULARY:\n",
    "        onset = 0.12\n",
    "        offset = 0.12\n",
    "        if CMU2VISEME[phoneme_list[i]] in VOWELS_JALI or CMU2VISEME[phoneme_list[i]] in SIBLANT_JALI:\n",
    "            viseme_jali = CMU2VISEME[phoneme_list[i]] + \"_pointer\"\n",
    "        else :\n",
    "            if CMU2VISEME[phoneme_list[i]] in NASAL_OBSTRUENTS_JALI and phoneme_interval[i][1] - phoneme_interval[i][0] > 1/20:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[i]] + \"_pointer\"\n",
    "            else:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[i]] + \"a_pointer\"\n",
    "        if viseme_jali in LIP_HEAVY_VISEMES_JALI:\n",
    "            onset = 0.16\n",
    "            offset = 0.16\n",
    "        start = phoneme_interval[i][0]\n",
    "        end = phoneme_interval[i][1]\n",
    "        if (end - start) <= 0.1:\n",
    "            value = 6\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        elif (end - start) <= 0.3:\n",
    "            value = 6\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        else:\n",
    "            value = 8\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        if phoneme_list[i] in LIP_CLOSERS_CMU:\n",
    "            value = 10\n",
    "        viseme_curve = generate_animation_ctrl_pts(start, end, value, sustain=sustain, decay=decay, onset=onset, offset=offset)\n",
    "        viseme_list.append(viseme_jali)\n",
    "        phoneme_list_pure.append(phoneme_list[i])\n",
    "        viseme_intervals.append(viseme_curve)\n",
    "# pass 2 enforcing co-articulation\n",
    "viseme_list_final = []\n",
    "viseme_intervals_final = []\n",
    "i = 0;\n",
    "\n",
    "while i < len(viseme_list):\n",
    "    increment = 1\n",
    "    i_next = min(i + 1, len(viseme_list)-1)\n",
    "    if (viseme_list[i_next] == viseme_list[i]):\n",
    "        viseme_list_final.append(viseme_list[i_next])\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], [int_curr[1][0], max(int_curr[1][1], int_next[1][1])], \n",
    "                           [int_next[2][0], max(int_curr[2][1], int_next[2][1])], int_next[3]]\n",
    "        viseme_intervals_final.append(viseme_interval)\n",
    "        if viseme_list[i_next] in LIP_ROUNDER_CONSONANT_JALI:\n",
    "            viseme_list_final.append(LIP_ROUNDER_CONSONANT_JALI_DICT[viseme_list[i_next]])\n",
    "            viseme_intervals_final.append(viseme_interval)\n",
    "        increment = 2\n",
    "    elif phoneme_list_pure[i] in SEMIVOWELS_CMU and viseme_list[i_next].split(\"_\")[0] in VOWELS_JALI:\n",
    "        viseme_list_final.append(viseme_list[i_next])\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], [int_curr[1][0], max(int_curr[1][1], int_next[1][1])], \n",
    "                   [int_next[2][0], max(int_curr[2][1], int_next[2][1])], int_next[3]]\n",
    "        viseme_intervals_final.append(viseme_interval)\n",
    "        if viseme_list[i_next] in LIP_ROUNDER_CONSONANT_JALI:\n",
    "            viseme_list_final.append(LIP_ROUNDER_CONSONANT_JALI_DICT[viseme_list[i_next]])\n",
    "            viseme_intervals_final.append(viseme_interval)\n",
    "        increment = 2\n",
    "    elif viseme_list[i] in LIP_HEAVY_VISEMES_JALI:\n",
    "        current_interval = viseme_intervals[i] \n",
    "        if not get_kth_neighbour(viseme_list, i, -1) is None:\n",
    "            current_interval[0][0] = viseme_intervals[i-1][0][0]\n",
    "            current_interval[1][0] = viseme_intervals[i-1][1][0]\n",
    "        if not get_kth_neighbour(viseme_list, i, +1) is None:\n",
    "            current_interval[2][0] = viseme_intervals[i+1][0][0]\n",
    "            current_interval[3][0] = viseme_intervals[i+1][1][0]\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(current_interval)\n",
    "        if viseme_list[i] in LIP_ROUNDER_CONSONANT_JALI:\n",
    "            viseme_list_final.append(LIP_ROUNDER_CONSONANT_JALI_DICT[viseme_list[i]])\n",
    "            viseme_intervals_final.append(current_interval)\n",
    "    else:\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(viseme_intervals[i])\n",
    "        if viseme_list[i] in LIP_ROUNDER_CONSONANT_JALI:\n",
    "            viseme_list_final.append(LIP_ROUNDER_CONSONANT_JALI_DICT[viseme_list[i]])\n",
    "            viseme_intervals_final.append(viseme_intervals[i])\n",
    "    i = i + increment\n",
    "# pass 3\n",
    "# set this up\n",
    "for i in range(0, len(list(JALI_SLIDERS_SET))):\n",
    "    prev_slider_dict[list(JALI_SLIDERS_SET)[i]] = -1\n",
    "viseme_list_final_final = []\n",
    "viseme_intervals_final_final = []\n",
    "i = 0  \n",
    "while i < len(viseme_list_final):\n",
    "    increment = 1\n",
    "    prev_viseme = viseme_list_final[i]\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[viseme_list_final[i]] != -1:\n",
    "        current_interval = viseme_intervals_final[i]\n",
    "        prev_interval = viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]]\n",
    "        if (current_interval[1][0] >= prev_interval[2][0] and current_interval[0][0] <= prev_interval[3][0]):\n",
    "            interval = prev_interval[:-1] + current_interval[1:]\n",
    "            viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        elif (current_interval[1][0] <= prev_interval[2][0]):\n",
    "            interval = prev_interval[0:-2] + current_interval[1:]\n",
    "            viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        else:\n",
    "            viseme_list_final_final.append(viseme_list_final[i])\n",
    "            viseme_intervals_final_final.append(viseme_intervals_final[i])\n",
    "                \n",
    "    else:        \n",
    "        viseme_list_final_final.append(viseme_list_final[i])\n",
    "        viseme_intervals_final_final.append(viseme_intervals_final[i])\n",
    "        \n",
    "    prev_slider_dict[viseme_list_final[i]] = len(viseme_list_final_final) - 1\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b66a0",
   "metadata": {},
   "source": [
    "### 2.1.a: Jali parameter version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c60569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jali_parameters\n",
    "DEFALT_JALI_VAL = 6\n",
    "\n",
    "jaw_ctrl_pts = []\n",
    "lip_ctrl_pts = []\n",
    "\n",
    "# get information on the frequency\n",
    "freq = lyric.pitch.selected_array[\"frequency\"]\n",
    "xs = lyric.xs\n",
    "freq[freq == 0] = np.nan\n",
    "mask = np.isnan(freq)\n",
    "freq[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), freq[~mask])\n",
    "freq = savgol_filter(freq, 21, 3)\n",
    "f = interp1d(xs, freq, kind=\"linear\")\n",
    "for sentence in sentences:\n",
    "    all_pitch_intervals_slope = []\n",
    "    all_pitch_intervals_time = []\n",
    "    si = [lyric.phoneme_intervals[sentence[0]][0],\n",
    "          lyric.phoneme_intervals[sentence[-1]][1]]\n",
    "    fs = f(np.arange(si[0], min(si[1], xs[-1]), 0.01))\n",
    "    max_fs = fs.max()\n",
    "    min_fs = fs.min()\n",
    "    # the starting point is always at \n",
    "    current_freq = fs[0]\n",
    "    jaw_ctrl_pt_0 = [lyric.phoneme_intervals[sentence[0]][0]-0.02, 6 + (current_freq-min_fs)/(max_fs-min_fs) * 4]\n",
    "    jaw_ctrl_pts.append(jaw_ctrl_pt_0)\n",
    "    lip_ctrl_pt_0 = [lyric.phoneme_intervals[sentence[0]][0]-0.02, 6 + (current_freq-min_fs)/(max_fs-min_fs) * 4]\n",
    "    lip_ctrl_pts.append(lip_ctrl_pt_0)\n",
    "    prev_voice_type = \"chest\"\n",
    "    for phone in sentence:\n",
    "        if len(lyric.pitch_slopes[phone]) == 0 and len(lyric.voice_quality_lists[phone]) > 0:\n",
    "            pitch_interval_time = lyric.phoneme_intervals[phone]\n",
    "            if lyric.voice_quality_lists[phone][0] == \"head\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = f(pitch_interval_time[0])\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[1])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], new_jaw_val])\n",
    "                if prev_voice_type == \"belt\":\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"head\"\n",
    "            elif lyric.voice_quality_lists[phone][0] == \"belt\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0])\n",
    "                new_lip_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], new_lip_val])\n",
    "                if prev_voice_type == \"head\":\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"belt\"\n",
    "        for i in range(0, len(lyric.pitch_slopes[phone])):\n",
    "            pitch_interval_time = lyric.pitch_intervals[phone][i]\n",
    "            if lyric.pitch_slopes[phone][i] > 0 and lyric.voice_quality_lists[phone][i] == \"head\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], new_jaw_val])\n",
    "                if prev_voice_type == \"belt\":\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"head\"\n",
    "            elif lyric.pitch_slopes[phone][i] > 0 and lyric.voice_quality_lists[phone][i] == \"belt\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_lip_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], new_lip_val])\n",
    "                if prev_voice_type == \"head\":\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"belt\"\n",
    "            elif lyric.pitch_slopes[phone][i] > 0 and lyric.voice_quality_lists[phone][i] == \"chest\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], new_jaw_val])\n",
    "                if prev_voice_type == \"belt\":\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "#                 if prev_voice_type == \"head\":\n",
    "#                     jaw_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "#                     jaw_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"chest\"\n",
    "            elif lyric.pitch_slopes[phone][i] < 0: # these are opportunities to bring \n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                new_lip_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], max(new_jaw_val, DEFALT_JALI_VAL)])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], max(new_lip_val, DEFALT_JALI_VAL)])\n",
    "                prev_voice_type = lyric.voice_quality_intervals[phone][i]\n",
    "            elif ((prev_voice_type == \"head\" and lyric.voice_quality_intervals[phone][i] == \"belt\") or \n",
    "                  (prev_voice_type == \"belt\" and lyric.voice_quality_intervals[phone][i] == \"head\")):\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], prev_jaw_val])\n",
    "                prev_voice_type = lyric.voice_quality_intervals[phone][i]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eda973",
   "metadata": {},
   "source": [
    "### 2.1.a: Jali parameter version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf6666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.SongDataStructure import Minimal_song_data_structure\n",
    "dir = \"E:/MASC/Structured_data/rolling_in_the_deep_adele\"\n",
    "file_name_template = \"audio\"\n",
    "min_lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), \n",
    "                                       os.path.join(dir, file_name_template+\".txt\"), \n",
    "                                       os.path.join(dir, \"audio_full.TextGrid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "213f5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value_stat():\n",
    "    def __init__(self, x : np.array, y : np.array):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mean = y.mean()\n",
    "        self.std = y.std()\n",
    "        self.min = y.min()\n",
    "        self.max = y.max()\n",
    "        q = np.nanpercentile(y, [2, 98])\n",
    "        self.min_2 = q[0]\n",
    "        self.max_98 = q[1]\n",
    "        \n",
    "    def plot(self):\n",
    "        plt.plot(self.x, np.ones(self.x.shape)*self.mean)\n",
    "        plt.plot(self.x, self.y)\n",
    "    def thresholding(self, threshold):\n",
    "        self.y[self.y <= threshold] = np.nan\n",
    "        mask = np.isnan(self.y) \n",
    "        self.y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), self.y[~mask])\n",
    "        self.y = savgol_filter(self.y, 21, 3)\n",
    "        self.y = interp1d(self.x, self.y, kind=\"linear\")(self.x)\n",
    "        \n",
    "        self.mean = self.y.mean()\n",
    "        self.std = self.y.std()\n",
    "        self.min = self.y.min()\n",
    "        self.max = self.y.max()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c201f6",
   "metadata": {},
   "source": [
    "## 2. Compute coarse intervals from fine ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176379df",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = lyric.voice_quality_intervals\n",
    "traits = lyric.voice_quality_lists\n",
    "def compute_coarse_intervals(traits, interval):\n",
    "    new_intervals = []\n",
    "    new_traits = []\n",
    "    for i in range(0, len(intervals)):\n",
    "        new_interval = []\n",
    "        new_trait = []\n",
    "        interval = intervals[i]\n",
    "        trait = traits[i]\n",
    "        if len(trait) > 1:\n",
    "            prev_trait = trait[0]\n",
    "            prev_index = 0\n",
    "            for k in range(1, len(trait)):\n",
    "                if trait[k] == prev_trait and k == len(trait)-1:\n",
    "                    new_trait.append(prev_trait)\n",
    "                    new_interval.append([interval[prev_index][0], interval[k][1]])\n",
    "                elif trait[k] == prev_trait:\n",
    "                    continue\n",
    "                elif trait[k] != prev_trait:\n",
    "                    new_trait.append(prev_trait)\n",
    "                    new_interval.append([interval[prev_index][0], interval[k-1][1]])\n",
    "                    prev_trait = trait[k]\n",
    "            new_traits.append(new_trait)\n",
    "            new_intervals.append(new_interval)\n",
    "        else:\n",
    "            new_traits.append(trait)\n",
    "            new_intervals.append(interval)\n",
    "    return new_traits, new_intervals\n",
    "new_traits, new_interval = compute_coarse_intervals(traits, intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adee2887",
   "metadata": {},
   "source": [
    "### Gather statistics from the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea77ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jali_parameters\n",
    "DEFALT_JALI_VAL = 5\n",
    "\n",
    "# get information on the frequency\n",
    "freq = min_lyric.pitch_arr\n",
    "intensity = min_lyric.intensity_arr\n",
    "xs = lyric.xs\n",
    "freq[freq == 0] = np.nan\n",
    "mask = np.isnan(freq) \n",
    "freq[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), freq[~mask])\n",
    "freq = savgol_filter(freq, 21, 3)\n",
    "f = interp1d(xs, freq, kind=\"linear\")\n",
    "\n",
    "xs = min_lyric.intensity.xs()\n",
    "intensity[intensity == 0] = np.nan\n",
    "mask = np.isnan(intensity)\n",
    "intensity[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), intensity[~mask])\n",
    "intensity = savgol_filter(intensity, 21, 3)\n",
    "I = interp1d(xs, intensity, kind=\"linear\")\n",
    "\n",
    "song_stat_f = Value_stat(min_lyric.pitch.xs(), freq)\n",
    "song_stat_I = Value_stat(min_lyric.intensity.xs(), intensity)\n",
    "sentence_stats_f = []\n",
    "sentence_stats_I = []\n",
    "\n",
    "max_min_f = 0\n",
    "max_min_I = 0\n",
    "for sentence in sentences: \n",
    "    # get the interval of the current sentence\n",
    "    s_interval = [lyric.phoneme_intervals[sentence[0]][0],\n",
    "          lyric.phoneme_intervals[sentence[-1]][1]]\n",
    "    s_xs = np.arange(s_interval[0], min(s_interval[1], min_lyric.intensity.xs()[-1]), 0.01)\n",
    "    s_intensity = I(s_xs)\n",
    "    s_freq = f(s_xs)\n",
    "    stat_i = Value_stat(s_xs, s_intensity)\n",
    "    stat_f = Value_stat(s_xs, s_freq)\n",
    "    max_min_I = max(stat_i.min_2, max_min_I)\n",
    "    max_min_f = max(stat_f.min_2, max_min_f)\n",
    "    sentence_stats_f.append(stat_f)\n",
    "    sentence_stats_I.append(stat_i)\n",
    "for s in sentence_stats_f:\n",
    "    s.thresholding(max_min_f)\n",
    "for s in sentence_stats_I:\n",
    "    s.thresholding(max_min_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2afb66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [0.0840625, 0.1000625]\n",
      "W [0.1000625, 0.1320625]\n",
      "IY [0.1320625, 0.2920625]\n",
      "> [0.2920625, 0.3240625]\n",
      "K [0.3240625, 0.38754073689673074]\n",
      "UH [0.38754073689673074, 0.7107276855215362]\n",
      "D [0.7107276855215362, 0.7384294239750909]\n",
      "AH [0.7384294239750909, 0.8538533341982357]\n",
      "V [0.8538533341982357, 0.890788985469642]\n",
      "> [0.890788985469642, 0.9184907239231968]\n",
      "HH [0.9184907239231968, 0.9692772444213805]\n",
      "AE [0.9692772444213805, 1.269379411001557]\n",
      "D [1.269379411001557, 1.3109320186818891]\n",
      "> [1.3109320186818891, 1.3386337571354439]\n",
      "IH [1.3386337571354439, 1.4309728853139596]\n",
      "T [1.4309728853139596, 1.4817594058121433]\n",
      "> [1.4817594058121433, 1.578715490399585]\n",
      "AO [1.578715490399585, 4.4689302023871305]\n",
      "L [4.4689302023871305, 4.6600624999999996]\n",
      "> [4.962125, 5.2021250000000006]\n",
      "R [5.2021250000000006, 5.261602145940463]\n",
      "OW [5.261602145940463, 5.566773278647922]\n",
      "L [5.566773278647922, 5.607163575623909]\n",
      "IH [5.607163575623909, 5.813602871278955]\n",
      "NG [5.813602871278955, 5.8809200329056]\n",
      "> [5.8809200329056, 5.907846897556258]\n",
      "IH [5.907846897556258, 6.078383707010427]\n",
      "N [6.078383707010427, 6.1367252470868525]\n",
      "> [6.1367252470868525, 6.1726277332877295]\n",
      "DH [6.1726277332877295, 6.213018030263717]\n",
      "AH [6.213018030263717, 6.334188921191679]\n",
      "> [6.334188921191679, 6.388042650492995]\n",
      "D [6.388042650492995, 6.464335433669859]\n",
      "IY [6.464335433669859, 9.349997762065389]\n",
      "P [9.349997762065389, 9.410125]\n",
      "> [9.64475, 9.82075]\n",
      "Y [9.82075, 9.90075]\n",
      "UW [9.90075, 10.07675]\n",
      "> [10.07675, 10.09275]\n",
      "HH [10.09275, 10.12475]\n",
      "AE [10.12475, 10.36475]\n",
      "D [10.36475, 10.38075]\n",
      "> [10.38075, 10.39675]\n",
      "M [10.39675, 10.46075]\n",
      "AY [10.46075, 10.66875]\n",
      "> [10.66875, 10.684750000000001]\n",
      "HH [10.684750000000001, 10.748750000000001]\n",
      "AA [10.748750000000001, 11.03675]\n",
      "R [11.03675, 11.06875]\n",
      "T [11.06875, 11.08475]\n",
      "> [11.08475, 11.11675]\n",
      "IH [11.11675, 11.229797662994763]\n",
      "N [11.229797662994763, 11.264828416167381]\n",
      "S [11.264828416167381, 11.35991188906449]\n",
      "AY [11.35991188906449, 12.94075]\n",
      "D [12.94075, 12.95675]\n",
      "> [12.95675, 12.97275]\n",
      "AH [12.97275, 13.001352894867198]\n",
      "V [13.001352894867198, 13.068618639930005]\n",
      "> [13.068618639930005, 13.085886849047911]\n",
      "Y [13.085886849047911, 13.21275]\n",
      "AO [13.21275, 13.45275]\n",
      "R [13.45275, 13.46875]\n",
      "> [13.46875, 13.48475]\n",
      "HH [13.48475, 13.56475]\n",
      "AE [13.56475, 14.252749999999999]\n",
      "N [14.252749999999999, 14.33275]\n",
      "D [14.33275, 14.36475]\n",
      "Z [14.36475, 14.60475]\n",
      "> [14.7415, 15.323080204141306]\n",
      "AH [15.323080204141306, 15.412767575864013]\n",
      "N [15.412767575864013, 15.429173802398655]\n",
      "D [15.429173802398655, 15.443392532062012]\n",
      "> [15.443392532062012, 15.454897969052224]\n",
      "Y [15.454897969052224, 15.566092359767891]\n",
      "UW [15.566092359767891, 15.813500000000001]\n",
      "> [15.813500000000001, 15.8295]\n",
      "P [15.8295, 15.9095]\n",
      "L [15.9095, 15.9415]\n",
      "EY [15.9415, 16.529777079303674]\n",
      "D [16.529777079303674, 16.61449661508704]\n",
      "> [16.61449661508704, 16.625086557059962]\n",
      "IH [16.625086557059962, 16.75746083172147]\n",
      "T [16.75746083172147, 16.805115570599614]\n",
      "> [16.805115570599614, 17.705260638297872]\n",
      "T [17.705260638297872, 17.747620406189554]\n",
      "UW [17.747620406189554, 18.028253868471953]\n",
      "> [18.028253868471953, 18.054728723404256]\n",
      "DH [18.054728723404256, 18.09708849129594]\n",
      "AH [18.09708849129594, 18.2935]\n",
      "> [18.2935, 18.3095]\n",
      "B [18.3095, 18.3575]\n",
      "IY [18.3575, 19.9735]\n",
      "T [19.9735, 19.9895]\n"
     ]
    }
   ],
   "source": [
    "jaw_ctrl_pts = []\n",
    "lip_ctrl_pts = []\n",
    "dimple_ctrl_pts = []\n",
    "for i in range(0, len(sentences)):\n",
    "    sentence = sentences[i]\n",
    "    all_pitch_intervals_slope = []\n",
    "    all_pitch_intervals_time = []\n",
    "    si = [lyric.phoneme_intervals[sentence[0]][0],\n",
    "          lyric.phoneme_intervals[sentence[-1]][1]]\n",
    "    # the starting point is always at \n",
    "    current_freq = fs[0]\n",
    "    jaw_ctrl_pt_0 = [lyric.phoneme_intervals[sentence[0]][0]-0.02, DEFALT_JALI_VAL]\n",
    "    jaw_ctrl_pts.append(jaw_ctrl_pt_0)\n",
    "    lip_ctrl_pt_0 = [lyric.phoneme_intervals[sentence[0]][0]-0.02, DEFALT_JALI_VAL]\n",
    "    lip_ctrl_pts.append(lip_ctrl_pt_0)\n",
    "    for phone in sentence:\n",
    "        interval_time = lyric.phoneme_intervals[phone]\n",
    "        print(lyric.phoneme_list[phone], interval_time)\n",
    "        xs_phone_freq = np.arange(interval_time[0], min(interval_time[1], lyric.xs[-1]), 0.01)\n",
    "        freq_phone = f(xs_phone_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6630c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vib_ctrl_pts = []\n",
    "for k in lyric.vibrato_intervals:\n",
    "    if len(k) > 0:\n",
    "        for m in k:\n",
    "            vib_ctrl_pts.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ea6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\"viseme\":[viseme_list_final_final, viseme_intervals_final_final],\n",
    "        \"brow\":[brow_movement, brow_ctrl_points, finer_brow_raise_ctrl_points, finer_brow_furrow_ctrl_points],\n",
    "        \"blink\":[eye_movement, eye_ctrl_points],\n",
    "        \"jaw\":jaw_ctrl_pts,\n",
    "        \"lip\":lip_ctrl_pts, \n",
    "        \"vib\":vib_ctrl_pts}\n",
    "jsonoutput = json.dumps(output)\n",
    "with open(os.path.join(dir, file_name_template+'_animation_data.json'), 'w') as outfile:\n",
    "    json.dump(jsonoutput, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d947d2",
   "metadata": {},
   "source": [
    "## 3. Simple head movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_shake(t_start, t_end, prev_motion_x, prev_motions_y):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "\n",
    "x_dir_head = []\n",
    "y_dir_head = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91582c",
   "metadata": {},
   "source": [
    "# Studying eye brow movements using facial landmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715952d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b50206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.facial_landmarking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac777b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_title = [\"video.mp4\"]\n",
    "video_path = [\"E:/facial_data_analysis_videos/1\"]\n",
    "extract_landmarks_media_pipe(video_title[0],\n",
    "                         video_path[0], save_annotated_video=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visemenet",
   "language": "python",
   "name": "visemenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
