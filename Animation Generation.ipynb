{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.sound_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "VOWELS = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW', \"ER\", \"N\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Structured_data/rolling_in_the_deep_adele\"\n",
    "file_name_template = \"audio\"\n",
    "lyric = combine_lyric_alignment_textgrids(dir, file_name_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric.compute_self_pitch_intervals()\n",
    "lyric.compute_self_vibrato_intervals()\n",
    "lyric.compute_self_singing_style_intervals()\n",
    "lyric.write_textgrid(dir, file_name_template+\"_new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation_ctrl_pts(start, end, value, sustain=1, decay = 0.75, onset=0.1, offset=0):\n",
    "    interval = []\n",
    "    interval.append([start-onset, 0])\n",
    "    # second point is when the belting starts \n",
    "    interval.append([start, 1 * value])\n",
    "    # third point emphasizes decay, it happens 75% down the interval\n",
    "    if sustain < 1:\n",
    "        interval.append([start + sustain * (end - start), decay * value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    elif sustain == 1:\n",
    "        interval.append([end, value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute coarse intervals from fine ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], ['head'], [], [], ['head'], [], ['belt'], [], [], [], ['head'], [], [], ['head'], [], [], ['belt'], [], [], [], [], ['belt'], [], ['head'], [], [], ['belt'], ['head'], [], [], ['head'], [], [], ['head'], [], [], [], [], ['head'], [], [], ['head'], [], [], [], ['head'], [], [], ['head'], [], [], [], ['head'], ['head'], [], ['belt'], [], [], ['head'], [], [], [], ['belt'], [], [], [], ['belt'], ['head'], [], [], [], [], ['head'], ['head'], [], [], [], ['belt'], [], [], [], ['head'], [], [], ['head'], [], [], [], ['head'], [], [], ['head'], [], [], ['head'], []]\n",
      "[[], [], [], ['head'], [], [], ['head'], [], ['belt'], [], [], [], ['head'], [], [], ['head'], [], [], ['belt', 'belt', 'belt', 'belt', 'belt', 'belt', 'belt', 'belt', 'belt'], [], [], [], [], ['belt'], [], ['head'], [], [], ['belt'], ['head'], [], [], ['head'], [], [], ['head', 'head', 'head', 'head', 'head', 'head', 'head', 'head', 'head', 'head'], [], [], [], [], ['head'], [], [], ['head'], [], [], [], ['head'], [], [], ['head'], [], [], [], ['head'], ['head'], [], ['belt', 'belt', 'belt', 'belt', 'belt'], [], [], ['head'], [], [], [], ['belt'], [], [], [], ['belt', 'belt', 'belt'], ['head'], [], [], [], [], ['head'], ['head'], [], [], [], ['belt'], [], [], [], ['head'], [], [], ['head'], [], [], [], ['head'], [], [], ['head'], [], [], ['head', 'head', 'head', 'head'], []]\n"
     ]
    }
   ],
   "source": [
    "intervals = lyric.voice_quality_intervals\n",
    "traits = lyric.voice_quality_lists\n",
    "def compute_coarse_intervals(traits, interval):\n",
    "    new_intervals = []\n",
    "    new_traits = []\n",
    "    for i in range(0, len(intervals)):\n",
    "        new_interval = []\n",
    "        new_trait = []\n",
    "        interval = intervals[i]\n",
    "        trait = traits[i]\n",
    "        if len(trait) > 1:\n",
    "            prev_trait = trait[0]\n",
    "            prev_index = 0\n",
    "            for k in range(1, len(trait)):\n",
    "                if trait[k] == prev_trait and k == len(trait)-1:\n",
    "                    new_trait.append(prev_trait)\n",
    "                    new_interval.append([interval[prev_index][0], interval[k][1]])\n",
    "                elif trait[k] == prev_trait:\n",
    "                    continue\n",
    "                elif trait[k] != prev_trait:\n",
    "                    new_trait.append(prev_trait)\n",
    "                    new_interval.append([interval[prev_index][0], interval[k-1][1]])\n",
    "                    prev_trait = trait[k]\n",
    "            new_traits.append(new_trait)\n",
    "            new_intervals.append(new_interval)\n",
    "        else:\n",
    "            new_traits.append(trait)\n",
    "            new_intervals.append(interval)\n",
    "    return new_traits, new_intervals\n",
    "new_traits, new_interval = compute_coarse_intervals(traits, intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute Eye Brow Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "# sentence stores the indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Compute Eye Brow Movements version 2\n",
    "This will change the data format for saving, and use more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36], [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]]\n"
     ]
    }
   ],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "# sentence stores the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is mostly for word level i.e. long vowels in a word. It would also be necessary to explore\n",
    "# sentence level expressions (possibly from studying another song)\n",
    "# this will have array of either 3 or 4 control points. \n",
    "# i.e. [[[ctrl_pt_1]...[ctrl_pt_k]], [[ctrl_pt_1]...[ctrl_pt_k]]] \n",
    "brow_movement = []\n",
    "brow_ctrl_points = []\n",
    "eye_movement = []\n",
    "eye_ctrl_points = []\n",
    "for i in range(0, len(sentences)):\n",
    "    sentence = sentences[i]\n",
    "    has_belt_pitch_interval_id = -1\n",
    "    has_belt_word_id = -1\n",
    "    has_head_pitch_interval_id = -1\n",
    "    has_head_word_id = -1\n",
    "    only_has_pitch_interval_id = -1\n",
    "    only_has_head_word_id = -1\n",
    "    \n",
    "    for phone_id in sentence:\n",
    "        phone = lyric.phoneme_list[phone_id]\n",
    "        voice_qualities = lyric.coarse_voice_quality_lists[phone_id]\n",
    "        voice_intervals = lyric.coarse_voice_quality_intervals[phone_id]\n",
    "        # look to see if there are any parts that has belting\n",
    "        for voice_quality_id in range(0, len(voice_qualities)):\n",
    "            if (voice_qualities[voice_quality_id] == \"belt\" and has_belt_word_id < 0 and \n",
    "                voice_intervals[voice_quality_id][1] -  voice_intervals[voice_quality_id][0] >= 0.4):\n",
    "                has_belt_word_id = phone_id\n",
    "                has_belt_pitch_interval_id = voice_quality_id\n",
    "            elif (voice_qualities[voice_quality_id] == \"head\" and has_belt_word_id >= 0 and has_head_word_id < 0 and \n",
    "                 voice_intervals[voice_quality_id][1] -  voice_intervals[voice_quality_id][0] >= 0.2):\n",
    "                has_head_word_id = phone_id\n",
    "                has_head_pitch_interval_id = voice_quality_id\n",
    "            if has_belt_word_id > 0 and has_head_word_id > 0:\n",
    "                break\n",
    "                \n",
    "    # do a second pass looking for brow raises\n",
    "    if has_belt_word_id < 0 and has_head_word_id < 0:\n",
    "        for phone_id in sentence:\n",
    "            phone = lyric.phoneme_list[phone_id]\n",
    "            pitch_change_interval = lyric.pitch_intervals[phone_id]\n",
    "            pitch_change_slopes = lyric.pitch_slopes[phone_id]\n",
    "            # look to see if there are any parts that has belting\n",
    "            for vi in range(0, len(pitch_change_slopes)):\n",
    "                if pitch_change_slopes[vi] >= 100 and only_has_head_word_id < 0:\n",
    "                    only_has_head_word_id = phone_id \n",
    "                    only_has_pitch_interval_id = vi\n",
    "                    break\n",
    "            if only_has_head_word_id >= 0:\n",
    "                break\n",
    "                \n",
    "    # this section of the code deal with having head voice only segments and the eye\n",
    "    # brow raising in those \n",
    "    if only_has_head_word_id > 0:\n",
    "        value = 5\n",
    "        onset = lyric.pitch_intervals[only_has_head_word_id][0][0]\n",
    "        start = lyric.pitch_intervals[only_has_head_word_id][only_has_pitch_interval_id][0] # where belting starts\n",
    "        onset = start - onset\n",
    "        end = lyric.pitch_intervals[only_has_head_word_id][-1][1]\n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, onset)\n",
    "        brow_movement.append(\"raise\")\n",
    "        brow_ctrl_points.append(interval)\n",
    "        \n",
    "    # this section of the code deal with belting and the related physiological points of the eyes\n",
    "    if has_belt_word_id > 0 and has_head_word_id > 0:\n",
    "        # deal with the furrowing related movements\n",
    "        value = 8\n",
    "        start = lyric.voice_quality_intervals[has_belt_word_id][has_belt_pitch_interval_id][0] # where belting starts\n",
    "        end = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][0] # where head voice starts i.e. end \n",
    "                                                                                             # end of belting   \n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, 0.1)\n",
    "        brow_movement.append(\"furrow\")\n",
    "        brow_ctrl_points.append(interval)\n",
    "        \n",
    "        # deal with the eyebrow raise related movements\n",
    "         \n",
    "        value = 5\n",
    "        start = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][0]\n",
    "        end = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][1]        \n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, 0.1)\n",
    "        brow_ctrl_points.append(interval)\n",
    "        brow_movement.append(\"raise\")\n",
    "        \n",
    "        # deal with eye openning and closing\n",
    "        value = 10\n",
    "        start = lyric.voice_quality_intervals[has_belt_word_id][has_belt_pitch_interval_id][0] # where belting starts\n",
    "        end = lyric.voice_quality_intervals[has_head_word_id][has_head_pitch_interval_id][0] # where head voice starts i.e. end \n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 1, 0.1)\n",
    "        eye_movement.append(\"closure\")\n",
    "        eye_ctrl_points.append(interval)\n",
    "        \n",
    "    elif has_belt_word_id > 0 and has_head_word_id < 0:\n",
    "        # if there is belting, but sentence do not end with the use of head voice\n",
    "        value = 8\n",
    "        start = lyric.voice_quality_intervals[has_belt_word_id][has_belt_pitch_interval_id][0]\n",
    "        start = min(start - 0.1, lyric.voice_quality_intervals[has_belt_word_id][0][0]) \n",
    "        end = lyric.phoneme_intervals[sentence[-1]][1]-0.1\n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 0.75, 0.05)\n",
    "        brow_movement.append(\"furrow\")\n",
    "        brow_ctrl_points.append(interval)\n",
    "        \n",
    "        value = 10\n",
    "        end = lyric.phoneme_intervals[sentence[-1]][1]-0.1 # end of this sentence if there is no next sentence\n",
    "        if i < len(sentences)-1:\n",
    "            # the end will be the first word from the next sentence if there are more than one sentence\n",
    "            start_of_next_sentence = -1\n",
    "            next_sentence = sentences[i+1]\n",
    "            for phone_id in next_sentence:\n",
    "                if lyric.phoneme_list[phone_id] in VOWELS:\n",
    "                    start_of_next_sentence = phone_id\n",
    "                    break\n",
    "            end = lyric.phoneme_intervals[start_of_next_sentence][0]\n",
    "        interval = generate_animation_ctrl_pts(start, end, value, 1, 1, 0.05, 0.1)\n",
    "        eye_movement.append(\"closure\")\n",
    "        eye_ctrl_points.append(interval)\n",
    "brow_movement.append(\"raise\")\n",
    "brow_movement.append(\"furrow\")\n",
    "brow_ctrl_points.append([[lyric.phoneme_intervals[-1][1], 0]])\n",
    "brow_ctrl_points.append([[lyric.phoneme_intervals[-1][1], 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Compute additional Eye Brow Movements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brow_ctrl_pts(max_mean, mean_min, prev_freq, next_freq, mean_freq, time_range):\n",
    "    max_fluctuation = 1\n",
    "    rtv_raise = []\n",
    "    rtv_furrow = []\n",
    "    prev_freq_relative = prev_freq - mean_freq\n",
    "    next_freq_relative = next_freq - mean_freq\n",
    "    if prev_freq_relative < 0 and next_freq_relative < 0:\n",
    "        rtv_furrow.append([time_range[0], abs(max_fluctuation * prev_freq_relative/mean_min)])\n",
    "        rtv_furrow.append([time_range[1], abs(max_fluctuation * next_freq_relative/mean_min)])\n",
    "    elif prev_freq_relative > 0 and next_freq_relative > 0:\n",
    "        rtv_raise.append([time_range[0], max_fluctuation * prev_freq_relative/max_mean])\n",
    "        rtv_raise.append([time_range[1], max_fluctuation * next_freq_relative/max_mean])\n",
    "    elif prev_freq_relative >= 0 and next_freq_relative <= 0:\n",
    "        slope = (next_freq - prev_freq)/(time_range[1] - time_range[0])\n",
    "        time_to_zero_crossing = prev_freq_relative/(next_freq - prev_freq) * (time_range[1] - time_range[0])\n",
    "        rtv_raise.append([time_range[0], max_fluctuation * prev_freq_relative/max_mean])\n",
    "        rtv_raise.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_furrow.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_furrow.append([time_range[1], abs(max_fluctuation * next_freq_relative/mean_min)])\n",
    "    elif prev_freq_relative <= 0 and next_freq_relative <= 0:\n",
    "        slope = (next_freq - prev_freq)/(time_range[1] - time_range[0])\n",
    "        time_to_zero_crossing = prev_freq_relative/(next_freq - prev_freq) * (time_range[1] - time_range[0])\n",
    "        rtv_furrow.append([time_range[0], abs(max_fluctuation * prev_freq_relative/mean_min)])\n",
    "        rtv_furrow.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_raise.append([time_range[0] + time_to_zero_crossing, 0])\n",
    "        rtv_raise.append([time_range[1], max_fluctuation * next_freq_relative/max_mean])\n",
    "    return rtv_raise, rtv_furrow\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "finer_brow_raise_ctrl_points = [[0, 0]]\n",
    "finer_brow_furrow_ctrl_points = [[0, 0]]\n",
    "\n",
    "\n",
    "freq = lyric.pitch.selected_array[\"frequency\"]\n",
    "xs = lyric.xs\n",
    "freq[freq == 0] = np.nan\n",
    "mask = np.isnan(freq)\n",
    "freq[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), freq[~mask])\n",
    "freq = savgol_filter(freq, 61, 1)\n",
    "f = interp1d(xs, freq, kind=\"linear\")\n",
    "for sentence in sentences:\n",
    "    all_pitch_intervals_slope = []\n",
    "    all_pitch_intervals_time = []\n",
    "    si = [lyric.phoneme_intervals[sentence[0]][0],\n",
    "          lyric.phoneme_intervals[sentence[-1]][1]]\n",
    "    fs = f(np.arange(si[0], min(si[1], xs[-1]), 0.01))\n",
    "    max_fs = fs.max()\n",
    "    min_fs = fs.min()\n",
    "    mean_fs = (max_fs * 0.7 + min_fs * 0.3)\n",
    "    # the starting point is always at \n",
    "    starting_freq = fs[0]\n",
    "                \n",
    "    for phone in sentence:\n",
    "        if len(lyric.pitch_slopes[phone]) == 0:\n",
    "            pitch_interval_time = lyric.phoneme_intervals[phone]\n",
    "            prev_freq = f(min(pitch_interval_time[0], xs[-1]))\n",
    "            next_freq = f(min(pitch_interval_time[1], xs[-1]))\n",
    "            raise_ctrl_pts_i, furrow_ctrl_pts_i = get_brow_ctrl_pts(max_fs-mean_fs, \n",
    "            mean_fs-min_fs, prev_freq, next_freq, mean_fs, pitch_interval_time)\n",
    "            finer_brow_raise_ctrl_points.extend(raise_ctrl_pts_i)\n",
    "            finer_brow_furrow_ctrl_points.extend(furrow_ctrl_pts_i)\n",
    "            \n",
    "        else:\n",
    "            for i in range(0, len(lyric.pitch_slopes[phone])):\n",
    "                pitch_interval_time = lyric.pitch_intervals[phone][i]\n",
    "                prev_freq = f(min(pitch_interval_time[0], xs[-1]))\n",
    "                next_freq = f(min(pitch_interval_time[1], xs[-1]))\n",
    "                raise_ctrl_pts_i, furrow_ctrl_pts_i = get_brow_ctrl_pts(max_fs-mean_fs, \n",
    "                mean_fs-min_fs, prev_freq, next_freq, mean_fs, pitch_interval_time)\n",
    "                finer_brow_raise_ctrl_points.extend(raise_ctrl_pts_i)\n",
    "                finer_brow_furrow_ctrl_points.extend(furrow_ctrl_pts_i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\"viseme\":[viseme_list, viseme_intervals],\n",
    "        \"brow\":[brow_movement, brow_ctrl_points, finer_brow_raise_ctrl_points, finer_brow_furrow_ctrl_points],\n",
    "        \"blink\":[eye_movement, eye_ctrl_points],\n",
    "        \"jaw\":jaw_ctrl_pts,\n",
    "        \"lip\":lip_ctrl_pts, \n",
    "        \"vib\":vib_ctrl_pts}\n",
    "jsonoutput = json.dumps(output)\n",
    "with open(os.path.join(dir, file_name_template+'_animation_data.json'), 'w') as outfile:\n",
    "    json.dump(jsonoutput, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bootleg Jali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.CMU2JALI import *\n",
    "CMU_VOCABULARY = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G',\n",
    "                  'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH',\n",
    "                  'UW', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "LIP_HEAVY_VISEMES_JALI = set([\"Oh_pointer\", \"W_pointer\", \"U_pointer\", \"SZ_pointer\", \"JY_pointer\"])\n",
    "NASAL_OBSTRUENTS_JALI = set([\"LNTD_pointer\", \"GK_pointer\", \"FV_pointer\", \"MBP_pointer\", ])\n",
    "LABIAL_AND_DENTAL_JALI = set([\"MBP_pointer\", \"SZ_pointer\", \"FV_pointer\"])\n",
    "SEMIVOWELS_CMU = set([\"Y\", \"W\", \"H\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_list = lyric.phoneme_list\n",
    "phoneme_interval = lyric.phoneme_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kth_neighbour(input_list, i, k):\n",
    "    if i+k < 0 or i+k >= len(input_list):\n",
    "        return None\n",
    "    return input_list[i+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "viseme_list = []\n",
    "viseme_intervals = []\n",
    "phoneme_list_pure = []\n",
    "prev_vowel = \"Uh\"\n",
    "next_vowel = \"\"\n",
    "# pass 1\n",
    "for i in range(0, len(phoneme_list)):\n",
    "    if phoneme_list[i] in CMU_VOCABULARY:\n",
    "        onset = 0.12\n",
    "        offset = 0.12\n",
    "        viseme_jali = CMU2VISEME[phoneme_list[i]]+\"_pointer\"\n",
    "        if viseme_jali in LIP_HEAVY_VISEMES_JALI:\n",
    "            onset = 0.16\n",
    "            offset = 0.16\n",
    "        start = phoneme_interval[i][0]\n",
    "        end = phoneme_interval[i][1]\n",
    "        if (end - start) <= 0.4:\n",
    "            value = 5\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "        else:\n",
    "            value = 8\n",
    "            sustain = 0.9\n",
    "            decay = 0.95\n",
    "        \n",
    "        if not viseme_jali in VOWELS_JALI:\n",
    "            value = 9\n",
    "        viseme_curve = generate_animation_ctrl_pts(start, end, value, sustain=0.75, decay=decay, onset=onset, offset=offset)\n",
    "        viseme_list.append(viseme_jali)\n",
    "        phoneme_list_pure.append(phoneme_list[i])\n",
    "        viseme_intervals.append(viseme_curve)\n",
    "# pass 2 enforcing co-articulation\n",
    "viseme_list_final = []\n",
    "viseme_intervals_final = []\n",
    "\n",
    "i = 0;\n",
    "prev_vowel = 0\n",
    "prev_consonants = 0\n",
    "\n",
    "while i < len(viseme_list):\n",
    "    increment = 1\n",
    "    i_next = min(i + 1, len(viseme_list)-1)\n",
    "    if (viseme_list[i_next] == viseme_list[i] and\n",
    "       viseme_list[i_next] in CONSONANTS_JALI):\n",
    "        viseme_list_final.append(viseme_list[i_next])\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], int_curr[1], int_next[0], int_next[1]]\n",
    "        increment = 2\n",
    "    elif phoneme_list_pure[i] in SEMIVOWELS_CMU and viseme_list[i_next] in VOWELS_JALI:\n",
    "        viseme_list_final.append(viseme_list[i_next])\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], int_curr[1], int_next[0], int_next[1]]\n",
    "        increment = 2\n",
    "    elif viseme_list[i] in LIP_HEAVY_VISEMES_JALI:\n",
    "        current_interval = viseme_intervals[i] \n",
    "        if not get_kth_neighbour(viseme_list, i, -1) is None:\n",
    "            current_interval[0][0] = viseme_intervals[i-1][0][0]\n",
    "            current_interval[1][0] = viseme_intervals[i-1][1][0]\n",
    "        if not get_kth_neighbour(viseme_list, i, +1) is None:\n",
    "            current_interval[2][0] = viseme_intervals[i+1][0][0]\n",
    "            current_interval[3][0] = viseme_intervals[i+1][1][0]\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(current_interval)\n",
    "    elif viseme_list[i] in NASAL_OBSTRUENTS_JALI:\n",
    "        # these have no effect on Jaw if they are not Sibilants\n",
    "        temp_interval = viseme_intervals[i]\n",
    "        length = temp_interval[2][0]-temp_interval[1][0]\n",
    "        if length > 1/25:\n",
    "            viseme_list_final.append(viseme_list[i])\n",
    "            viseme_intervals_final.append(viseme_intervals[i])\n",
    "        else:    \n",
    "            temp = viseme_list[i].split(\"_\")\n",
    "            viseme_list_final.append(temp[0] + \"a_\" + temp[1])\n",
    "            viseme_intervals_final.append(viseme_intervals[i])\n",
    "    else:\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(viseme_intervals[i])\n",
    "        \n",
    "    if viseme_list[i] in CONSONANTS_JALI:\n",
    "        current_consonant_id = i\n",
    "    elif viseme_list[i] in VOWELS_JALI:\n",
    "        current_vowel_id = i\n",
    "    i = i + increment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.a: Jali parameter version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the jali_parameters\n",
    "DEFALT_JALI_VAL = 6\n",
    "\n",
    "jaw_ctrl_pts = []\n",
    "lip_ctrl_pts = []\n",
    "\n",
    "# get information on the frequency\n",
    "freq = lyric.pitch.selected_array[\"frequency\"]\n",
    "xs = lyric.xs\n",
    "freq[freq == 0] = np.nan\n",
    "mask = np.isnan(freq)\n",
    "freq[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), freq[~mask])\n",
    "freq = savgol_filter(freq, 21, 3)\n",
    "f = interp1d(xs, freq, kind=\"linear\")\n",
    "for sentence in sentences:\n",
    "    all_pitch_intervals_slope = []\n",
    "    all_pitch_intervals_time = []\n",
    "    si = [lyric.phoneme_intervals[sentence[0]][0],\n",
    "          lyric.phoneme_intervals[sentence[-1]][1]]\n",
    "    fs = f(np.arange(si[0], min(si[1], xs[-1]), 0.01))\n",
    "    max_fs = fs.max()\n",
    "    min_fs = fs.min()\n",
    "    # the starting point is always at \n",
    "    current_freq = fs[0]\n",
    "    jaw_ctrl_pt_0 = [lyric.phoneme_intervals[sentence[0]][0]-0.02, 6 + (current_freq-min_fs)/(max_fs-min_fs) * 4]\n",
    "    jaw_ctrl_pts.append(jaw_ctrl_pt_0)\n",
    "    lip_ctrl_pt_0 = [lyric.phoneme_intervals[sentence[0]][0]-0.02, 6 + (current_freq-min_fs)/(max_fs-min_fs) * 4]\n",
    "    lip_ctrl_pts.append(lip_ctrl_pt_0)\n",
    "    prev_voice_type = \"chest\"\n",
    "    for phone in sentence:\n",
    "        if len(lyric.pitch_slopes[phone]) == 0 and len(lyric.voice_quality_lists[phone]) > 0:\n",
    "            pitch_interval_time = lyric.phoneme_intervals[phone]\n",
    "            if lyric.voice_quality_lists[phone][0] == \"head\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = f(pitch_interval_time[0])\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[1])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], new_jaw_val])\n",
    "                if prev_voice_type == \"belt\":\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"head\"\n",
    "            elif lyric.voice_quality_lists[phone][0] == \"belt\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0])\n",
    "                new_lip_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], new_lip_val])\n",
    "                if prev_voice_type == \"head\":\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"belt\"\n",
    "        for i in range(0, len(lyric.pitch_slopes[phone])):\n",
    "            pitch_interval_time = lyric.pitch_intervals[phone][i]\n",
    "            if lyric.pitch_slopes[phone][i] > 0 and lyric.voice_quality_lists[phone][i] == \"head\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], new_jaw_val])\n",
    "                if prev_voice_type == \"belt\":\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"head\"\n",
    "            elif lyric.pitch_slopes[phone][i] > 0 and lyric.voice_quality_lists[phone][i] == \"belt\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_lip_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], new_lip_val])\n",
    "                if prev_voice_type == \"head\":\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    jaw_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"belt\"\n",
    "            elif lyric.pitch_slopes[phone][i] > 0 and lyric.voice_quality_lists[phone][i] == \"chest\":\n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], new_jaw_val])\n",
    "                if prev_voice_type == \"belt\":\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "                    lip_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "#                 if prev_voice_type == \"head\":\n",
    "#                     jaw_ctrl_pts.append([pitch_interval_time[0], DEFALT_JALI_VAL])\n",
    "#                     jaw_ctrl_pts.append([pitch_interval_time[1], DEFALT_JALI_VAL])\n",
    "                prev_voice_type = \"chest\"\n",
    "            elif lyric.pitch_slopes[phone][i] < 0: # these are opportunities to bring \n",
    "                # the pitch at the beginning of the intervals\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                # pitch at the end of the interval (also updates it)\n",
    "                current_freq = f(pitch_interval_time[0]) + lyric.pitch_slopes[phone][i] * (pitch_interval_time[1] - pitch_interval_time[0])\n",
    "                new_jaw_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                new_lip_val = DEFALT_JALI_VAL + (current_freq - min_fs)/(max_fs-min_fs) * 4\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], max(new_jaw_val, DEFALT_JALI_VAL)])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], max(new_lip_val, DEFALT_JALI_VAL)])\n",
    "                prev_voice_type = lyric.voice_quality_intervals[phone][i]\n",
    "            elif ((prev_voice_type == \"head\" and lyric.voice_quality_intervals[phone][i] == \"belt\") or \n",
    "                  (prev_voice_type == \"belt\" and lyric.voice_quality_intervals[phone][i] == \"head\")):\n",
    "                prev_jaw_val = jaw_ctrl_pts[-1][1]\n",
    "                prev_lip_val = lip_ctrl_pts[-1][1]\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[0], prev_lip_val])\n",
    "                jaw_ctrl_pts.append([pitch_interval_time[1], prev_lip_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[0], prev_jaw_val])\n",
    "                lip_ctrl_pts.append([pitch_interval_time[1], prev_jaw_val])\n",
    "                prev_voice_type = lyric.voice_quality_intervals[phone][i]\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vib_ctrl_pts = []\n",
    "for k in lyric.vibrato_intervals:\n",
    "    if len(k) > 0:\n",
    "        for m in k:\n",
    "            vib_ctrl_pts.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\"viseme\":[viseme_list, viseme_intervals],\n",
    "        \"brow\":[brow_movement, brow_ctrl_points, finer_brow_raise_ctrl_points, finer_brow_furrow_ctrl_points],\n",
    "        \"blink\":[eye_movement, eye_ctrl_points],\n",
    "        \"jaw\":jaw_ctrl_pts,\n",
    "        \"lip\":lip_ctrl_pts, \n",
    "        \"vib\":vib_ctrl_pts}\n",
    "jsonoutput = json.dumps(output)\n",
    "with open(os.path.join(dir, file_name_template+'_animation_data.json'), 'w') as outfile:\n",
    "    json.dump(jsonoutput, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple head movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_shake(t_start, t_end, prev_motion_x, prev_motions_y):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the thing into sentence structures\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "\n",
    "x_dir_head = []\n",
    "y_dir_head = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying eye brow movements using facial landmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.facial_landmarking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:/facial_data_analysis_videos/1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EVANSA~1\\AppData\\Local\\Temp/ipykernel_2640/1733076059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvideo_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"video.mp4\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"E:/facial_data_analysis_videos/1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m extract_landmarks_media_pipe(video_title[0],\n\u001b[0m\u001b[0;32m      4\u001b[0m                          video_path[0], save_annotated_video=True)\n",
      "\u001b[1;32m~\\Desktop\\jali_sing\\util\\facial_landmarking.py\u001b[0m in \u001b[0;36mextract_landmarks_media_pipe\u001b[1;34m(input_video, input_dir, show_annotated_video, show_normalized_pts, save_annotated_video, tolerance)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#     return output_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mget_audio_from_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# set up cv2 object for querying images from video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\jali_sing\\util\\ioUtil.py\u001b[0m in \u001b[0;36mget_audio_from_video\u001b[1;34m(file_name, video_folder_path, target_fps, remove)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_audio_from_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_fps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mdir_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_folder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_files\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The directory is empty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:/facial_data_analysis_videos/1'"
     ]
    }
   ],
   "source": [
    "video_title = [\"video.mp4\"]\n",
    "video_path = [\"E:/facial_data_analysis_videos/1\"]\n",
    "extract_landmarks_media_pipe(video_title[0],\n",
    "                         video_path[0], save_annotated_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visemenet",
   "language": "python",
   "name": "visemenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
