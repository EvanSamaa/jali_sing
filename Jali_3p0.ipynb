{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4599d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.SongDataStructure import *\n",
    "from util.pitch_interval_estimation import *\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from util.ioUtil import get_audio_from_video\n",
    "from scipy.interpolate import interp1d, splrep, splev\n",
    "from models.vowel_modification_detector import vowel_mod_detector\n",
    "vowel_mod = vowel_mod_detector()\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e562b8",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb9da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = \"E:/MASC/Sig_videos/song2face4/\"\n",
    "# file_name_template = \"song2face_4\"\n",
    "# get_audio_from_video(file_name_template+\".mp4\", dir)\n",
    "# os.system('ffmpeg -i ' + os.path.join(dir, file_name_template+\"/audio.mp3 \") + os.path.join(dir, file_name_template+\"/audio.wav\"))\n",
    "# lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\"/audio.wav\"), os.path.join(dir, file_name_template+\".txt\"))\n",
    "# lyric.compute_self_phoneme_alignment()\n",
    "# lyric.write_textgrid(dir, \"MVP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bb266",
   "metadata": {},
   "source": [
    "## Input Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75609c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Sig_videos/cry_me_a_river_ella_fitzgerald\"\n",
    "file_name_template = \"audio_1\"\n",
    "script_path = os.path.join(dir, \"audio_1_full.TextGrid\")\n",
    "output_template = \"jali_MVP\"\n",
    "spike_width = 0.5\n",
    "speech_vowel_threshold = 0.3\n",
    "vowel_blend_distance = 0.3\n",
    "vowel_blend_magnitude = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5204667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/lmbmm_vocal_sep_data/NUS/test/\"\n",
    "file_name_template = \"0\"\n",
    "script_path = os.path.join(dir, \"0.TextGrid\")\n",
    "output_template = \"\"\n",
    "spike_width = 0.5\n",
    "speech_vowel_threshold = 0.3\n",
    "vowel_blend_distance = 0.3\n",
    "vowel_blend_magnitude = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1106bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICED = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW', \"ER\"])\n",
    "CMU2VISEME = {\"AA\":\"Ah\", \"AO\":\"Ah\", \"AY\":\"Ah\", \"AW\":\"Ah\",\"AE\":\"Aa\",\n",
    "              \"EY\":\"Aa\",\"UH\":\"Uh\", \"UW\":\"U\",\"IH\": \"Ih\",\"IY\": \"Ih\",\"EH\": \"Eh\",\"HH\": \"Eh\",\"UH\": \"Eh\",\"AH\": \"Eh\",\n",
    "              \"ER\": \"Eh\",\"OW\":\"Oo\",\"OY\":\"Oh\",\"R\":\"R\",\"D\":\"LNTD\",\"T\": \"LNTD\",\"L\":\"LNTD\",\"N\":\"LNTD\",\"NG\":\"LNTD\",\n",
    "              \"F\":\"FV\",\"V\":\"FV\",\"B\":\"BP\",\"M\":\"M\",\"P\":\"BP\",\"CH\":\"ShChZh\",\"SH\":\"ShChZh\",\"ZH\":\"ShChZh\",\n",
    "              \"S\": \"SZ\", \"Z\": \"SZ\",\"DH\":\"Th\", \"TH\":\"Th\",\"G\":\"GK\", \"K\":\"GK\",\"Y\":\"Y\",\"JH\":\"J\",\"W\":\"W\",}\n",
    "VOWELS_SLIDERS_JALI = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\"])\n",
    "CONSONANTS_SLIDERS_JALI = set([\"M_pointer\", \"BP_pointer\", \"JY_pointer\", \"Th_pointer\", \"ShChZh_pointer\", \"SZ_pointer\", \"GK_pointer\", \"LNTD_pointer\", \"R_pointer\", \"W_pointer\", \"FV_pointer\"])\n",
    "CONSONANTS_SLIDERS_NOJAW_JALI = set([\"Ya_pointer\", \"Ja_pointer\", \"Ra_pointer\", \"FVa_pointer\", \"LNTDa_pointer\", \"Ma_pointer\", \"BPa_pointer\", \"Wa_pointer\", \"Tha_pointer\", \"GKa_pointer\"])\n",
    "JALI_SLIDERS_SET = set.union(VOWELS_SLIDERS_JALI, CONSONANTS_SLIDERS_JALI, CONSONANTS_SLIDERS_NOJAW_JALI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c42ceb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMU2VISEME = {\"AA\":\"Ah\", \"AO\":\"Ah\", \"AY\":\"Ah\", \"AW\":\"Ah\",\"AE\":\"Eh\",\n",
    "              \"EY\":\"Eh\",\"UH\":\"Ah\", \"UW\":\"U\",\"IH\": \"Ee\",\"IY\": \"Ee\",\"EH\": \"Eh\",\"HH\": \"Eh\",\"UH\": \"U\",\"AH\": \"Eh\",\n",
    "              \"ER\": \"Eh\",\"OW\":\"Oo\",\"OY\":\"Oo\",\"R\":\"R\",\"D\":\"LNTD\",\"T\": \"LNTD\",\"L\":\"LNTD\",\"N\":\"LNTD\",\"NG\":\"LNTD\",\n",
    "              \"F\":\"FV\",\"V\":\"FV\",\"B\":\"BP\",\"M\":\"M\",\"P\":\"BP\",\"CH\":\"ShChZh\",\"SH\":\"ShChZh\",\"ZH\":\"ShChZh\",\n",
    "              \"S\": \"SZ\", \"Z\": \"SZ\",\"DH\":\"Th\", \"TH\":\"Th\",\"G\":\"GK\", \"K\":\"GK\",\"Y\":\"Y\",\"JH\":\"J\",\"W\":\"W\",}\n",
    "\n",
    "dip_percentage = {\"U_pointer\":1.05, \"Oo_pointer\":0.95, \"Ah_pointer\":0.9, \"Eh_pointer\":0.9, \"Ee_pointer\":1.1}\n",
    "cmu_sets = CMU_phonemes_dicts()\n",
    "jali_sets = JALI_visemes_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be63245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_basic_viseme_curve(start, end, value, sustain=1, decay = 0.75, onset=0.1, offset=0):\n",
    "    if end - start < 0.1:\n",
    "        end = start + 0.1\n",
    "    interval = []\n",
    "    interval.append([start-onset, 0, \"bound\"])\n",
    "    # second point is when the belting starts \n",
    "    interval.append([start, 1 * value, \"internal\"])\n",
    "    # third point emphasizes decay, it happens 75% down the interval\n",
    "    if sustain < 1:\n",
    "        interval.append([start + sustain * (end - start), decay * value, \"internal\"])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0, \"bound\"])\n",
    "    elif sustain == 1:\n",
    "        interval.append([end, value, \"internal\"])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0, \"bound\"])\n",
    "    return interval\n",
    "def get_kth_neighbour(input_list, i, k):\n",
    "    if i+k < 0 or i+k >= len(input_list):\n",
    "        return None\n",
    "    return input_list[i+k]\n",
    "def difference_of_ctrl_pts(ctrl_pts1, ctrl_pts2):\n",
    "    if len(ctrl_pts1) != len(ctrl_pts2):\n",
    "        print(False)\n",
    "        return False\n",
    "    for i in range(0, len(ctrl_pts1)):\n",
    "        if len(ctrl_pts1[i]) != len(ctrl_pts2[i]):\n",
    "            print(False)\n",
    "            return False\n",
    "    for i in range(0, len(ctrl_pts1)):\n",
    "        for j in range(0, len(ctrl_pts1[i])):\n",
    "            if ctrl_pts1[i][j][0] != ctrl_pts2[i][j][0] or ctrl_pts1[i][j][1] != ctrl_pts2[i][j][1]:\n",
    "                print(False)\n",
    "                return False\n",
    "    return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff00098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_viseme_curve(viseme_curve:Viseme_curve, viseme_slider_name:str):\n",
    "    v_list = viseme_curve.viseme_list[-1]\n",
    "    ctrl_pts = viseme_curve.viseme_ctrl_pts[-1]\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0, len(v_list)):\n",
    "        if v_list[i] == viseme_slider_name:\n",
    "            for k in range(0, len(ctrl_pts[i])):\n",
    "                x.append(ctrl_pts[i][k][0])\n",
    "                y.append(ctrl_pts[i][k][1])\n",
    "#     tck = splrep(x, y, s=0)\n",
    "    A = [x, y]\n",
    "    A = np.array(A)\n",
    "    A = A[::, A[0,].argsort()[::-1]]\n",
    "    x = A[0]\n",
    "    y = A[1]\n",
    "    \n",
    "#     x_range = np.arange(x.min(), x.max(), 0.01)\n",
    "#     y_interp = splev(x_range, tck, der=0)\n",
    "#     plt.plot(x_range, y_interp)\n",
    "    plt.plot(x, y)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2238832f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fc76cfe190>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using tanh function to get a smooth curve\n",
    "def Viseme_A(peak=None, lowest=None):\n",
    "    if not peak is None:\n",
    "        total = np.log((1+peak)/(1-peak))/2\n",
    "        b = np.log((1+lowest)/(1-lowest))/2\n",
    "        a = total-b\n",
    "    else:\n",
    "        peak = 0.99\n",
    "        lowest = 0.8\n",
    "        total = np.log((1+peak)/(1-peak))/2\n",
    "        b = np.log((1+lowest)/(1-lowest))/2\n",
    "        a = total-b\n",
    "    def fn(val, val_max, val_min, max_val = 8):\n",
    "        val = (val - val_min) / (val_max - val_min)\n",
    "        if val_min == val_max:\n",
    "            val = 1\n",
    "#         print(val)\n",
    "#         return (lowest + val * ((peak - lowest)))*max_val\n",
    "        return np.tanh((val)*a+b) * max_val\n",
    "#         return (np.exp(val * 8)/np.exp(8) * (peak-lowest) + lowest) * max_val\n",
    "    return fn\n",
    "viseme_A = Viseme_A()\n",
    "plt.plot(np.arange(0, 1, 0.01), viseme_A(np.arange(0, 1, 0.01), 1, 0, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93116468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82ac693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file for Jali\n",
    "# lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n",
    "#                                                                                              script_path)\n",
    "lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template + \".pt\"),\n",
    "                                    None,\n",
    "                                    os.path.join(dir, file_name_template + \".TextGrid\"),\n",
    "                                    use_torch=True)\n",
    "\n",
    "# break the thing into sentence structures (if possible)\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "# sentence stores the indexes\n",
    "if len(sentences) == 0:\n",
    "    sentences = [list(range(0, len(lyric.phoneme_list)))]\n",
    "phoneme_list = lyric.phoneme_list\n",
    "phoneme_interval = lyric.phoneme_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad5989",
   "metadata": {},
   "source": [
    "### Animating Consonant and Vowel visemes with Musical Articulation and relative Pitch Change (Ver original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fef378",
   "metadata": {},
   "source": [
    "### Ver 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1523ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_intervals(slopes, intervals, freq_interp, xs, min_length=0.3, flatness_threshold=60):\n",
    "    flat_intervals = []\n",
    "    flat_slopes = []\n",
    "    pass_next = False\n",
    "    for i in range(0, len(slopes)):\n",
    "        if pass_next:\n",
    "            pass_next = False\n",
    "            continue\n",
    "        if abs(slopes[i]) <= flatness_threshold:\n",
    "            if xs[intervals[i][1]] - xs[intervals[i][0]] >= min_length:\n",
    "                flat_intervals.append([xs[intervals[i][0]], xs[intervals[i][1]]])\n",
    "                flat_slopes.append(slopes[i])\n",
    "            else:\n",
    "                next_index = min(i+1, len(slopes)-1) \n",
    "                if next_index == i:\n",
    "                    continue\n",
    "                next_slope = slopes[next_index]\n",
    "                next_interval = intervals[next_index]\n",
    "                if xs[next_interval[0]] - xs[intervals[i][1]] <= 0.07 and abs(next_slope) <= flatness_threshold and (\n",
    "                freq_interp((xs[next_interval[0]] + xs[next_interval[1]])/2.0) - \n",
    "                    freq_interp((xs[intervals[i][0]] + xs[intervals[i][1]])/2.0)) <= 50:\n",
    "                    if xs[next_interval[1]] - xs[intervals[i][0]] >= min_length:\n",
    "                        flat_intervals.append([xs[intervals[i][0]], xs[next_interval[1]]])\n",
    "                        pass_next = True\n",
    "                        flat_slopes.append(next_slope)\n",
    "    return flat_intervals, flat_slopes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eebf0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## phone_id = sentence[i]\n",
    "## \n",
    "\n",
    "def generate_pitch_sensitive_viseme_curve(lyric, phoneme_interval, phone_id):\n",
    "    xI, yI = lyric.get_I_interval(phoneme_interval[phone_id])\n",
    "    xf, yf = lyric.get_f_interval(phoneme_interval[phone_id])\n",
    "    xF, yF = lyric.get_F1_interval(phoneme_interval[phone_id])\n",
    "    length_of_interval = xI[-1] - xI[0] \n",
    "    if length_of_interval <= speech_vowel_threshold: # if the vowel is approximately a speech vowel, then it is handled like speech\n",
    "        onset = 0.12\n",
    "        offset = 0.12\n",
    "        if phoneme_list[phone_id] in cmu_sets.lip_heavy:\n",
    "            onset = 0.16\n",
    "            offset = 0.16\n",
    "        value = 7\n",
    "        sustain = 0.75\n",
    "        decay = 0.75\n",
    "        curve = generate_basic_viseme_curve(phoneme_interval[phone_id][0], phoneme_interval[phone_id][1], value, sustain=sustain, \n",
    "                                    decay = decay, onset=onset, offset=offset)\n",
    "        visemes_sing.add(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\", curve, phoneme_list[phone_id])\n",
    "        visemes_speak.add(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\", curve, phoneme_list[phone_id])\n",
    "        extended_vowel_list.append(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\")\n",
    "        extended_vowel_intervals.append(phoneme_interval[phone_id])\n",
    "\n",
    "    else:\n",
    "        onset = 0.12\n",
    "        offset = 0.12\n",
    "        if phoneme_list[phone_id] in cmu_sets.lip_heavy:\n",
    "            onset = 0.16\n",
    "            offset = 0.16\n",
    "        value = 7\n",
    "        sustain = 0.75\n",
    "        decay = 0.75\n",
    "        control_pts = generate_basic_viseme_curve(phoneme_interval[phone_id][0], phoneme_interval[phone_id][1], value, sustain=sustain, \n",
    "                                    decay = decay, onset=onset, offset=offset)\n",
    "        control_pts_with_pitch_change = []\n",
    "#                 vib = get_vib(yf-savgol_filter(yf, 29, 1), xf, lyric.dt)\n",
    "        vib = lyric.compute_vibrato_intervals(yf-savgol_filter(yf, 29, 1), xf, lyric.dt)\n",
    "        vib_interval_indexs = lyric.get_subarrays_indexes_from_time_interval(vib, xf)\n",
    "        for vib_int in vib_interval_indexs:\n",
    "            yf[vib_int[0]:vib_int[1]] = yf[vib_int[0]:vib_int[1]].mean()\n",
    "\n",
    "        slopes_f, intervals_f = efficient_piece_wise_linear_intervals(xf, yf)\n",
    "        kpx_f, kpy_f = get_key_points(xf, yf, intervals_f, slopes_f)\n",
    "        flat_intervals, flat_slopes = merge_intervals(slopes_f, intervals_f, interp1d(xf, yf), xf)\n",
    "        # onset and offset of these would be the same as regular vowels \n",
    "        control_pts_with_pitch_change.append([phoneme_interval[phone_id][0] - onset, 0, \"bound\"])\n",
    "        # here I will determine the average pitch when singing this vowel. Which is used to \n",
    "        avg_pitch = 0\n",
    "        total_weight = 0\n",
    "        pitch_values = []\n",
    "        for si in range(0, len(slopes_f)):\n",
    "            if abs(slopes_f[si]) <= threshold_slope:\n",
    "                avg_pitch = avg_pitch + (yf[intervals_f[si][0]] * (intervals_f[si][1] - intervals_f[si][0]))\n",
    "                pitch_values.append(yf[intervals_f[si][0]])\n",
    "                total_weight = total_weight + (intervals_f[si][1] - intervals_f[si][0])\n",
    "        if avg_pitch == 0:\n",
    "                avg_pitch = yf.mean()\n",
    "                total_weight = 1\n",
    "        pitch_values = np.array(pitch_values)\n",
    "        avg_pitch = avg_pitch / total_weight\n",
    "        start = 0\n",
    "        first_points_of_intervals = []\n",
    "        interp_pitch = interp1d(kpx_f, kpy_f)\n",
    "        # now find the first key point - i.e. the beginning of the first plateau\n",
    "        # the first key point is defined as the point where a plateau first appears \n",
    "        # it can also be the first point that reaches the same pitch as the first plateau\n",
    "        # this ensures that undetected vibrato will not mess up with the timing\n",
    "        # and cause the mouth to open too slowly \n",
    "\n",
    "        for si in range(0, len(flat_intervals)):\n",
    "            current_interval_x_range = np.arange(flat_intervals[si][0], flat_intervals[si][1], 0.01)\n",
    "            current_interval_f_range = interp_pitch(current_interval_x_range)\n",
    "            start = si\n",
    "            # make sure the search do not exceed the interpolation range\n",
    "            end_x_search = min(flat_intervals[si][0], kpx_f[-1])\n",
    "            begin_x_search = max(intervals_f[0][0], kpx_f[0])\n",
    "            x_range = np.arange(begin_x_search, end_x_search, 0.01)\n",
    "            f_range = interp_pitch(x_range)\n",
    "            first_val = interp_pitch(flat_intervals[si][0])\n",
    "            for ssi in range(0, x_range.shape[0]-1):\n",
    "                if ((f_range[ssi] < first_val) and  (f_range[ssi+1] >= first_val) \n",
    "                    or (f_range[ssi] >= first_val) and  (f_range[ssi+1] < first_val)):\n",
    "                    end_x_search = x_range[ssi]\n",
    "                    break\n",
    "            val0 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min())\n",
    "            height_ratio = dip_percentage[CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\"]\n",
    "            val1 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min()) * height_ratio\n",
    "            control_pts_with_pitch_change.append([flat_intervals[si][0], val0, \"internal\"])\n",
    "            if len(flat_intervals) > 1:\n",
    "#                         dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si+1][0] - flat_intervals[si][1]- 0.025)\n",
    "                dif = flat_intervals[si+1][0] - flat_intervals[si][0]- 0.1\n",
    "            else:\n",
    "#                         dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si][1] - flat_intervals[si][0]- 0.025)\n",
    "                dif = flat_intervals[si][1] - flat_intervals[si][0]- 0.1\n",
    "            control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val1, \"internal\"])                 \n",
    "            break\n",
    "        # now determine intermediate key-points that correlates with lipshape\n",
    "        for si in range(start+1, len(flat_intervals)):\n",
    "            current_interval_x_range = np.arange(flat_intervals[si][0], flat_intervals[si][1], 0.01)\n",
    "            current_interval_f_range = interp_pitch(current_interval_x_range)\n",
    "\n",
    "            val0 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min())\n",
    "            height_ratio = dip_percentage[CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\"]\n",
    "#                     height_ratio = 0.9\n",
    "            val1 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min()) * height_ratio\n",
    "            if len(flat_intervals) - 1> si:\n",
    "                # if it's not the last interval\n",
    "                # dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si+1][0] - flat_intervals[si][1]- 0.025)\n",
    "                dif = flat_intervals[si+1][0] - flat_intervals[si][0]- 0.1\n",
    "            else:\n",
    "                # if it is the last interval\n",
    "#                         dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si][1] - flat_intervals[si][0]- 0.025)\n",
    "                dif = flat_intervals[si][1] - flat_intervals[si][0]- 0.1\n",
    "            prev_interval_end_pt_x = control_pts_with_pitch_change[-1][0]\n",
    "            prev_interval_end_pt_y = min(control_pts_with_pitch_change[-1][1], val0)\n",
    "#                     prev_interval_end_pt_y = min(control_pts_with_pitch_change[-1][1], val0) * dip_percentage[CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"]\n",
    "\n",
    "            control_pts_with_pitch_change.append([(flat_intervals[si][0] + prev_interval_end_pt_x)/2.0, prev_interval_end_pt_y, \"internal_ph\"])    \n",
    "            control_pts_with_pitch_change.append([flat_intervals[si][0], val0, \"internal\"])\n",
    "#                     if len(flat_intervals) - 1 == si:\n",
    "#                         control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val0 * 0.8, \"internal\"])\n",
    "#                     else:\n",
    "#                         control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val1, \"internal_ph\"])\n",
    "            control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val1, \"internal\"])\n",
    "        control_pts_with_pitch_change.append([phoneme_interval[phone_id][1] + offset, 0, \"bound\"])\n",
    "        # if I cannot find any flat intervals in the vowel, then this step is spared\n",
    "        if len(control_pts_with_pitch_change) < 4:\n",
    "            onset = 0.12\n",
    "            offset = 0.12\n",
    "            if phoneme_list[phone_id] in cmu_sets.lip_heavy:\n",
    "                onset = 0.16\n",
    "                offset = 0.16\n",
    "            value = 7\n",
    "            sustain = 0.75\n",
    "            decay = 0.75\n",
    "            control_pts_with_pitch_change = generate_basic_viseme_curve(phoneme_interval[phone_id][0], phoneme_interval[phone_id][1], value, sustain=sustain, \n",
    "                                        decay = decay, onset=onset, offset=offset)\n",
    "            extended_vowel_list.append(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\")\n",
    "            extended_vowel_intervals.append(phoneme_interval[phone_id])\n",
    "        else:\n",
    "            for item in flat_intervals:\n",
    "                extended_vowel_list.append(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer_pitch_change\")\n",
    "                extended_vowel_intervals.append(item)\n",
    "        control_pts_with_pitch_change_final = []\n",
    "        skip = False\n",
    "        control_pts_with_pitch_change.sort(key=lambda x:x[0])\n",
    "        for mi in range(0, len(control_pts_with_pitch_change)):\n",
    "            if skip:\n",
    "                skip = False\n",
    "                continue\n",
    "            if control_pts_with_pitch_change[mi][2] == \"internal_ph\":\n",
    "                if mi != len(control_pts_with_pitch_change)-2:\n",
    "                    new_pt = [control_pts_with_pitch_change[mi+1][0], \n",
    "                              control_pts_with_pitch_change[mi+1][1],\n",
    "                              \"internal\"]\n",
    "                    control_pts_with_pitch_change_final.append(new_pt)\n",
    "                    skip = True\n",
    "                else:\n",
    "                    new_pt = [control_pts_with_pitch_change[mi][0], \n",
    "                              control_pts_with_pitch_change[mi][1],\n",
    "                               \"internal\"]\n",
    "                    control_pts_with_pitch_change_final.append(new_pt)  \n",
    "            else:\n",
    "                control_pts_with_pitch_change_final.append(control_pts_with_pitch_change[mi])\n",
    "\n",
    "\n",
    "        visemes_sing.add(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\", control_pts_with_pitch_change_final, phoneme_list[phone_id])\n",
    "        visemes_speak.add(CMU2VISEME[phoneme_list[phone_id]] + \"_pointer\", control_pts, phoneme_list[phone_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4190739",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LNTD_pointer 0.05689600000000006\n",
      "LNTD_pointer 0.5128469999999998\n",
      "FV_pointer 0.05245999999999995\n"
     ]
    }
   ],
   "source": [
    "visemes_sing = Viseme_curve()\n",
    "visemes_sing.new_pass()\n",
    "visemes_speak = Viseme_curve()\n",
    "visemes_speak.new_pass()\n",
    "\n",
    "extended_vowel_intervals = []\n",
    "extended_vowel_list = []\n",
    "\n",
    "# animate only vowels and see how it goes\n",
    "max_activation = 8\n",
    "# threshold_slope = 200 # for formants\n",
    "threshold_slope = 60 # for pitch\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence_pitch_x, sentence_pitch_y = lyric.get_f_interval([phoneme_interval[sentence[0]][0], \n",
    "                                                               phoneme_interval[sentence[-1]][1]])\n",
    "    sentence_percentiles = np.nanpercentile(sentence_pitch_y, [5, 95])\n",
    "    sentence_mean = sentence_pitch_y.mean()\n",
    "    sentence_min = sentence_percentiles[0]\n",
    "    sentence_max = sentence_percentiles[1]\n",
    "    for i in range(0, len(sentence)):\n",
    "        # skip the misc symbols in the sentence\n",
    "        if phoneme_list[sentence[i]] in VOICED: # basically vowels\n",
    "            xI, yI = lyric.get_I_interval(phoneme_interval[sentence[i]])\n",
    "            xf, yf = lyric.get_f_interval(phoneme_interval[sentence[i]])\n",
    "            xF, yF = lyric.get_F1_interval(phoneme_interval[sentence[i]])\n",
    "            length_of_interval = xI[-1] - xI[0] \n",
    "            if length_of_interval <= speech_vowel_threshold: # if the vowel is approximately a speech vowel, then it is handled like speech\n",
    "                onset = 0.12\n",
    "                offset = 0.12\n",
    "                if phoneme_list[sentence[i]] in cmu_sets.lip_heavy:\n",
    "                    onset = 0.16\n",
    "                    offset = 0.16\n",
    "                value = 7\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "                curve = generate_basic_viseme_curve(phoneme_interval[sentence[i]][0], phoneme_interval[sentence[i]][1], value, sustain=sustain, \n",
    "                                            decay = decay, onset=onset, offset=offset)\n",
    "                visemes_sing.add(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\", curve, phoneme_list[sentence[i]])\n",
    "                visemes_speak.add(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\", curve, phoneme_list[sentence[i]])\n",
    "                extended_vowel_list.append(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\")\n",
    "                extended_vowel_intervals.append(phoneme_interval[sentence[i]])\n",
    "                \n",
    "            else:\n",
    "                onset = 0.12\n",
    "                offset = 0.12\n",
    "                if phoneme_list[sentence[i]] in cmu_sets.lip_heavy:\n",
    "                    onset = 0.16\n",
    "                    offset = 0.16\n",
    "                value = 7\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "                control_pts = generate_basic_viseme_curve(phoneme_interval[sentence[i]][0], phoneme_interval[sentence[i]][1], value, sustain=sustain, \n",
    "                                            decay = decay, onset=onset, offset=offset)\n",
    "                control_pts_with_pitch_change = []\n",
    "#                 vib = get_vib(yf-savgol_filter(yf, 29, 1), xf, lyric.dt)\n",
    "                vib = lyric.compute_vibrato_intervals(yf-savgol_filter(yf, 29, 1), xf, lyric.dt)\n",
    "                vib_interval_indexs = lyric.get_subarrays_indexes_from_time_interval(vib, xf)\n",
    "                for vib_int in vib_interval_indexs:\n",
    "                    yf[vib_int[0]:vib_int[1]] = yf[vib_int[0]:vib_int[1]].mean()\n",
    "                    \n",
    "                slopes_f, intervals_f = efficient_piece_wise_linear_intervals(xf, yf)\n",
    "                kpx_f, kpy_f = get_key_points(xf, yf, intervals_f, slopes_f)\n",
    "                flat_intervals, flat_slopes = merge_intervals(slopes_f, intervals_f, interp1d(xf, yf), xf)\n",
    "                # onset and offset of these would be the same as regular vowels \n",
    "                control_pts_with_pitch_change.append([phoneme_interval[sentence[i]][0] - onset, 0, \"bound\"])\n",
    "                # here I will determine the average pitch when singing this vowel. Which is used to \n",
    "                avg_pitch = 0\n",
    "                total_weight = 0\n",
    "                pitch_values = []\n",
    "                for si in range(0, len(slopes_f)):\n",
    "                    if abs(slopes_f[si]) <= threshold_slope:\n",
    "                        avg_pitch = avg_pitch + (yf[intervals_f[si][0]] * (intervals_f[si][1] - intervals_f[si][0]))\n",
    "                        pitch_values.append(yf[intervals_f[si][0]])\n",
    "                        total_weight = total_weight + (intervals_f[si][1] - intervals_f[si][0])\n",
    "                if avg_pitch == 0:\n",
    "                        avg_pitch = yf.mean()\n",
    "                        total_weight = 1\n",
    "                pitch_values = np.array(pitch_values)\n",
    "                avg_pitch = avg_pitch / total_weight\n",
    "#                 if CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\" == \"Ah_pointer\":\n",
    "#                     plt.plot(kpx_f, kpy_f)\n",
    "#                     plt.plot(xf, yf)\n",
    "#                     plt.show()\n",
    "                start = 0\n",
    "                first_points_of_intervals = []\n",
    "                interp_pitch = interp1d(kpx_f, kpy_f)\n",
    "                # now find the first key point - i.e. the beginning of the first plateau\n",
    "                # the first key point is defined as the point where a plateau first appears \n",
    "                # it can also be the first point that reaches the same pitch as the first plateau\n",
    "                # this ensures that undetected vibrato will not mess up with the timing\n",
    "                # and cause the mouth to open too slowly \n",
    "\n",
    "                for si in range(0, len(flat_intervals)):\n",
    "                    current_interval_x_range = np.arange(flat_intervals[si][0], flat_intervals[si][1], 0.01)\n",
    "                    current_interval_f_range = interp_pitch(current_interval_x_range)\n",
    "                    start = si\n",
    "                    # make sure the search do not exceed the interpolation range\n",
    "                    end_x_search = min(flat_intervals[si][0], kpx_f[-1])\n",
    "                    begin_x_search = max(intervals_f[0][0], kpx_f[0])\n",
    "                    x_range = np.arange(begin_x_search, end_x_search, 0.01)\n",
    "                    f_range = interp_pitch(x_range)\n",
    "                    first_val = interp_pitch(flat_intervals[si][0])\n",
    "                    for ssi in range(0, x_range.shape[0]-1):\n",
    "                        if ((f_range[ssi] < first_val) and  (f_range[ssi+1] >= first_val) \n",
    "                            or (f_range[ssi] >= first_val) and  (f_range[ssi+1] < first_val)):\n",
    "                            end_x_search = x_range[ssi]\n",
    "                            break\n",
    "                    val0 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min())\n",
    "                    height_ratio = dip_percentage[CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"]\n",
    "                    val1 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min()) * height_ratio\n",
    "                    control_pts_with_pitch_change.append([flat_intervals[si][0], val0, \"internal\"])\n",
    "                    if len(flat_intervals) > 1:\n",
    "#                         dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si+1][0] - flat_intervals[si][1]- 0.025)\n",
    "                        dif = flat_intervals[si+1][0] - flat_intervals[si][0]- 0.1\n",
    "                    else:\n",
    "#                         dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si][1] - flat_intervals[si][0]- 0.025)\n",
    "                        dif = flat_intervals[si][1] - flat_intervals[si][0]- 0.1\n",
    "                    control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val1, \"internal\"])                 \n",
    "                    break\n",
    "                # now determine intermediate key-points that correlates with lipshape\n",
    "                for si in range(start+1, len(flat_intervals)):\n",
    "                    current_interval_x_range = np.arange(flat_intervals[si][0], flat_intervals[si][1], 0.01)\n",
    "                    current_interval_f_range = interp_pitch(current_interval_x_range)\n",
    "                    \n",
    "                    val0 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min())\n",
    "                    height_ratio = dip_percentage[CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"]\n",
    "#                     height_ratio = 0.9\n",
    "                    val1 = viseme_A(current_interval_f_range.max(), yf.max(), yf.min()) * height_ratio\n",
    "                    if len(flat_intervals) - 1> si:\n",
    "                        # if it's not the last interval\n",
    "                        # dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si+1][0] - flat_intervals[si][1]- 0.025)\n",
    "                        dif = flat_intervals[si+1][0] - flat_intervals[si][0]- 0.1\n",
    "                    else:\n",
    "                        # if it is the last interval\n",
    "#                         dif = max((flat_intervals[si][1] - flat_intervals[si][0]) * 0.9, flat_intervals[si][1] - flat_intervals[si][0]- 0.025)\n",
    "                        dif = flat_intervals[si][1] - flat_intervals[si][0]- 0.1\n",
    "                    prev_interval_end_pt_x = control_pts_with_pitch_change[-1][0]\n",
    "                    prev_interval_end_pt_y = min(control_pts_with_pitch_change[-1][1], val0)\n",
    "#                     prev_interval_end_pt_y = min(control_pts_with_pitch_change[-1][1], val0) * dip_percentage[CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"]\n",
    "\n",
    "                    control_pts_with_pitch_change.append([(flat_intervals[si][0] + prev_interval_end_pt_x)/2.0, prev_interval_end_pt_y, \"internal_ph\"])    \n",
    "                    control_pts_with_pitch_change.append([flat_intervals[si][0], val0, \"internal\"])\n",
    "#                     if len(flat_intervals) - 1 == si:\n",
    "#                         control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val0 * 0.8, \"internal\"])\n",
    "#                     else:\n",
    "#                         control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val1, \"internal_ph\"])\n",
    "                    control_pts_with_pitch_change.append([flat_intervals[si][0] + dif, val1, \"internal\"])\n",
    "                control_pts_with_pitch_change.append([phoneme_interval[sentence[i]][1] + offset, 0, \"bound\"])\n",
    "                # if I cannot find any flat intervals in the vowel, then this step is spared\n",
    "                if len(control_pts_with_pitch_change) < 4:\n",
    "                    onset = 0.12\n",
    "                    offset = 0.12\n",
    "                    if phoneme_list[sentence[i]] in cmu_sets.lip_heavy:\n",
    "                        onset = 0.16\n",
    "                        offset = 0.16\n",
    "                    value = 7\n",
    "                    sustain = 0.75\n",
    "                    decay = 0.75\n",
    "                    control_pts_with_pitch_change = generate_basic_viseme_curve(phoneme_interval[sentence[i]][0], phoneme_interval[sentence[i]][1], value, sustain=sustain, \n",
    "                                                decay = decay, onset=onset, offset=offset)\n",
    "                    extended_vowel_list.append(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\")\n",
    "                    extended_vowel_intervals.append(phoneme_interval[sentence[i]])\n",
    "                else:\n",
    "                    for item in flat_intervals:\n",
    "                        extended_vowel_list.append(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer_pitch_change\")\n",
    "                        extended_vowel_intervals.append(item)\n",
    "                control_pts_with_pitch_change_final = []\n",
    "                skip = False\n",
    "                control_pts_with_pitch_change.sort(key=lambda x:x[0])\n",
    "                for mi in range(0, len(control_pts_with_pitch_change)):\n",
    "                    if skip:\n",
    "                        skip = False\n",
    "                        continue\n",
    "                    if control_pts_with_pitch_change[mi][2] == \"internal_ph\":\n",
    "                        if mi != len(control_pts_with_pitch_change)-2:\n",
    "                            new_pt = [control_pts_with_pitch_change[mi+1][0], \n",
    "                                      control_pts_with_pitch_change[mi+1][1],\n",
    "                                      \"internal\"]\n",
    "                            control_pts_with_pitch_change_final.append(new_pt)\n",
    "                            skip = True\n",
    "                        else:\n",
    "                            new_pt = [control_pts_with_pitch_change[mi][0], \n",
    "                                      control_pts_with_pitch_change[mi][1],\n",
    "                                       \"internal\"]\n",
    "                            control_pts_with_pitch_change_final.append(new_pt)  \n",
    "                    else:\n",
    "                        control_pts_with_pitch_change_final.append(control_pts_with_pitch_change[mi])\n",
    "            \n",
    "            \n",
    "                visemes_sing.add(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\", control_pts_with_pitch_change_final, phoneme_list[sentence[i]])\n",
    "                visemes_speak.add(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\", control_pts, phoneme_list[sentence[i]])\n",
    "                \n",
    "        ### Dealing with consonants here. I'm just going to insert them between without too much modification\n",
    "        ### it will about the same as pure Jali\n",
    "        elif phoneme_list[sentence[i]] in cmu_sets.consonants:\n",
    "#             if phoneme_list[sentence[i]] in cmu_sets.voiced:\n",
    "            onset = 0.12\n",
    "            offset = 0.12\n",
    "            if phoneme_list[sentence[i]] == \"HH\" or phoneme_list[sentence[i]] in cmu_sets.sibilant:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"\n",
    "            else:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[sentence[i]]] + \"a_pointer\"\n",
    "            if viseme_jali in jali_sets.lip_heavy:\n",
    "                onset = 0.16\n",
    "                offset = 0.16\n",
    "            start = phoneme_interval[sentence[i]][0]\n",
    "            end = phoneme_interval[sentence[i]][1]\n",
    "            if (end - start) <= 0.1:\n",
    "                value = 6\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "            elif (end - start) <= 0.3:\n",
    "                value = 6\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "            else:\n",
    "                value = 8\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "            if phoneme_list[sentence[i]] in cmu_sets.lip_closer:\n",
    "                value = 10\n",
    "            viseme_curve = generate_basic_viseme_curve(start, end, value, sustain=sustain, decay=decay, onset=onset, offset=offset)\n",
    "            visemes_sing.add(viseme_jali, viseme_curve, phoneme_list[sentence[i]])\n",
    "            visemes_speak.add(viseme_jali, viseme_curve, phoneme_list[sentence[i]])\n",
    "            # add jaw component to voiced consonants if it's sufficiently voiced\n",
    "            if phoneme_list[sentence[i]] in cmu_sets.voiced and phoneme_interval[sentence[i]][1] - phoneme_interval[sentence[i]][0] > 1/20:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bb84b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eh_pointer [[3.4133739999999997, 0, 'bound'], [3.533374, 7.92, 'internal'], [4.663373999999974, 7.128, 'internal'], [4.8838, 0, 'bound']]\n",
      "LNTDa_pointer [[4.6438, 0, 'bound'], [4.7638, 6, 'internal'], [4.838799999999999, 4.5, 'internal'], [4.9838, 0, 'bound']]\n",
      "LNTDa_pointer [[4.700526, 0, 'bound'], [4.820526, 8, 'internal'], [5.20516125, 6.0, 'internal'], [5.453373, 0, 'bound']]\n",
      "FVa_pointer [[5.213373, 0, 'bound'], [5.333373, 10, 'internal'], [5.408372999999999, 7.5, 'internal'], [5.553373, 0, 'bound']]\n",
      "Ah_pointer [[5.265833, 0, 'bound'], [5.385833, 7.92, 'internal'], [6.8658329999999665, 7.128, 'internal'], [7.094945, 0, 'bound']]\n",
      "SZ_pointer [[6.814945, 0, 'bound'], [6.974945, 10, 'internal'], [7.09282325, 7.5, 'internal'], [7.292116, 0, 'bound']]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(visemes_sing.viseme_ctrl_pts[-1])):\n",
    "    print(visemes_sing.viseme_list[-1][i], visemes_sing.viseme_ctrl_pts[-1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aa1252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce co-articulation rules of consonants for speech visemes\n",
    "i = 0;\n",
    "viseme_list = copy.deepcopy(visemes_speak.viseme_list[-1])\n",
    "pure_phoneme_list = copy.deepcopy(visemes_speak.pure_phoneme[-1])\n",
    "viseme_intervals = copy.deepcopy(visemes_speak.viseme_ctrl_pts[-1])\n",
    "visemes_speak.new_pass()\n",
    "while i < len(viseme_list):\n",
    "    increment = 1\n",
    "    i_next = min(i + 1, len(viseme_list)-1)\n",
    "    if ((viseme_list[i_next] == viseme_list[i] and not viseme_list[i] in jali_sets.vowels) or (pure_phoneme_list[i] == \"HH\" and pure_phoneme_list[i_next] in cmu_sets.vowels)\n",
    "        and viseme_intervals[i][-1][0] >= viseme_intervals[i_next][0][0]):\n",
    "        # remove repeated vowels or consonants\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], [int_curr[1][0], max(int_curr[1][1], int_next[1][1]), int_curr[1][2]]]\n",
    "        for interv in int_next[2:]:\n",
    "            viseme_interval.append(interv)                \n",
    "        visemes_speak.add(viseme_list[i_next], copy.deepcopy(viseme_interval), pure_phoneme_list[i_next])\n",
    "#         if viseme_list[i_next] in jali_sets.lip_rounder:\n",
    "#             visemes_sing(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i_next]], viseme_interval, pure_phoneme_list[i_next])\n",
    "        increment = 2\n",
    "    elif viseme_list[i] in jali_sets.lip_heavy:\n",
    "        # if the viseme is a lip-heavy viseme, the it is voice simutaneously as nearby labial dental and bilabials \n",
    "        current_interval = copy.deepcopy(viseme_intervals[i])\n",
    "        if not get_kth_neighbour(viseme_list, i, -1) is None:\n",
    "            if current_interval[0][0] <= viseme_intervals[i-1][-1][0] - lyric.dt and viseme_intervals[i-1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[0][0] = viseme_intervals[i-1][0][0]\n",
    "                current_interval[1][0] = viseme_intervals[i-1][1][0]\n",
    "        if not get_kth_neighbour(viseme_list, i, +1) is None:\n",
    "            if current_interval[-1][0] <= viseme_intervals[i+1][0][0] - lyric.dt and viseme_intervals[i+1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[2][0] = viseme_intervals[i+1][0][0]\n",
    "                current_interval[3][0] = viseme_intervals[i+1][1][0]\n",
    "#         if viseme_list[i] in jali_sets.lip_rounder:\n",
    "#             visemes_sing(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i]], current_interval, pure_phoneme_list[i])\n",
    "        visemes_speak.add(viseme_list[i], copy.deepcopy(current_interval), pure_phoneme_list[i])\n",
    "    else:\n",
    "        visemes_speak.add(viseme_list[i], copy.deepcopy(viseme_intervals[i]), pure_phoneme_list[i])\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdccded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce co-articulation rules of consonants for singing visemes\n",
    "i = 0;\n",
    "viseme_list = copy.deepcopy(visemes_sing.viseme_list[-1])\n",
    "pure_phoneme_list = copy.deepcopy(visemes_sing.pure_phoneme[-1])\n",
    "viseme_intervals = copy.deepcopy(visemes_sing.viseme_ctrl_pts[-1])\n",
    "visemes_sing.new_pass()\n",
    "while i < len(viseme_list):\n",
    "    increment = 1\n",
    "    i_next = min(i + 1, len(viseme_list)-1)\n",
    "    if ((viseme_list[i_next] == viseme_list[i] and not viseme_list[i] in jali_sets.vowels) or (pure_phoneme_list[i] == \"HH\" and pure_phoneme_list[i_next] in cmu_sets.vowels)\n",
    "        and viseme_intervals[i][-1][0] >= viseme_intervals[i_next][0][0]):\n",
    "        # remove repeated vowels or consonants\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], [int_curr[1][0], max(int_curr[1][1], int_next[1][1]), int_curr[1][2]]]\n",
    "        for interv in int_next[2:]:\n",
    "            viseme_interval.append(interv)                \n",
    "        visemes_sing.add(viseme_list[i_next], copy.deepcopy(viseme_interval), pure_phoneme_list[i_next])\n",
    "#         if viseme_list[i_next] in jali_sets.lip_rounder:\n",
    "#             visemes_sing(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i_next]], viseme_interval, pure_phoneme_list[i_next])\n",
    "        increment = 2\n",
    "    elif viseme_list[i] in jali_sets.lip_heavy:\n",
    "        # if the viseme is a lip-heavy viseme, the it is voice simutaneously as nearby labial dental and bilabials \n",
    "        current_interval = viseme_intervals[i] \n",
    "        if not get_kth_neighbour(viseme_list, i, -1) is None:\n",
    "            if current_interval[0][0] <= viseme_intervals[i-1][-1][0] - lyric.dt and viseme_intervals[i-1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[0][0] = viseme_intervals[i-1][0][0]\n",
    "                current_interval[1][0] = viseme_intervals[i-1][1][0]\n",
    "        if not get_kth_neighbour(viseme_list, i, +1) is None:\n",
    "            if current_interval[-1][0] <= viseme_intervals[i+1][0][0] - lyric.dt and viseme_intervals[i+1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[2][0] = viseme_intervals[i+1][0][0]\n",
    "                current_interval[3][0] = viseme_intervals[i+1][1][0]\n",
    "#         if viseme_list[i] in jali_sets.lip_rounder:\n",
    "#             visemes_sing(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i]], current_interval, pure_phoneme_list[i])\n",
    "        visemes_sing.add(viseme_list[i], copy.deepcopy(current_interval), pure_phoneme_list[i])\n",
    "    else:\n",
    "        visemes_sing.add(viseme_list[i], copy.deepcopy(viseme_intervals[i]), pure_phoneme_list[i])\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fad9a",
   "metadata": {},
   "source": [
    "## 2.2 smooth out un-intended artifacts due to unexpected overlaps for speech visemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b08d8be",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# pass 3\n",
    "# set this up\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(list(jali_sets.vocabs))):\n",
    "    prev_slider_dict[list(jali_sets.vocabs)[i]] = -1\n",
    "viseme_list_final = copy.deepcopy(visemes_speak.viseme_list[-1])\n",
    "viseme_intervals_final = copy.deepcopy(visemes_speak.viseme_ctrl_pts[-1])\n",
    "pure_phoneme_list = copy.deepcopy(visemes_speak.pure_phoneme[-1])\n",
    "visemes_speak.new_pass()\n",
    "i = 0\n",
    "while i < len(visemes_speak.viseme_list[-2]):\n",
    "    increment = 1\n",
    "    # prev_viseme = viseme_list_final[i]\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[viseme_list_final[i]] != -1:\n",
    "        current_interval = copy.deepcopy(viseme_intervals_final[i])\n",
    "        prev_interval = copy.deepcopy(visemes_speak.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]])\n",
    "        # For the same vowel/consonant if the two intervals do not overlap but the onset and off set overlap \n",
    "        if (current_interval[0][0] <= prev_interval[-1][0]):\n",
    "            # if we have weird overlap where the boundary of the previous interval interupts the curve of the current\n",
    "            if (current_interval[1][0] <= prev_interval[-1][0]):\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = current_interval[0][0]\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.5\n",
    "                visemes_speak.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = temp\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.5\n",
    "                visemes_speak.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "            elif (current_interval[0][0] <= prev_interval[-2][0]):\n",
    "                temp = copy.deepcopy(current_interval)\n",
    "                temp[0][0] = prev_interval[-1][0]\n",
    "                temp[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.5\n",
    "                visemes_speak.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.5\n",
    "                visemes_speak.add(viseme_list_final[i], temp, pure_phoneme_list[i])\n",
    "            else:\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                \n",
    "                if pure_phoneme_list[i] in cmu_sets.lip_closer:\n",
    "                    visemes_speak.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "#                 print(temp[-1][0], current_interval[0][0])\n",
    "                else:\n",
    "                    temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.5\n",
    "                    visemes_speak.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = temp\n",
    "                    current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.5\n",
    "                    visemes_speak.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "                \n",
    "                    \n",
    "        # if the two interval overlaps\n",
    "        elif (current_interval[1][0] <= prev_interval[-2][0]):\n",
    "            interval = prev_interval[0:-2] + current_interval[1:]\n",
    "            visemes_speak.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = copy.deepcopy(interval)\n",
    "        else:\n",
    "            visemes_speak.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "            \n",
    "    else:        \n",
    "        visemes_speak.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "        \n",
    "    prev_slider_dict[viseme_list_final[i]] = len(visemes_speak.viseme_ctrl_pts[-1]) - 1\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3dbb1",
   "metadata": {},
   "source": [
    "## 2.3 Extending the onset and offset of vowels so they overlap more for singing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f18b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "viseme_list = copy.deepcopy(visemes_sing.viseme_list[-1])\n",
    "viseme_intervals = copy.deepcopy(visemes_sing.viseme_ctrl_pts[-1])\n",
    "pure_phonemes = copy.deepcopy(visemes_sing.pure_phoneme[-1])\n",
    "# visemes_sing_notM = Viseme_curve(viseme_list.deepcopy(), viseme_intervals.deepcopy())\n",
    "for i in range(1, len(viseme_list)):\n",
    "    # re-order all the clips so that \n",
    "    if viseme_list[i] in jali_sets.vowels:\n",
    "        next_nasal_vowel = -1\n",
    "        for si in range(i+1, len(pure_phonemes)):\n",
    "            if pure_phonemes[si] in set([\"N\", \"NG\"]):\n",
    "                next_nasal_vowel = si\n",
    "                break\n",
    "        if next_nasal_vowel > -1:\n",
    "            interval_i = copy.deepcopy(viseme_intervals[i])\n",
    "            interval_i.sort(key=lambda x:x[0])\n",
    "            interval_next = copy.deepcopy(viseme_intervals[next_nasal_vowel])\n",
    "            interval_next.sort(key=lambda x:x[0])\n",
    "#             if interval_i[0][0] <= interval_prev[-1][0]:\n",
    "            if abs(interval_i[-1][0]-interval_next[0][0]) <= 0.1 or (interval_i[-1][0] >= interval_next[0][0] and interval_i[-1][0] <= interval_next[-1][0]):\n",
    "                interval_i[-1][0] = interval_next[-1][0]\n",
    "#                 interval_i[-2][0] = interval_next[-3][0]\n",
    "                viseme_intervals[i] = interval_i\n",
    "visemes_sing.viseme_list[-1] = viseme_list\n",
    "visemes_sing.viseme_ctrl_pts[-1] = viseme_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f741ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "viseme_list = copy.deepcopy(visemes_sing.viseme_list[-1])\n",
    "viseme_intervals = copy.deepcopy(visemes_sing.viseme_ctrl_pts[-1])\n",
    "pure_phonemes = copy.deepcopy(visemes_sing.pure_phoneme[-1])\n",
    "for i in range(1, len(viseme_list)):\n",
    "    # re-order all the clips so that \n",
    "    if viseme_list[i] in jali_sets.vowels:\n",
    "        prev_vowel = -1\n",
    "        for si in range(i-1, -1, -1):\n",
    "            if pure_phoneme_list[si] in cmu_sets.vowels:\n",
    "                prev_vowel = si\n",
    "                break\n",
    "#         if prev_vowel > -1 and viseme_list[i] != viseme_list[prev_vowel]:\n",
    "        if prev_vowel > -1:\n",
    "            interval_i = copy.deepcopy(viseme_intervals[i])\n",
    "            interval_i.sort(key=lambda x:x[0])\n",
    "            interval_prev = copy.deepcopy(viseme_intervals[prev_vowel])\n",
    "            interval_prev.sort(key=lambda x:x[0])\n",
    "            if abs(interval_i[0][0]-interval_prev[-1][0]) <= 0.3 or (\n",
    "                interval_i[0][0] >= interval_prev[0][0] and interval_i[0][0] <= interval_prev[-1][0]):\n",
    "                # there is an overlap\n",
    "                interval_prev[-1][0] = min(interval_i[1][0] + 0.12, interval_i[-2][0])\n",
    "                interval_i[0][0] = max(interval_prev[-2][0] - 0.12, interval_prev[1][0])\n",
    "                viseme_intervals[i] = interval_i\n",
    "                viseme_intervals[prev_vowel] = interval_prev\n",
    "visemes_sing.viseme_list[-1] = viseme_list\n",
    "visemes_sing.viseme_ctrl_pts[-1] = viseme_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516101c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 3\n",
    "# set this up\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(list(jali_sets.vocabs))):\n",
    "    prev_slider_dict[list(jali_sets.vocabs)[i]] = -1\n",
    "viseme_list_final = visemes_sing.viseme_list[-1]\n",
    "viseme_intervals_final = visemes_sing.viseme_ctrl_pts[-1]\n",
    "pure_phoneme_list = visemes_sing.pure_phoneme[-1]\n",
    "visemes_sing.new_pass()\n",
    "i = 0  \n",
    "while i < len(visemes_sing.viseme_list[-2]):\n",
    "    increment = 1\n",
    "    prev_viseme = viseme_list_final[i]\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[viseme_list_final[i]] != -1:\n",
    "        current_interval = copy.deepcopy(viseme_intervals_final[i])\n",
    "        current_interval.sort(key=lambda x:x[0])\n",
    "        prev_interval = copy.deepcopy(visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]])\n",
    "        prev_interval.sort(key=lambda x:x[0])\n",
    "        # For the same vowel/consonant if the two intervals do not overlap but the onset and off set overlap \n",
    "        if (current_interval[0][0] - prev_interval[-1][0]) <= vowel_blend_distance:\n",
    "            # if we have weird overlap where the boundary of the previous interval interupts the curve of the current\n",
    "            if prev_interval[2][0] - prev_interval[1][0] <= speech_vowel_threshold:\n",
    "                prev_interval[2][1] = 0.95 * prev_interval[1][1]\n",
    "            if current_interval[1][0] <= prev_interval[-1][0] and current_interval[0][0] <= prev_interval[-2][0]:\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = copy.deepcopy(temp)\n",
    "                current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "            elif (current_interval[1][0] <= prev_interval[-1][0]):\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = current_interval[0][0]\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = temp\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "            elif (current_interval[0][0] <= prev_interval[-2][0]):\n",
    "                temp = copy.deepcopy(current_interval)\n",
    "                temp[0][0] = prev_interval[-1][0]\n",
    "                temp[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                visemes_sing.add(viseme_list_final[i], temp, pure_phoneme_list[i])\n",
    "            else:\n",
    "                if pure_phoneme_list[i] in cmu_sets.lip_closer:\n",
    "                    visemes_sing.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "                else:\n",
    "                    temp = copy.deepcopy(prev_interval)\n",
    "                    temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                    visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = copy.deepcopy(temp)\n",
    "                    current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                    visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "        # if the two interval overlaps\n",
    "        elif (current_interval[1][0] <= prev_interval[-2][0]):\n",
    "            interval = prev_interval[0:-2] + current_interval[1:]\n",
    "            visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        else:\n",
    "            visemes_sing.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "    else:        \n",
    "        visemes_sing.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "        \n",
    "    prev_slider_dict[viseme_list_final[i]] = len(visemes_sing.viseme_ctrl_pts[-1]) - 1\n",
    "    i = i + increment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b900e",
   "metadata": {},
   "source": [
    "### Vibrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4f5e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lyric.compute_self_vibrato_intervals()\n",
    "\n",
    "vib_ctrl_pts = []\n",
    "for k in lyric.vibrato_intervals:\n",
    "    if len(k) > 0:\n",
    "        for m in k:\n",
    "            vib_ctrl_pts.append(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b460b3c",
   "metadata": {},
   "source": [
    "## Vowel Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09e738a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314524,)\n"
     ]
    }
   ],
   "source": [
    "print(lyric.sound_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e50be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel2Cardinal5 = {\"Ah_pointer\":0, \"Aa_pointer\":1, \"Eh_pointer\":1, \"Ee_pointer\":2, \n",
    "                 \"Ih_pointer\":2, \"Oo_pointer\":3, \"Oh_pointer\":3, \"Uh_pointer\":0, \n",
    "                  \"U_pointer\":4, \"Eu_pointer\":4}\n",
    "vowel2Cardinal3 = {\"Ah_pointer\":0, \"Aa_pointer\":1, \"Eh_pointer\":1, \"Ee_pointer\":1, \n",
    "                 \"Ih_pointer\":1, \"Oo_pointer\":2, \"Oh_pointer\":2, \"Uh_pointer\":0, \n",
    "                  \"U_pointer\":2, \"Eu_pointer\":2}\n",
    "\n",
    "control_direction_matrix_coarse = {0:{1:[\"Dimple\", \"Dimple\", [0, 9]], 2:[\"Pucker\", \"Pucker\", [0, 3]]},\n",
    "                                  1:{0:[\"self\", \"lipCornerPull\", [0, -3],\n",
    "                                       \"self\", \"lipStretch\", [0, -3]], 2:[\"Pucker\", \"Pucker\", [0, 3]]},\n",
    "                                  2:{0:[\"self\", \"lipPucker\", [0, -7]], 1:[\"self\", \"lipPucker\", [0, -7],\n",
    "                                                                          \"Dimple\", \"Dimple\", [0, 9]]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2617c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "viseme_list = visemes_sing.viseme_list[-1]\n",
    "viseme_interval = visemes_sing.viseme_ctrl_pts[-1]\n",
    "\n",
    "modification_ctrl_pts = []\n",
    "modification_sliders = []\n",
    "# iterate through the vowels in the list\n",
    "dt = 0.01\n",
    "for i in range(0, len(viseme_list)):\n",
    "    if viseme_list[i] in VOWELS_SLIDERS_JALI and viseme_interval[i][-2][0] - viseme_interval[i][0][0] > 0.30:\n",
    "        ##################################################################\n",
    "        ###################### get the audio signal ######################\n",
    "        ##################################################################\n",
    "        vowel_mod_out, vowel_mod_out_coarse = vowel_mod(lyric.sound_arr_interp(np.arange(viseme_interval[i][1][0], \n",
    "                                                                                        min(viseme_interval[i][-1][0], lyric.snd.xs()[-1]), 1.0/44100.0)))\n",
    "#         print([\"A\", \"Stretcher\", \"Rounder\", \"Silence\"][vowel2Cardinal3[viseme_list[i]]])\n",
    "        if vowel_mod_out_coarse.shape[0] <= 10:\n",
    "            continue\n",
    "        xs = np.linspace(viseme_interval[i][1][0], min(viseme_interval[i][-1][0], lyric.snd.xs()[-1]), vowel_mod_out_coarse.shape[0])\n",
    "        coarse_vowel_sounds_like_interp = interp1d(xs, vowel_mod_out_coarse, axis=0)\n",
    "        \n",
    "#         for i in range(0, 4):\n",
    "#             plt.plot(vowel_mod_out_coarse[:, i], label=[\"Ah\", \"stretcher\", \"rounder\", \"silence\"][i])\n",
    "# #         plt.plot(np.argmax(out[0, :], axis=1))\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        \n",
    "        # what the original sound was\n",
    "        original_vowel_shape = vowel2Cardinal3[viseme_list[i]]\n",
    "        only_peaks = np.where(vowel_mod_out_coarse > 0.75, vowel_mod_out_coarse, 0)\n",
    "        vowel_sounds_like = np.argmax(only_peaks, axis=1)\n",
    "        ##################################################################\n",
    "        ### obtain the intervals of which cardinal vowels are dominant ###\n",
    "        ##################################################################\n",
    "        cardinal_list = []\n",
    "        cardinal_intervals = []\n",
    "        current_interval_start = 0\n",
    "        current_vowel = original_vowel_shape\n",
    "        for t in range(0, vowel_sounds_like.shape[0]):\n",
    "            if vowel_sounds_like[t] == current_vowel:\n",
    "                if (t == vowel_sounds_like.shape[0]-1) and current_vowel != 3:\n",
    "                    cardinal_list.append(current_vowel)\n",
    "                    cardinal_intervals.append([current_interval_start, t])\n",
    "            else:\n",
    "                if xs[t-1] - xs[current_interval_start] >= 0.1:\n",
    "                    if t > 0 and current_vowel != 3:\n",
    "                        cardinal_list.append(current_vowel)\n",
    "                        cardinal_intervals.append([current_interval_start, t-1])\n",
    "                    current_interval_start = t\n",
    "                    current_vowel = vowel_sounds_like[t]\n",
    "        ###########################################################################\n",
    "        ######### optionally additional smoothing are added to this here ##########      \n",
    "        ###########################################################################\n",
    "        cardinal_list_new = []\n",
    "        cardinal_intervals_new = []\n",
    "        j = 0\n",
    "        while j < len(cardinal_list):\n",
    "            step = 1\n",
    "            if j == len(cardinal_list) - 1:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append(cardinal_intervals[j])\n",
    "            elif cardinal_list[j] == cardinal_list[j+1] and xs[cardinal_intervals[j+1][0]] - xs[cardinal_intervals[j][1]] <= spike_width:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append([cardinal_intervals[j][0], cardinal_intervals[j+1][1]])\n",
    "                step = 2\n",
    "            elif j < len(cardinal_list) - 2:\n",
    "                if (cardinal_list[j] == cardinal_list[j+2] and xs[cardinal_intervals[j+2][0]] - xs[cardinal_intervals[j][1]] <= spike_width \n",
    "                    and cardinal_list[j+1] == original_vowel_shape):\n",
    "                    cardinal_list_new.append(cardinal_list[j])\n",
    "                    cardinal_intervals_new.append([cardinal_intervals[j][0], cardinal_intervals[j+2][1]])\n",
    "                    step = 3\n",
    "            else:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append(cardinal_intervals[j])\n",
    "            j = j + step\n",
    "        cardinal_list = cardinal_list_new\n",
    "        cardinal_intervals = cardinal_intervals_new\n",
    "        # now set pucker/stretch values based on the detected sound\n",
    "        for c in range(0, len(cardinal_list)):\n",
    "            if original_vowel_shape == cardinal_list[c] or cardinal_list[c] == 3:\n",
    "                continue\n",
    "            else:\n",
    "                max_prob = coarse_vowel_sounds_like_interp(xs[cardinal_intervals[c][0]:cardinal_intervals[c][1]+1])[:, cardinal_list[c]].max()\n",
    "                \n",
    "                slider_ct_pts = control_direction_matrix_coarse[original_vowel_shape][cardinal_list[c]]\n",
    "                for s in range(0, int(len(slider_ct_pts)/3)):\n",
    "                    ctrl_pts = []\n",
    "                    # get the name and attribute of the slider\n",
    "                    slider_name = slider_ct_pts[0 + 3*s]\n",
    "                    if slider_name == \"self\":\n",
    "                        slider_name = viseme_list[i]\n",
    "                    slider_attribute = slider_ct_pts[1 + 3*s]\n",
    "                    # add a starting keyframe and ending keyframe\n",
    "                    modification_sliders.append([slider_name, slider_attribute])\n",
    "                    # the start of this curve should be earlier, e.g. at 75% of the previous interval\n",
    "                    # however, if the detected modification is at the very beginning of the vowel, then it is\n",
    "                    # applied the same time as the beginning of the vowel\n",
    "                    slider_range = slider_ct_pts[2 + 3*s]\n",
    "                    same_start = False\n",
    "                    start = -100\n",
    "                    \n",
    "                    if c == 0 : \n",
    "                        start = viseme_interval[i][0][0]\n",
    "                        same_start = True\n",
    "                    else:\n",
    "                        # otherwise I choose the starting point \n",
    "                        # find the previous c that is not the current vowel\n",
    "                        ci = -1\n",
    "                        for ccci in range(c-1, -1, -1):\n",
    "                            if original_vowel_shape != cardinal_list[ccci] and cardinal_list[ccci] != 3:\n",
    "                                ci = ccci\n",
    "                                break\n",
    "                        if ci > -1:\n",
    "#                             start_candidate = (xs[cardinal_intervals[ci][1]] - xs[cardinal_intervals[ci][0]]) * 0.6 + xs[cardinal_intervals[ci][0]]\n",
    "#                             start_candidate = min(start_candidate, xs[cardinal_intervals[c][0]]-0.12)\n",
    "                            start_candidate = xs[cardinal_intervals[ci][0]]-0.12\n",
    "                            start = max(start_candidate, viseme_interval[i][0][0])\n",
    "                            if np.abs(start - viseme_interval[i][0][0]) <= 0.2:\n",
    "                                start = viseme_interval[i][0][0]\n",
    "                                same_start = True\n",
    "                        else:\n",
    "                            start = viseme_interval[i][0][0]\n",
    "#                             start_candidate = xs[cardinal_intervals[ci][0]]-0.12\n",
    "#                             start = max(viseme_interval[i][0][0], start_candidate)\n",
    "#                             if viseme_interval[i][0][0] >= start_candidate:\n",
    "#                                 same_start = True\n",
    "#                             if np.abs(start - viseme_interval[i][0][0]) <= 0.2:\n",
    "#                                 start = viseme_interval[i][0][0]\n",
    "#                                 same_start = True\n",
    "\n",
    "                            \n",
    "                    ctrl_pts.append([start, slider_range[0]])\n",
    "                    # add the end point of the curve. This would either at the end of the \n",
    "                    # prediction interval, or at the end of the vowel. \n",
    "#                     modification_sliders.append([slider_name, slider_attribute])\n",
    "                    ci = -1\n",
    "                    for ccci in range(c+1, len(cardinal_intervals)):\n",
    "                        if original_vowel_shape != cardinal_list[ccci] and cardinal_list[ccci] != 3:\n",
    "                            ci = ccci\n",
    "                            break\n",
    "                    if ci == -1:\n",
    "                        ctrl_pts.append([viseme_interval[i][-1][0], slider_range[0]])\n",
    "                    else:\n",
    "                        ctrl_pts.append([xs[cardinal_intervals[c][1]] + 0.12, slider_range[0]])\n",
    "        \n",
    "                    # add the peaks in the middle with the decay\n",
    "                    \n",
    "#                     modification_sliders.append([slider_name, slider_attribute])\n",
    "                    # with some anticipation \n",
    "                    if same_start:\n",
    "                        ctrl_pts.append([viseme_interval[i][1][0], max_prob * (slider_range[1])])\n",
    "                    else:\n",
    "                        if slider_name == \"Dimple\":\n",
    "                            print(xs[cardinal_intervals[c][0]])\n",
    "                        ctrl_pts.append([xs[cardinal_intervals[c][0]], max_prob * (slider_range[1])])\n",
    "#                     modification_sliders.append([slider_name, slider_attribute])\n",
    "                    end_p75 = (xs[cardinal_intervals[c][1]] - xs[cardinal_intervals[c][0]]) * 0.75 + xs[cardinal_intervals[c][0]]\n",
    "                    ctrl_pts.append([end_p75, max_prob * (slider_range[1]) * 0.75])\n",
    "                    modification_ctrl_pts.append(ctrl_pts)\n",
    "modification_ctrl_pts_sing = copy.deepcopy(modification_ctrl_pts)\n",
    "modification_sliders_sing = copy.deepcopy(modification_sliders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0276294e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.265833, 0], [5.385833, 8.923359096050262], [6.692949721893491, 6.692519322037697], [7.094945, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a0d09ad2b0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(0, len(modification_sliders_sing)):\n",
    "    if modification_sliders_sing[i][0] == \"Dimple\":\n",
    "        modification_ctrl_pts_sing[i].sort(key=lambda x:x[0])\n",
    "        print(modification_ctrl_pts_sing[i])\n",
    "        for l in range(0, len(modification_ctrl_pts_sing[i])):\n",
    "            x.append(modification_ctrl_pts_sing[i][l][0])\n",
    "            y.append(modification_ctrl_pts_sing[i][l][1])\n",
    "#             xs.append(modification_ctrl_pts[i][l][0])\n",
    "#             ys.append(modification_ctrl_pts[i][l][1])\n",
    "plt.plot(np.array(x), np.array(y))\n",
    "plt.plot(np.array(xs), np.array(ys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aea24984",
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_ctpt_temp = copy.deepcopy(modification_ctrl_pts_sing)\n",
    "vm_slider_temp = copy.deepcopy(modification_sliders_sing) # these are references\n",
    "# pass 3\n",
    "# set this up\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(vm_slider_temp)):\n",
    "    prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]] = -1\n",
    "modification_ctrl_pts = copy.deepcopy(modification_ctrl_pts_sing) # output is stored here\n",
    "modification_sliders = copy.deepcopy(modification_sliders_sing)\n",
    "i = 0  \n",
    "while i < len(modification_ctrl_pts):\n",
    "    increment = 1\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]] != -1:\n",
    "        prev_i = prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]]\n",
    "        current_interval = copy.deepcopy(vm_ctpt_temp[i])\n",
    "        current_interval.sort(key=lambda x:x[0])\n",
    "        prev_interval = copy.deepcopy(vm_ctpt_temp[prev_i])\n",
    "        prev_interval.sort(key=lambda x:x[0])\n",
    "        # For the same vowel/consonant if the two intervals do not overlap but the onset and off set overlap \n",
    "        if (current_interval[0][0] - prev_interval[-1][0]) <= vowel_blend_distance:\n",
    "            # if we have weird overlap where the boundary of the previous interval interupts the curve of the current\n",
    "#             if prev_interval[2][0] - prev_interval[1][0] <= speech_vowel_threshold:\n",
    "#                 prev_interval[2][1] = 0.95 * prev_interval[1][1]\n",
    "            if current_interval[1][0] <= prev_interval[-1][0] and current_interval[0][0] <= prev_interval[-2][0]:\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                modification_ctrl_pts[prev_i] = copy.deepcopy(temp)\n",
    "                current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                modification_ctrl_pts[i] =  copy.deepcopy(current_interval)\n",
    "            elif (current_interval[1][0] <= prev_interval[-1][0]):\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = current_interval[0][0]\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = temp\n",
    "                modification_ctrl_pts[prev_i] = copy.deepcopy(temp)\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "                modification_ctrl_pts[i] =  copy.deepcopy(current_interval)\n",
    "            elif (current_interval[0][0] <= prev_interval[-2][0]):\n",
    "                temp = copy.deepcopy(current_interval)\n",
    "                temp[0][0] = prev_interval[-1][0]\n",
    "                temp[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                modification_ctrl_pts[prev_i][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.add(viseme_list_final[i], temp, pure_phoneme_list[i])\n",
    "                modification_ctrl_pts[i] =  copy.deepcopy(temp)\n",
    "            else:\n",
    "                if pure_phoneme_list[i] in cmu_sets.lip_closer:\n",
    "                    pass\n",
    "#                     visemes_sing.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "                else:\n",
    "                    temp = copy.deepcopy(prev_interval)\n",
    "                    temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                     visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = copy.deepcopy(temp)\n",
    "                    modification_ctrl_pts[prev_i] = copy.deepcopy(temp)\n",
    "                    current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                     visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "                    modification_ctrl_pts[i] =  copy.deepcopy(current_interval)        \n",
    "    prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]] = i\n",
    "    i = i + increment\n",
    "modification_ctrl_pts_sing = copy.deepcopy(modification_ctrl_pts)\n",
    "modification_sliders_sing = copy.deepcopy(modification_sliders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68b472c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viseme_list = visemes_speak.viseme_list[-1]\n",
    "viseme_interval = visemes_speak.viseme_ctrl_pts[-1]\n",
    "\n",
    "modification_ctrl_pts = []\n",
    "modification_sliders = []\n",
    "# iterate through the vowels in the list\n",
    "dt = 0.01\n",
    "for i in range(0, len(viseme_list)):\n",
    "    if viseme_list[i] in VOWELS_SLIDERS_JALI and viseme_interval[i][-2][0] - viseme_interval[i][0][0] > 0.30:\n",
    "        ##################################################################\n",
    "        ###################### get the audio signal ######################\n",
    "        ##################################################################\n",
    "        vowel_mod_out, vowel_mod_out_coarse = vowel_mod(lyric.sound_arr_interp(np.arange(viseme_interval[i][1][0], \n",
    "                                                                                        min(viseme_interval[i][-1][0], lyric.snd.xs()[-1]), 1.0/44100.0)))\n",
    "#         print([\"A\", \"Stretcher\", \"Rounder\", \"Silence\"][vowel2Cardinal3[viseme_list[i]]])\n",
    "        if  vowel_mod_out_coarse.shape[0] <= 10:\n",
    "            continue\n",
    "        xs = np.linspace(viseme_interval[i][1][0], min(viseme_interval[i][-1][0], lyric.snd.xs()[-1]), vowel_mod_out_coarse.shape[0])\n",
    "        coarse_vowel_sounds_like_interp = interp1d(xs, vowel_mod_out_coarse, axis=0)\n",
    "        \n",
    "#         for i in range(0, 4):\n",
    "#             plt.plot(vowel_mod_out_coarse[:, i], label=[\"Ah\", \"stretcher\", \"rounder\", \"silence\"][i])\n",
    "# #         plt.plot(np.argmax(out[0, :], axis=1))\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        \n",
    "        # what the original sound was\n",
    "        original_vowel_shape = vowel2Cardinal3[viseme_list[i]]\n",
    "        only_peaks = np.where(vowel_mod_out_coarse > 0.75, vowel_mod_out_coarse, 0)\n",
    "        vowel_sounds_like = np.argmax(only_peaks, axis=1)\n",
    "        ##################################################################\n",
    "        ### obtain the intervals of which cardinal vowels are dominant ###\n",
    "        ##################################################################\n",
    "        cardinal_list = []\n",
    "        cardinal_intervals = []\n",
    "        current_interval_start = 0\n",
    "        current_vowel = original_vowel_shape\n",
    "        for t in range(0, vowel_sounds_like.shape[0]):\n",
    "            if vowel_sounds_like[t] == current_vowel:\n",
    "                if (t == vowel_sounds_like.shape[0]-1) and current_vowel != 3:\n",
    "                    cardinal_list.append(current_vowel)\n",
    "                    cardinal_intervals.append([current_interval_start, t])\n",
    "            else:\n",
    "                if xs[t-1] - xs[current_interval_start] >= 0.1:\n",
    "                    if t > 0 and current_vowel != 3:\n",
    "                        cardinal_list.append(current_vowel)\n",
    "                        cardinal_intervals.append([current_interval_start, t-1])\n",
    "                    current_interval_start = t\n",
    "                    current_vowel = vowel_sounds_like[t]\n",
    "        ###########################################################################\n",
    "        ######### optionally additional smoothing are added to this here ##########      \n",
    "        ###########################################################################\n",
    "        cardinal_list_new = []\n",
    "        cardinal_intervals_new = []\n",
    "        j = 0\n",
    "        while j < len(cardinal_list):\n",
    "            step = 1\n",
    "            if j == len(cardinal_list) - 1:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append(cardinal_intervals[j])\n",
    "            elif cardinal_list[j] == cardinal_list[j+1] and xs[cardinal_intervals[j+1][0]] - xs[cardinal_intervals[j][1]] <= spike_width:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append([cardinal_intervals[j][0], cardinal_intervals[j+1][1]])\n",
    "                step = 2\n",
    "            elif j < len(cardinal_list) - 2:\n",
    "                if (cardinal_list[j] == cardinal_list[j+2] and xs[cardinal_intervals[j+2][0]] - xs[cardinal_intervals[j][1]] <= spike_width \n",
    "                    and cardinal_list[j+1] == original_vowel_shape):\n",
    "                    cardinal_list_new.append(cardinal_list[j])\n",
    "                    cardinal_intervals_new.append([cardinal_intervals[j][0], cardinal_intervals[j+2][1]])\n",
    "                    step = 3\n",
    "            else:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append(cardinal_intervals[j])\n",
    "            j = j + step\n",
    "        cardinal_list = cardinal_list_new\n",
    "        cardinal_intervals = cardinal_intervals_new\n",
    "#         print(cardinal_list, cardinal_intervals)\n",
    "        # now set pucker/stretch values based on the detected sound\n",
    "        for c in range(0, len(cardinal_list)):\n",
    "            if original_vowel_shape == cardinal_list[c] or cardinal_list[c] == 3:\n",
    "                continue\n",
    "            else:\n",
    "                max_prob = coarse_vowel_sounds_like_interp(xs[cardinal_intervals[c][0]:cardinal_intervals[c][1]+1])[:, cardinal_list[c]].max()\n",
    "                \n",
    "                slider_ct_pts = control_direction_matrix_coarse[original_vowel_shape][cardinal_list[c]]\n",
    "                for s in range(0, int(len(slider_ct_pts)/3)):\n",
    "                    ctrl_pts = []\n",
    "                    # get the name and attribute of the slider\n",
    "                    slider_name = slider_ct_pts[0 + 3*s]\n",
    "                    if slider_name == \"self\":\n",
    "                        slider_name = viseme_list[i]\n",
    "                    slider_attribute = slider_ct_pts[1 + 3*s]\n",
    "                    slider_range = slider_ct_pts[2 + 3*s]\n",
    "                    # add a starting keyframe and ending keyframe\n",
    "                    modification_sliders.append([slider_name, slider_attribute])\n",
    "                    # the start of this curve should be earlier, e.g. at 75% of the previous interval\n",
    "                    # however, if the detected modification is at the very beginning of the vowel, then it is\n",
    "                    # applied the same time as the beginning of the vowel\n",
    "                    same_start = False\n",
    "                    if c == 0 : \n",
    "                        start = viseme_interval[i][0][0]\n",
    "                        same_start = True\n",
    "                    else:\n",
    "                        # otherwise I choose the starting point \n",
    "                        # find the previous c that is not the current vowel\n",
    "                        ci = -1\n",
    "                        for ccci in range(c-1, -1, -1):\n",
    "                            if original_vowel_shape != cardinal_list[ccci] and cardinal_list[ccci] != 3:\n",
    "                                ci = ccci\n",
    "                                break\n",
    "                        if ci > -1:\n",
    "#                             start_candidate = (xs[cardinal_intervals[ci][1]] - xs[cardinal_intervals[ci][0]]) * 0.6 + xs[cardinal_intervals[ci][0]]\n",
    "#                             start_candidate = min(start_candidate, xs[cardinal_intervals[c][0]]-0.12)\n",
    "                            start_candidate = xs[cardinal_intervals[ci][0]]-0.12\n",
    "                            if viseme_interval[i][0][0] >= start_candidate:\n",
    "                                same_start = True\n",
    "                            start = max(start_candidate, viseme_interval[i][0][0])\n",
    "                            if np.abs(start - viseme_interval[i][0][0]) <= 0.2:\n",
    "                                start = viseme_interval[i][0][0]\n",
    "                                same_start = True\n",
    "                        else:\n",
    "                            start_candidate = xs[cardinal_intervals[ci][0]]-0.12\n",
    "#                             start = max(viseme_interval[i][0][0], start_candidate)\n",
    "                            start = viseme_interval[i][0][0]\n",
    "#                             if np.abs(start - viseme_interval[i][0][0]) <= 0.2:\n",
    "#                                 start = viseme_interval[i][0][0]\n",
    "#                                 same_start = True\n",
    "                    ctrl_pts.append([start, slider_range[0]])\n",
    "                    # add the end point of the curve. This would either at the end of the \n",
    "                    # prediction interval, or at the end of the vowel. \n",
    "#                     modification_sliders.append([slider_name, slider_attribute])\n",
    "                    if c < len(cardinal_list) - 1:\n",
    "                        ctrl_pts.append([xs[cardinal_intervals[c][1]] + 0.12, slider_range[0]])\n",
    "                    else:\n",
    "                        ctrl_pts.append([viseme_interval[i][-1][0], slider_range[0]])        \n",
    "                    # add the peaks in the middle with the decay\n",
    "#                     modification_sliders.append([slider_name, slider_attribute])\n",
    "                    # with some anticipation \n",
    "#                     print(slider_name, max_prob, slider_range[1])\n",
    "                    if same_start:\n",
    "                        ctrl_pts.append([viseme_interval[i][1][0], max_prob * (slider_range[1])])\n",
    "                    else:\n",
    "                        ctrl_pts.append([xs[cardinal_intervals[c][0]], max_prob * (slider_range[1])])\n",
    "#                     modification_sliders.append([slider_name, slider_attribute])\n",
    "                    end_p75 = (xs[cardinal_intervals[c][1]] - xs[cardinal_intervals[c][0]]) * 0.75 + xs[cardinal_intervals[c][0]]\n",
    "                    ctrl_pts.append([end_p75, max_prob * (slider_range[1]) * 0.75])\n",
    "                    if slider_name == \"Pucker\":\n",
    "                        print(slider_name, ctrl_pts)\n",
    "                        print(cardinal_list)\n",
    "                    \n",
    "                    modification_ctrl_pts.append(ctrl_pts)\n",
    "modification_ctrl_pts_speak = copy.deepcopy(modification_ctrl_pts)\n",
    "modification_sliders_speak = copy.deepcopy(modification_sliders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "711a085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_ctpt_temp = copy.deepcopy(modification_ctrl_pts_speak)\n",
    "vm_slider_temp = copy.deepcopy(modification_sliders_speak) # these are references\n",
    "# pass 3\n",
    "# set this up\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(vm_slider_temp)):\n",
    "    prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]] = -1\n",
    "modification_ctrl_pts = copy.deepcopy(modification_ctrl_pts_speak) # output is stored here\n",
    "modification_sliders = copy.deepcopy(modification_sliders_speak)\n",
    "i = 0  \n",
    "while i < len(modification_ctrl_pts):\n",
    "    increment = 1\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]] != -1:\n",
    "        prev_i = prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]]\n",
    "        current_interval = copy.deepcopy(vm_ctpt_temp[i])\n",
    "        current_interval.sort(key=lambda x:x[0])\n",
    "        prev_interval = copy.deepcopy(vm_ctpt_temp[prev_i])\n",
    "        prev_interval.sort(key=lambda x:x[0])\n",
    "        # For the same vowel/consonant if the two intervals do not overlap but the onset and off set overlap \n",
    "        if (current_interval[0][0] - prev_interval[-1][0]) <= vowel_blend_distance:\n",
    "            # if we have weird overlap where the boundary of the previous interval interupts the curve of the current\n",
    "#             if prev_interval[2][0] - prev_interval[1][0] <= speech_vowel_threshold:\n",
    "#                 prev_interval[2][1] = 0.95 * prev_interval[1][1]\n",
    "            if current_interval[1][0] <= prev_interval[-1][0] and current_interval[0][0] <= prev_interval[-2][0]:\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                modification_ctrl_pts[prev_i] = copy.deepcopy(temp)\n",
    "                current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                modification_ctrl_pts[i] =  copy.deepcopy(current_interval)\n",
    "            elif (current_interval[1][0] <= prev_interval[-1][0]):\n",
    "                temp = copy.deepcopy(prev_interval)\n",
    "                temp[-1][0] = current_interval[0][0]\n",
    "                temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = temp\n",
    "                modification_ctrl_pts[prev_i] = copy.deepcopy(temp)\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "                modification_ctrl_pts[i] =  copy.deepcopy(current_interval)\n",
    "            elif (current_interval[0][0] <= prev_interval[-2][0]):\n",
    "                temp = copy.deepcopy(current_interval)\n",
    "                temp[0][0] = prev_interval[-1][0]\n",
    "                temp[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "                modification_ctrl_pts[prev_i][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                 visemes_sing.add(viseme_list_final[i], temp, pure_phoneme_list[i])\n",
    "                modification_ctrl_pts[i] =  copy.deepcopy(temp)\n",
    "            else:\n",
    "                if pure_phoneme_list[i] in cmu_sets.lip_closer:\n",
    "#                     visemes_sing.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "                    pass\n",
    "                else:\n",
    "                    temp = copy.deepcopy(prev_interval)\n",
    "                    temp[-1][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    temp[-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                     visemes_sing.viseme_ctrl_pts[-1][prev_slider_dict[viseme_list_final[i]]] = copy.deepcopy(temp)\n",
    "                    modification_ctrl_pts[prev_i] = copy.deepcopy(temp)\n",
    "                    current_interval[0][0] = (current_interval[0][0] + prev_interval[-1][0]) / 2.0\n",
    "                    current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * vowel_blend_magnitude\n",
    "#                     visemes_sing.add(viseme_list_final[i], current_interval, pure_phoneme_list[i])\n",
    "                    modification_ctrl_pts[i] =  copy.deepcopy(current_interval)        \n",
    "    prev_slider_dict[vm_slider_temp[i][0]+vm_slider_temp[i][1]] = i\n",
    "    i = i + increment\n",
    "modification_ctrl_pts_speak = copy.deepcopy(modification_ctrl_pts)\n",
    "modification_sliders_speak = copy.deepcopy(modification_sliders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7afab",
   "metadata": {},
   "source": [
    "## Larynx movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bbbab84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# viseme_list = visemes_sing.viseme_list[-1]\n",
    "# viseme_ctrl_pts = visemes_sing.viseme_ctrl_pts[-1]\n",
    "larynx_movements_ct_pts = []\n",
    "# extended_vowel_intervals = []\n",
    "# extended_vowel_list = []\n",
    "in_between = False\n",
    "pitch_change_intervals = []\n",
    "for i in range(0, len(extended_vowel_list)):\n",
    "    viseme = extended_vowel_list[i]\n",
    "    if len(viseme) > 13 and viseme[-13:] == \"_pitch_change\":\n",
    "        viseme = viseme[:-13]\n",
    "        in_between = True\n",
    "    else:\n",
    "        in_between = False\n",
    "        \n",
    "    if not in_between:\n",
    "        if len(pitch_change_intervals) == 0:\n",
    "            curve = extended_vowel_intervals[i]\n",
    "            val = 2\n",
    "            throat_curve = generate_basic_viseme_curve(curve[0], curve[1], val, sustain=0.75, decay = 0.95, onset=0.12, offset=0.12)\n",
    "            larynx_movements_ct_pts.append(throat_curve)\n",
    "            \n",
    "        else:\n",
    "            throat_curve = []\n",
    "            # add the onset\n",
    "            throat_curve.append([pitch_change_intervals[0][0]-0.12, 0])\n",
    "            for m in range(0, len(pitch_change_intervals)):\n",
    "                val = 2\n",
    "                throat_curve.append([pitch_change_intervals[m][0], val])\n",
    "                throat_curve.append([(pitch_change_intervals[m][1] - \n",
    "                                      pitch_change_intervals[m][0]) * 0.8 + pitch_change_intervals[m][0], val*0.9])\n",
    "            throat_curve.append([pitch_change_intervals[-1][1]+0.12, 0])\n",
    "            pitch_change_intervals = []\n",
    "            in_between = False\n",
    "            larynx_movements_ct_pts.append(throat_curve)\n",
    "                \n",
    "    else:\n",
    "        curve = extended_vowel_intervals[i]\n",
    "        pitch_change_intervals.append(curve)\n",
    "        \n",
    "        \n",
    "\n",
    "x = []\n",
    "y = []\n",
    "larynx_movements_ct_pts.sort(key=lambda x:x[0])\n",
    "for i in range(0, len(larynx_movements_ct_pts)):\n",
    "    for k in range(0, len(larynx_movements_ct_pts[i])):\n",
    "        x.append(larynx_movements_ct_pts[i][k][0])\n",
    "        y.append(larynx_movements_ct_pts[i][k][1])\n",
    "plt.plot(np.array(x), np.array(y))\n",
    "plt.show()\n",
    "\n",
    "## remove overlap artifacts\n",
    "i = 0  \n",
    "while i < len(larynx_movements_ct_pts):\n",
    "    increment = 1\n",
    "    prev_viseme = viseme_list_final[i]\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if i >= 1:\n",
    "        current_interval = copy.deepcopy(larynx_movements_ct_pts[i])\n",
    "        prev_interval = copy.deepcopy(larynx_movements_ct_pts[i-1])\n",
    "        # For the same vowel/consonant if the two intervals do not overlap but the onset and off set overlap \n",
    "        if (current_interval[0][0] <= prev_interval[-1][0]):\n",
    "            # if we have weird overlap where the boundary of the previous interval interupts the curve of the current\n",
    "            if (current_interval[1][0] <= prev_interval[-1][0] and current_interval[0][0] <= prev_interval[-2][0]):\n",
    "                larynx_movements_ct_pts[i-1] = copy.deepcopy(prev_interval[:-1])\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.95\n",
    "                current_interval[0][0] = (current_interval[0][0] + prev_interval[-2][0]) / 2\n",
    "                larynx_movements_ct_pts[i] = current_interval\n",
    "            elif (current_interval[1][0] <= prev_interval[-1][0]):\n",
    "                larynx_movements_ct_pts[i-1] = copy.deepcopy(prev_interval[:-1])\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.95\n",
    "                current_interval[0][0] = (current_interval[0][0] + prev_interval[-2][0]) / 2\n",
    "                larynx_movements_ct_pts[i] = current_interval\n",
    "            elif (current_interval[0][0] <= prev_interval[-2][0]):\n",
    "                larynx_movements_ct_pts[i-1][-1][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.95\n",
    "                larynx_movements_ct_pts[i-1][-1][0] = (current_interval[0][0] + prev_interval[-2][0]) / 2\n",
    "                larynx_movements_ct_pts[i] = copy.deepcopy(current_interval[1:])\n",
    "            else:\n",
    "                larynx_movements_ct_pts[i-1] = copy.deepcopy(prev_interval[:-1])\n",
    "                current_interval[0][0] = (current_interval[0][0] + prev_interval[-2][0]) / 2.0\n",
    "                current_interval[0][1] = min(current_interval[1][1], prev_interval[-2][1]) * 0.95\n",
    "                larynx_movements_ct_pts[i] = current_interval\n",
    "        # if the two interval overlaps\n",
    "        elif (current_interval[1][0] <= prev_interval[-2][0]):\n",
    "            interval = prev_interval[0:-2] + current_interval[1:]\n",
    "            larynx_movements_ct_pts[i-1] = copy.deepcopy(interval)\n",
    "#         else:\n",
    "#             visemes_speak.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "    else:        \n",
    "#         visemes_speak.add(viseme_list_final[i], viseme_intervals_final[i], pure_phoneme_list[i])\n",
    "        pass\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c1a21",
   "metadata": {},
   "source": [
    "## Output 1 Marking all the boundary points accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad642095",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Pnot_viseme_list = []\n",
    "M_Pnot_viseme_ctrl_pts = []\n",
    "M_P_viseme_list = []\n",
    "M_P_viseme_ctrl_pts = []\n",
    "Mnot_Pnot_viseme_list = []\n",
    "Mnot_Pnot_viseme_ctrl_pts = []\n",
    "Mnot_P_viseme_list = []\n",
    "Mnot_P_viseme_ctrl_pts = []\n",
    "\n",
    "for i in range(0, len(visemes_sing.viseme_list[-1])):\n",
    "    M_Pnot_viseme_list.append(visemes_sing.viseme_list[-1][i])\n",
    "    Mnot_P_viseme_list.append(visemes_sing.viseme_list[-1][i])\n",
    "    Mnot_Pnot_viseme_list.append(visemes_sing.viseme_list[-1][i])\n",
    "    M_P_viseme_list.append(visemes_sing.viseme_list[-1][i])\n",
    "    ########################################################################\n",
    "    # M and Pnot => boundary from visemes_sing + internal from visemes_speak\n",
    "    ########################################################################\n",
    "    interval = []\n",
    "    for item in visemes_speak.viseme_ctrl_pts[-1][i]:\n",
    "        if item[2] == \"internal\":\n",
    "            interval.append([item[0], item[1]])\n",
    "    for item in visemes_sing.viseme_ctrl_pts[-1][i]:\n",
    "        if item[2] == \"bound\":\n",
    "            interval.append([item[0], item[1]])\n",
    "    M_Pnot_viseme_ctrl_pts.append(interval)\n",
    "    ##########################################################################\n",
    "    # M not and P => boundary from visemes_speak + internal from visemes_sing#\n",
    "    ##########################################################################\n",
    "    interval = []\n",
    "    for item in visemes_sing.viseme_ctrl_pts[-1][i]:\n",
    "        if item[2] == \"internal\":\n",
    "            interval.append([item[0], item[1]])\n",
    "    for item in visemes_speak.viseme_ctrl_pts[-1][i]:\n",
    "        if item[2] == \"bound\":\n",
    "            interval.append([item[0], item[1]])\n",
    "    \n",
    "    Mnot_P_viseme_ctrl_pts.append(interval)\n",
    "    ##########################################################################\n",
    "    # M not and P not => boundary from visemes_speak + internal from visemes_speak\n",
    "    ##########################################################################\n",
    "    interval = []\n",
    "    for item in visemes_speak.viseme_ctrl_pts[-1][i]:\n",
    "        interval.append([item[0], item[1]])\n",
    "    Mnot_Pnot_viseme_ctrl_pts.append(interval)\n",
    "    ##########################################################################\n",
    "    # M and P => boundary from visemes_speak + internal from visemes_sing\n",
    "    ##########################################################################\n",
    "    interval = []\n",
    "    for item in visemes_sing.viseme_ctrl_pts[-1][i]:\n",
    "        interval.append([item[0], item[1]])\n",
    "    M_P_viseme_ctrl_pts.append(interval)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b7b3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\"M_Pnot_viseme\":[M_Pnot_viseme_list, M_Pnot_viseme_ctrl_pts],\n",
    "         \"M_P_viseme\":[M_P_viseme_list, M_P_viseme_ctrl_pts],\n",
    "         \"Mnot_Pnot_viseme\":[Mnot_Pnot_viseme_list, Mnot_Pnot_viseme_ctrl_pts],\n",
    "         \"Mnot_P_viseme\":[Mnot_P_viseme_list, Mnot_P_viseme_ctrl_pts],\n",
    "#         \"brow\":[brow_movement, brow_ctrl_points, finer_brow_raise_ctrl_points, finer_brow_furrow_ctrl_points],\n",
    "         \n",
    "#         \"blink\":[eye_movement, eye_ctrl_points],\n",
    "        \"vowel_mod_M\": [modification_sliders_sing, modification_ctrl_pts_sing],\n",
    "        \"vowel_mod_M_not\": [modification_sliders_speak, modification_ctrl_pts_speak],\n",
    "        \"throat\": larynx_movements_ct_pts,\n",
    "        \"jaw\":[[0, 6]],\n",
    "        \"lip\":[[0, 6]], \n",
    "        \"vib\":vib_ctrl_pts}\n",
    "jsonoutput = json.dumps(output)\n",
    "with open(os.path.join(dir, file_name_template + \"_\" + output_template + '.json'), 'w') as outfile:\n",
    "    json.dump(jsonoutput, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb83ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8e726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "visemenet",
   "language": "python",
   "name": "visemenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
