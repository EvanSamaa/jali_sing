{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.SongDataStructure import *\n",
    "from util.pitch_interval_estimation import *\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from models.vowel_modification_detector import vowel_mod_detector\n",
    "vowel_mod = vowel_mod_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"E:/MASC/Structured_data/rolling_in_the_deep_adele\"\n",
    "file_name_template = \"audio\"\n",
    "script_path = os.path.join(dir, \"audio_full.TextGrid\")\n",
    "output_template = \"jali_sing_2\"\n",
    "spike_width = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicionaries and Constants and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOICED = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW', \"ER\"])\n",
    "CMU2VISEME = {\"AA\":\"Ah\", \"AO\":\"Ah\", \"AY\":\"Ah\", \"AW\":\"Ah\",\"AE\":\"Aa\",\n",
    "              \"EY\":\"Aa\",\"UH\":\"Uh\", \"UW\":\"U\",\"IH\": \"Ih\",\"IY\": \"Ih\",\"EH\": \"Eh\",\"HH\": \"Eh\",\"UH\": \"Eh\",\"AH\": \"Eh\",\n",
    "              \"ER\": \"Eh\",\"OW\":\"Oo\",\"OY\":\"Oh\",\"R\":\"R\",\"D\":\"LNTD\",\"T\": \"LNTD\",\"L\":\"LNTD\",\"N\":\"LNTD\",\"NG\":\"LNTD\",\n",
    "              \"F\":\"FV\",\"V\":\"FV\",\"B\":\"BP\",\"M\":\"M\",\"P\":\"BP\",\"CH\":\"ShChZh\",\"SH\":\"ShChZh\",\"ZH\":\"ShChZh\",\n",
    "              \"S\": \"SZ\", \"Z\": \"SZ\",\"DH\":\"Th\", \"TH\":\"Th\",\"G\":\"GK\", \"K\":\"GK\",\"Y\":\"Y\",\"JH\":\"J\",\"W\":\"W\",}\n",
    "VOWELS_SLIDERS_JALI = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\"])\n",
    "CONSONANTS_SLIDERS_JALI = set([\"M_pointer\", \"BP_pointer\", \"JY_pointer\", \"Th_pointer\", \"ShChZh_pointer\", \"SZ_pointer\", \"GK_pointer\", \"LNTD_pointer\", \"R_pointer\", \"W_pointer\", \"FV_pointer\"])\n",
    "CONSONANTS_SLIDERS_NOJAW_JALI = set([\"Ya_pointer\", \"Ja_pointer\", \"Ra_pointer\", \"FVa_pointer\", \"LNTDa_pointer\", \"Ma_pointer\", \"BPa_pointer\", \"Wa_pointer\", \"Tha_pointer\", \"GKa_pointer\"])\n",
    "JALI_SLIDERS_SET = set.union(VOWELS_SLIDERS_JALI, CONSONANTS_SLIDERS_JALI, CONSONANTS_SLIDERS_NOJAW_JALI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMU_phonemes_dicts():\n",
    "    def __init__(self):\n",
    "        self.vocabs = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G',\n",
    "                  'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH',\n",
    "                  'UW', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "        self.vowels = set(['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', \n",
    "                  'IH', 'IY', 'OW', 'OY', 'UH', 'UW', ])\n",
    "        self.voiced = set(['M', 'N']).union(self.vowels)\n",
    "        self.consonants = set(['B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L', 'M', 'N', 'NG', \n",
    "                              'P', 'R', 'S', 'SH', 'T', 'TH', 'V', 'W', 'Y', 'Z', 'ZH'])\n",
    "        self.consonants_no_jaw = self.consonants\n",
    "        self.lip_closer = set([\"B\", \"F\", \"M\", \"P\", \"S\", \"V\"])\n",
    "        self.lip_rounder = set([\"B\", \"F\", \"M\", \"P\", \"V\"])\n",
    "        self.nasal_obtruents = set(['L', 'N', 'NG', 'T', 'D', 'G', 'K', 'F', 'V', 'M', 'B', 'P'])\n",
    "        self.fricative = set([\"S\", \"Z\", \"ZH\", \"SH\", \"CH\", \"F\", \"V\", 'TH'])\n",
    "        self.plosive = set([\"P\", \"B\", \"D\", \"T\", \"K\", \"G\"])\n",
    "        self.lip_heavy = set([\"W\", \"OW\", \"UW\", \"S\", \"Z\", \"Y\", \"JH\", \"OY\"])\n",
    "        self.sibilant = set([\"S\", \"Z\", \"SH\", \"CH\", \"ZH\"])\n",
    "class JALI_visemes_dicts():\n",
    "     def __init__(self):\n",
    "        self.vowels = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\"])\n",
    "        self.voiced = set(['Ih_pointer', 'Ee_pointer', 'Eh_pointer', 'Aa_pointer', 'U_pointer', 'Uh_pointer'\n",
    "                           , 'Oo_pointer', 'Oh_pointer', 'Schwa_pointer', 'Eu_pointer', \"Ah_pointer\", \"LNTD_pointer\", \"LNTDa_pointer\"])\n",
    "        self.consonants_no_jaw = set([\"Ya_pointer\", \"Ja_pointer\", \"Ra_pointer\", \"FVa_pointer\", \"LNTDa_pointer\", \"Ma_pointer\", \"BPa_pointer\", \"Wa_pointer\", \"Tha_pointer\", \"GKa_pointer\"])\n",
    "        self.consonants = set([\"M_pointer\", \"BP_pointer\", \"JY_pointer\", \"Th_pointer\", \"ShChZh_pointer\", \"SZ_pointer\", \"GK_pointer\", \"LNTD_pointer\", \"R_pointer\", \"W_pointer\", \"FV_pointer\"]) \n",
    "        self.lip_closer = set([\"M_pointer\", \"BP_pointer\", \"FV_pointer\", \"SZ_pointer\"])\n",
    "        self.lip_rounder = set([\"M_pointer\", \"BP_pointer\", \"FV_pointer\"])\n",
    "        self.vocabs = self.consonants.union(self.vowels).union(self.consonants_no_jaw)\n",
    "        self.sibilant = set([\"SZ_pointer\", \"ShChZh_pointer\"])\n",
    "        self.nasal_obtruents = set([\"LNTD_pointer\", \"GK_pointer\", \"FV_pointer\", \"M_pointer\", \"BP_pointer\"])\n",
    "        self.fricative = set([\"FV_pointer\", \"SZ_pointer\", \"ShChZh_pointer\", \"Th_pointer\"])\n",
    "        self.plosive = set([\"BP_pointer\", \"LNTDa_pointer\", \"GK_pointer\"])\n",
    "        self.lip_heavy = set([\"Oh_pointer\", \"W_pointer\", \"Wa_pointer\", \"U_pointer\", \"SZ_pointer\", \"JY_pointer\",\n",
    "                             \"Ya_pointer\", \"Ja_pointer\"])\n",
    "        self.lip_rounder_to_no_jaw_dict = {\"M_pointer\":\"Ma_pointer\", \"BP_pointer\":\"BPa_pointer\", \"FV_pointer\":\"FVa_pointer\"}\n",
    "cmu_sets = CMU_phonemes_dicts()\n",
    "jali_sets = JALI_visemes_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_basic_viseme_curve(start, end, value, sustain=1, decay = 0.75, onset=0.1, offset=0):\n",
    "    if end - start < 0.1:\n",
    "        end = start + 0.1\n",
    "    interval = []\n",
    "    interval.append([start-onset, 0])\n",
    "    # second point is when the belting starts \n",
    "    interval.append([start, 1 * value])\n",
    "    # third point emphasizes decay, it happens 75% down the interval\n",
    "    if sustain < 1:\n",
    "        interval.append([start + sustain * (end - start), decay * value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    elif sustain == 1:\n",
    "        interval.append([end, value])\n",
    "        # last point is where the furrowing ends\n",
    "        interval.append([end+offset, 0])\n",
    "    return interval\n",
    "def get_kth_neighbour(input_list, i, k):\n",
    "    if i+k < 0 or i+k >= len(input_list):\n",
    "        return None\n",
    "    return input_list[i+k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tanh function to get a smooth curve\n",
    "def Viseme_A(peak=None, lowest=None):\n",
    "    if not peak is None:\n",
    "        total = np.log((1+peak)/(1-peak))/2\n",
    "        b = np.log((1+lowest)/(1-lowest))/2\n",
    "        a = total-b\n",
    "    else:\n",
    "        peak = 0.99\n",
    "        lowest = 0.4\n",
    "        total = np.log((1+peak)/(1-peak))/2\n",
    "        b = np.log((1+lowest)/(1-lowest))/2\n",
    "        a = total-b\n",
    "    def fn(val, val_max, val_min, max_val = 10):\n",
    "        val = (val - val_min) / (val_max - val_min)\n",
    "#         print(val)\n",
    "#         return (lowest + val * ((peak - lowest)))*max_val\n",
    "        return np.tanh((val)*a+b) * max_val\n",
    "#         return (np.exp(val * 8)/np.exp(8) * (peak-lowest) + lowest) * max_val\n",
    "    return fn\n",
    "viseme_A = Viseme_A()\n",
    "# plt.plot(np.arange(0, 1, 0.01), viseme_A(np.arange(0, 1, 0.01), 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load file for Jali\n",
    "lyric = Minimal_song_data_structure(os.path.join(dir, file_name_template+\".wav\"), os.path.join(dir, file_name_template+\".txt\"),\n",
    "                                                                                             script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# break the thing into sentence structures (if possible)\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "for i in range(0, len(lyric.phoneme_list)):\n",
    "    if lyric.phoneme_list[i] == \"EOS_tag\":\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "    else:\n",
    "        current_sentence.append(i)\n",
    "        if i == len(lyric.phoneme_list) - 1:\n",
    "            sentences.append(current_sentence)\n",
    "sentences = sentences[1:] \n",
    "# sentence stores the indexes\n",
    "if len(sentences) == 0:\n",
    "    sentences = [list(range(0, len(lyric.phoneme_list)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneme_list = lyric.phoneme_list\n",
    "phoneme_interval = lyric.phoneme_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass 1, Determine Animation Curve for all the vowels (without consideration for co-articulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EVANSA~1\\AppData\\Local\\Temp/ipykernel_3760/1123883530.py:48: RuntimeWarning: Mean of empty slice.\n",
      "  yf[vib_int[0]:vib_int[1]] = yf[vib_int[0]:vib_int[1]].mean()\n",
      "C:\\Users\\evansamaa\\anaconda3\\envs\\visemenet\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.818715490399587\n",
      "3.8207154903995866\n"
     ]
    }
   ],
   "source": [
    "# animate only vowels and see how it goes\n",
    "viseme_list = []\n",
    "viseme_intervals = []\n",
    "pure_phoneme_list = []\n",
    "max_activation = 8\n",
    "# threshold_slope = 200 # for formants\n",
    "threshold_slope = 80 # for pitch\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence_pitch_x, sentence_pitch_y = lyric.get_f_interval([phoneme_interval[sentence[0]][0], \n",
    "                                                               phoneme_interval[sentence[-1]][1]])\n",
    "    sentence_percentiles = np.nanpercentile(sentence_pitch_y, [5, 95])\n",
    "    sentence_mean = sentence_pitch_y.mean()\n",
    "    sentence_min = sentence_percentiles[0]\n",
    "    sentence_max = sentence_percentiles[1]\n",
    "    for i in range(0, len(sentence)):\n",
    "        # skip the misc symbols in the sentence\n",
    "        if phoneme_list[sentence[i]] != \"EOL_tag\" and phoneme_list[sentence[i]] != \">\":\n",
    "            pure_phoneme_list.append(phoneme_list[sentence[i]])\n",
    "        if phoneme_list[sentence[i]] in VOICED:\n",
    "            xI, yI = lyric.get_I_interval(phoneme_interval[sentence[i]])\n",
    "            xf, yf = lyric.get_f_interval(phoneme_interval[sentence[i]])\n",
    "            xF, yF = lyric.get_F1_interval(phoneme_interval[sentence[i]])\n",
    "            length_of_interval = xI[-1] - xI[0] \n",
    "            if length_of_interval <= 0.30: # if the vowel is approximately a speech vowel, then it is handled like speech\n",
    "                onset = 0.12\n",
    "                offset = 0.12\n",
    "                if phoneme_list[sentence[i]] in cmu_sets.lip_heavy:\n",
    "                    onset = 0.16\n",
    "                    offset = 0.16\n",
    "                value = 7\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "                curve = generate_basic_viseme_curve(phoneme_interval[sentence[i]][0], phoneme_interval[sentence[i]][1], value, sustain=sustain, \n",
    "                                            decay = decay, onset=onset, offset=offset)\n",
    "                viseme_intervals.append(curve)\n",
    "                viseme_list.append(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\")\n",
    "            else:\n",
    "                onset = 0.12\n",
    "                offset = 0.12\n",
    "                if phoneme_list[sentence[i]] in cmu_sets.lip_heavy:\n",
    "                    onset = 0.16\n",
    "                    offset = 0.16\n",
    "                control_pts = []\n",
    "                vib = lyric.compute_vibrato_intervals(yf-savgol_filter(yf, 29, 1), xf, lyric.dt)\n",
    "                vib_interval_indexs = lyric.get_subarrays_indexes_from_time_interval(vib, xf)\n",
    "                for vib_int in vib_interval_indexs:\n",
    "                    yf[vib_int[0]:vib_int[1]] = yf[vib_int[0]:vib_int[1]].mean()\n",
    "                slopes_f, intervals_f = efficient_piece_wise_linear_intervals(xf, yf)\n",
    "                kpx_f, kpy_f = get_key_points(xf, yf, intervals_f, slopes_f)\n",
    "                # onset and offset of these would be the same as regular vowels \n",
    "                control_pts.append([phoneme_interval[sentence[i]][0] - onset, 0])\n",
    "                \n",
    "                # here I will determine the average pitch when singing this vowel. Which is used to \n",
    "                avg_pitch = 0\n",
    "                total_weight = 0\n",
    "                pitch_values = []\n",
    "                for si in range(0, len(slopes_f)):\n",
    "                    if abs(slopes_f[si]) <= threshold_slope:\n",
    "                        avg_pitch = avg_pitch + (yf[intervals_f[si][0]] * (intervals_f[si][1] - intervals_f[si][0]))\n",
    "                        pitch_values.append(yf[intervals_f[si][0]])\n",
    "                        total_weight = total_weight + (intervals_f[si][1] - intervals_f[si][0])\n",
    "                if avg_pitch == 0:\n",
    "                        avg_pitch = yf.mean()\n",
    "                        total_weight = 1\n",
    "                pitch_values = np.array(pitch_values)\n",
    "                avg_pitch = avg_pitch / total_weight\n",
    "                \n",
    "                # now find the first key point - i.e. the beginning of the first plateau\n",
    "                # the first key point is defined as the point where a plateau first appears \n",
    "                # it can also be the first point that reaches the same pitch as the first plateau\n",
    "                # this ensures that undetected vibrato will not mess up with the timing\n",
    "                # and cause the mouth to open too slowly \n",
    "                start = 0\n",
    "                for si in range(0, len(slopes_f)):\n",
    "                    if abs(slopes_f[si]) <= threshold_slope:\n",
    "                        interp_pitch = interp1d(kpx_f, kpy_f)\n",
    "                        start = si\n",
    "                        end_x_search = min(xf[intervals_f[si][0]], kpx_f[-1])\n",
    "                        begin_x_search = xf[intervals_f[0][0]]\n",
    "                        x_range = np.arange(begin_x_search, end_x_search, 0.01)\n",
    "                        f_range = interp_pitch(x_range)\n",
    "                        first_val = interp_pitch(xf[intervals_f[si][0]])\n",
    "                        for ssi in range(0, x_range.shape[0]-1):\n",
    "                            if ((f_range[ssi] < first_val) and  (f_range[ssi+1] >= first_val) \n",
    "                                or (f_range[ssi] >= first_val) and  (f_range[ssi+1] < first_val)):\n",
    "                                end_x_search = x_range[ssi]\n",
    "                                break\n",
    "                        val0 = viseme_A(yf[intervals_f[si][0]], yf.max(), min(yf.min(), sentence_mean))\n",
    "                        val1 = viseme_A((yf[intervals_f[si][1]] + yf[intervals_f[si][0]])/2, yf.max(), min(yf.min(), sentence_mean))\n",
    "\n",
    "#                         dif = (xf[intervals_f[si][1]] - end_x_search) * 0.7\n",
    "                        dif = max((xf[intervals_f[si][1]] - xf[intervals_f[si][0]]) * 0.8, xf[intervals_f[si][1]] - xf[intervals_f[si][0]]- 0.1)\n",
    "                        control_pts.append([end_x_search, val0])\n",
    "                        control_pts.append([xf[intervals_f[si][0]] + dif, val1])                 \n",
    "                        break\n",
    "                # now determine intermediate key-points that correlates with lipshape\n",
    "                # will not have any of these pts\n",
    "#                 for si in range(start+1, len(slopes_f)):\n",
    "#                     val0 = viseme_A(yf[intervals_f[si][0]], yf.max(), min(yf.min(), sentence_mean))\n",
    "#                     val1 = viseme_A((yf[intervals_f[si][1]] + yf[intervals_f[si][0]])/2, yf.max(), min(yf.min(), sentence_mean))\n",
    "#                     dif = max((xf[intervals_f[si][1]] - xf[intervals_f[si][0]]) * 0.8, xf[intervals_f[si][1]] - xf[intervals_f[si][0]]- 0.1)\n",
    "#                     if abs(slopes_f[si]) <= threshold_slope:\n",
    "#                         control_pts.append([xf[intervals_f[si][0]], val0])\n",
    "#                         control_pts.append([xf[intervals_f[si][0]] + dif, val1])\n",
    "                    \n",
    "                for si in range(len(slopes_f)-1, -1, -1):\n",
    "                    if abs(slopes_f[si]) <= threshold_slope:\n",
    "                        control_pts.append([xf[intervals_f[si][1]], viseme_A(yf[intervals_f[si][1]], \n",
    "                                                                             yf.max(), yf.min())])\n",
    "                        break\n",
    "                control_pts.append([phoneme_interval[sentence[i]][1] + offset, 0])\n",
    "                viseme_intervals.append(control_pts)\n",
    "                viseme_list.append(CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\")   \n",
    "                \n",
    "        ### Dealing with consonants here. I'm just going to insert them between without too much modification\n",
    "        ### it will about the same as pure Jali\n",
    "        elif phoneme_list[sentence[i]] in cmu_sets.consonants:\n",
    "            onset = 0.12\n",
    "            offset = 0.12\n",
    "            if CMU2VISEME[phoneme_list[sentence[i]]] in jali_sets.nasal_obtruents and phoneme_interval[sentence[i]][1] - phoneme_interval[sentence[i]][0] > 1/20:\n",
    "                viseme_jali = CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"\n",
    "            else:\n",
    "                if phoneme_list[sentence[i]] == \"HH\" or phoneme_list[sentence[i]] in cmu_sets.sibilant:\n",
    "                    viseme_jali = CMU2VISEME[phoneme_list[sentence[i]]] + \"_pointer\"\n",
    "                else:\n",
    "                    viseme_jali = CMU2VISEME[phoneme_list[sentence[i]]] + \"a_pointer\"\n",
    "            if viseme_jali in jali_sets.lip_heavy:\n",
    "                onset = 0.16\n",
    "                offset = 0.16\n",
    "            start = phoneme_interval[sentence[i]][0]\n",
    "            end = phoneme_interval[sentence[i]][1]\n",
    "            if (end - start) <= 0.1:\n",
    "                value = 6\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "            elif (end - start) <= 0.3:\n",
    "                value = 6\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "            else:\n",
    "                value = 8\n",
    "                sustain = 0.75\n",
    "                decay = 0.75\n",
    "            if phoneme_list[sentence[i]] in cmu_sets.lip_closer:\n",
    "                value = 10\n",
    "            viseme_curve = generate_basic_viseme_curve(start, end, value, sustain=sustain, decay=decay, onset=onset, offset=offset)\n",
    "            viseme_list.append(viseme_jali)\n",
    "            viseme_intervals.append(viseme_curve)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlap between visemes so that they are more fluid\n",
    "# for i in range(1, len(viseme_list)):\n",
    "#     # re-order all the clips so that \n",
    "#     if pure_phoneme_list[i] in cmu_sets.vowels:\n",
    "#         prev_vowel = -1\n",
    "#         for si in range(i-1, -1, -1):\n",
    "#             if pure_phoneme_list[si] in cmu_sets.vowels:\n",
    "#                 prev_vowel = si\n",
    "#                 break\n",
    "#         if prev_vowel > -1 and viseme_list[i] != viseme_list[prev_vowel]:\n",
    "#             interval_i = viseme_intervals[i]\n",
    "#             interval_i.sort(key=lambda x:x[0])\n",
    "#             interval_prev = viseme_intervals[prev_vowel]\n",
    "#             interval_prev.sort(key=lambda x:x[0])\n",
    "#             if interval_i[0][0] <= interval_prev[-1][0]:\n",
    "#                 # there is an overlap\n",
    "#                 interval_prev[-2][0] = interval_i[1][0]\n",
    "#                 interval_prev[-1][0] = interval_i[1][0] + 0.12\n",
    "#                 viseme_intervals[prev_vowel] = interval_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pass 2 for co-articupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce co-articulation rules of consonants\n",
    "viseme_list_final = []\n",
    "viseme_intervals_final = []\n",
    "pure_phoneme_list_final = []\n",
    "i = 0;\n",
    "\n",
    "while i < len(viseme_list):\n",
    "    increment = 1\n",
    "    i_next = min(i + 1, len(viseme_list)-1)\n",
    "    if (viseme_list[i_next] == viseme_list[i] and viseme_intervals[i][-1][0] >= viseme_intervals[i_next][0][0]):\n",
    "        # remove repeated vowels or consonants\n",
    "        viseme_list_final.append(viseme_list[i_next])\n",
    "        int_curr = viseme_intervals[i]\n",
    "        int_next = viseme_intervals[i_next]\n",
    "        viseme_interval = [int_curr[0], [int_curr[1][0], max(int_curr[1][1], int_next[1][1])], \n",
    "                           [int_next[2][0], max(int_curr[2][1], int_next[2][1])], int_next[3]]\n",
    "        viseme_intervals_final.append(viseme_interval)\n",
    "        pure_phoneme_list_final.append(pure_phoneme_list[i])\n",
    "        if viseme_list[i_next] in jali_sets.lip_rounder:\n",
    "            viseme_list_final.append(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i_next]])\n",
    "            viseme_intervals_final.append(viseme_interval)\n",
    "        increment = 2\n",
    "    elif viseme_list[i] in jali_sets.lip_heavy:\n",
    "        # if the viseme is a lip-heavy viseme, the it is voice simutaneously as nearby labial dental and bilabials \n",
    "        current_interval = viseme_intervals[i] \n",
    "        if not get_kth_neighbour(viseme_list, i, -1) is None:\n",
    "            if current_interval[0][0] <= viseme_intervals[i-1][-1][0] - lyric.dt and viseme_intervals[i-1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[0][0] = viseme_intervals[i-1][0][0]\n",
    "                current_interval[1][0] = viseme_intervals[i-1][1][0]\n",
    "        if not get_kth_neighbour(viseme_list, i, +1) is None:\n",
    "            if current_interval[-1][0] <= viseme_intervals[i+1][0][0] - lyric.dt and viseme_intervals[i+1][-1][0] in jali_sets.lip_rounder:\n",
    "                current_interval[2][0] = viseme_intervals[i+1][0][0]\n",
    "                current_interval[3][0] = viseme_intervals[i+1][1][0]\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(current_interval)\n",
    "        if viseme_list[i] in jali_sets.lip_rounder:\n",
    "            viseme_list_final.append(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i]])\n",
    "            viseme_intervals_final.append(current_interval)\n",
    "        pure_phoneme_list_final.append(pure_phoneme_list[i])\n",
    "    else:\n",
    "        viseme_list_final.append(viseme_list[i])\n",
    "        viseme_intervals_final.append(viseme_intervals[i])\n",
    "        if viseme_list[i] in jali_sets.lip_rounder:\n",
    "            viseme_list_final.append(jali_sets.lip_rounder_no_jaw_dict[viseme_list[i]])\n",
    "            viseme_intervals_final.append(viseme_intervals[i])\n",
    "        pure_phoneme_list_final.append(pure_phoneme_list[i])\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oo_pointer [[5.101602145940463, 0], [5.261602145940463, 7], [5.490480495471058, 5.25], [5.726773278647922, 0]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(viseme_list_final)):\n",
    "    if viseme_list_final[i] == \">\":\n",
    "        continue\n",
    "    if viseme_list_final[i] == \"Oo_pointer\":\n",
    "        print(viseme_list_final[i], viseme_intervals_final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(viseme_list_final)-1):\n",
    "    # re-order all the clips so that \n",
    "    if pure_phoneme_list_final[i] in cmu_sets.vowels:\n",
    "        next_vowel = -1\n",
    "        for si in range(i+1, len(viseme_list_final)):\n",
    "            if pure_phoneme_list_final[si] in cmu_sets.vowels:\n",
    "                next_vowel = si\n",
    "                break\n",
    "        if next_vowel > -1:\n",
    "            interval_i = viseme_intervals_final[i]\n",
    "            interval_i.sort(key=lambda x:x[0])\n",
    "            interval_next = viseme_intervals_final[next_vowel]\n",
    "            interval_next.sort(key=lambda x:x[0])\n",
    "            if interval_i[-1][0] <= interval_next[0][0]:\n",
    "                # there is no overlap \n",
    "                interval_i[-1][1] = interval_i[-2][1]/2\n",
    "                interval_i.append([interval_next[0][0], interval_i[-1][1] * 0.75])\n",
    "                interval_i.append([interval_next[1][0], 0])\n",
    "                viseme_intervals_final[i] = interval_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 3\n",
    "# set this up\n",
    "prev_slider_dict = {}\n",
    "for i in range(0, len(list(jali_sets.vocabs))):\n",
    "    prev_slider_dict[list(jali_sets.vocabs)[i]] = -1\n",
    "viseme_list_final_final = []\n",
    "viseme_intervals_final_final = []\n",
    "i = 0  \n",
    "while i < len(viseme_list_final):\n",
    "    increment = 1\n",
    "    prev_viseme = viseme_list_final[i]\n",
    "    # if the previous instance of the current viseme is not -1\n",
    "    if prev_slider_dict[viseme_list_final[i]] != -1:\n",
    "        current_interval = viseme_intervals_final[i]\n",
    "        prev_interval = viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]]\n",
    "        if (current_interval[1][0] >= prev_interval[2][0] and current_interval[0][0] <= prev_interval[3][0]):\n",
    "            interval = prev_interval[:-1] + current_interval[1:]\n",
    "            viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        elif (current_interval[1][0] <= prev_interval[2][0]):\n",
    "            interval = prev_interval[0:-2] + current_interval[1:]\n",
    "            viseme_intervals_final_final[prev_slider_dict[viseme_list_final[i]]] = interval\n",
    "        else:\n",
    "            viseme_list_final_final.append(viseme_list_final[i])\n",
    "            viseme_intervals_final_final.append(viseme_intervals_final[i])\n",
    "                \n",
    "    else:        \n",
    "        viseme_list_final_final.append(viseme_list_final[i])\n",
    "        viseme_intervals_final_final.append(viseme_intervals_final[i])\n",
    "        \n",
    "    prev_slider_dict[viseme_list_final[i]] = len(viseme_list_final_final) - 1\n",
    "    i = i + increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric.compute_self_vibrato_intervals()\n",
    "vib_ctrl_pts = []\n",
    "# for k in lyric.vibrato_intervals:\n",
    "#     if len(k) > 0:\n",
    "#         for m in k:\n",
    "#             vib_ctrl_pts.append(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vowel modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel2Cardinal5 = {\"Ah_pointer\":0, \"Aa_pointer\":1, \"Eh_pointer\":1, \"Ee_pointer\":2, \n",
    "                 \"Ih_pointer\":2, \"Oo_pointer\":3, \"Oh_pointer\":3, \"Uh_pointer\":0, \n",
    "                  \"U_pointer\":4, \"Eu_pointer\":4}\n",
    "vowel2Cardinal3 = {\"Ah_pointer\":0, \"Aa_pointer\":1, \"Eh_pointer\":1, \"Ee_pointer\":1, \n",
    "                 \"Ih_pointer\":1, \"Oo_pointer\":2, \"Oh_pointer\":2, \"Uh_pointer\":0, \n",
    "                  \"U_pointer\":2, \"Eu_pointer\":2}\n",
    "\n",
    "control_direction_matrix_coarse = {0:{1:[\"Dimple\", \"Dimple\", [0, 7]], 2:[\"Pucker\", \"Pucker\", [0, 4]]},\n",
    "                                  1:{0:[\"Pucker\", \"Pucker\", [0, 3]], 2:[\"Pucker\", \"Pucker\", [0, 4]]},\n",
    "                                  2:{0:[\"self\", \"Lip Pucker\", [0, -3]], 1:[\"self\", \"Lip Pucker\", [0, -6],\n",
    "                                                                          \"Dimple\", \"Dimple\", [0, 7]]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0] [[0, 50]]\n",
      "[0] [[0, 50]]\n",
      "[0, 3]\n",
      "0\n",
      "[0, 1, 0, 1, 0, 3] [[0, 59], [60, 202], [203, 223], [224, 244], [245, 304], [305, 356]]\n",
      "[1, 0, 3] [[60, 244], [245, 304], [305, 356]]\n",
      "[0, 7]\n",
      "1\n",
      "[0] [[0, 58]]\n",
      "[0] [[0, 58]]\n",
      "[0, 3]\n",
      "1\n",
      "[0] [[0, 341]]\n",
      "[0] [[0, 341]]\n",
      "[0, 3]\n",
      "0\n",
      "[0] [[0, 68]]\n",
      "[0] [[0, 68]]\n",
      "0\n",
      "[0, 1] [[0, 20], [21, 167]]\n",
      "[0, 1] [[0, 20], [21, 167]]\n",
      "[0, 7]\n",
      "1\n",
      "[0] [[0, 173]]\n",
      "[0] [[0, 173]]\n",
      "[0, 3]\n",
      "1\n",
      "[0] [[0, 68]]\n",
      "[0] [[0, 68]]\n",
      "[0, 3]\n",
      "1\n",
      "[0] [[0, 111]]\n",
      "[0] [[0, 111]]\n",
      "[0, 3]\n",
      "1\n",
      "[0] [[0, 161]]\n",
      "[0] [[0, 161]]\n",
      "[0, 3]\n"
     ]
    }
   ],
   "source": [
    "viseme_list, viseme_interval = [viseme_list_final_final, viseme_intervals_final_final]\n",
    "\n",
    "modification_ctrl_pts = []\n",
    "modification_sliders = []\n",
    "# iterate through the vowels in the list\n",
    "dt = 0.01\n",
    "for i in range(0, len(viseme_list)):\n",
    "    if viseme_list[i] in VOWELS_SLIDERS_JALI and viseme_interval[i][-2][0] - viseme_interval[i][1][0] > 0.25:\n",
    "        ##################################################################\n",
    "        ###################### get the audio signal ######################\n",
    "        ##################################################################\n",
    "        vowel_mod_out, vowel_mod_out_coarse = vowel_mod(lyric.sound_arr_interp(np.arange(viseme_interval[i][1][0], \n",
    "                                                                                        min(viseme_interval[i][-1][0], lyric.snd.xs()[-1]), 1.0/44100.0)))\n",
    "#         print([\"A\", \"Stretcher\", \"Rounder\", \"Silence\"][vowel2Cardinal3[viseme_list[i]]])\n",
    "        xs = np.linspace(viseme_interval[i][1][0], min(viseme_interval[i][-1][0], lyric.snd.xs()[-1]), vowel_mod_out_coarse.shape[0])\n",
    "        coarse_vowel_sounds_like_interp = interp1d(xs, vowel_mod_out_coarse, axis=0)\n",
    "\n",
    "        # what the original sound was\n",
    "        original_vowel_shape = vowel2Cardinal3[viseme_list[i]]\n",
    "        only_peaks = np.where(vowel_mod_out_coarse > 0.7, vowel_mod_out_coarse, original_vowel_shape)\n",
    "        vowel_sounds_like = np.argmax(only_peaks, axis=1)\n",
    "        ##################################################################\n",
    "        ### obtain the intervals of which cardinal vowels are dominant ###\n",
    "        ##################################################################\n",
    "        cardinal_list = []\n",
    "        cardinal_intervals = []\n",
    "        current_interval_start = 0\n",
    "        current_vowel = original_vowel_shape\n",
    "        for t in range(0, vowel_sounds_like.shape[0]):\n",
    "            if vowel_sounds_like[t] == current_vowel:\n",
    "                if (t == vowel_sounds_like.shape[0]-1):\n",
    "                    cardinal_list.append(current_vowel)\n",
    "                    cardinal_intervals.append([current_interval_start, t])\n",
    "            else:\n",
    "                if xs[t-1] - xs[current_interval_start] >= 0.2:\n",
    "                    if t > 0:\n",
    "                        cardinal_list.append(current_vowel)\n",
    "                        cardinal_intervals.append([current_interval_start, t-1])\n",
    "                    current_interval_start = t\n",
    "                    current_vowel = vowel_sounds_like[t]\n",
    "        ###########################################################################\n",
    "        ######### optionally additional smoothing are added to this here ##########      \n",
    "        ###########################################################################\n",
    "        cardinal_list_new = []\n",
    "        cardinal_intervals_new = []\n",
    "        j = 0\n",
    "        while j < len(cardinal_list):\n",
    "            step = 1\n",
    "            if j == len(cardinal_list) - 1:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append(cardinal_intervals[j])\n",
    "            elif cardinal_list[j] == cardinal_list[j+1] and xs[cardinal_intervals[j+1][0]] - xs[cardinal_intervals[j][1]] <= spike_width:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append([cardinal_intervals[j][0], cardinal_intervals[j+1][1]])\n",
    "                step = 2\n",
    "            elif j < len(cardinal_list) - 2:\n",
    "                if (cardinal_list[j] == cardinal_list[j+2] and xs[cardinal_intervals[j+2][0]] - xs[cardinal_intervals[j][1]] <= spike_width \n",
    "                    and cardinal_list[j+1] == original_vowel_shape):\n",
    "                    cardinal_list_new.append(cardinal_list[j])\n",
    "                    cardinal_intervals_new.append([cardinal_intervals[j][0], cardinal_intervals[j+2][1]])\n",
    "                    step = 3\n",
    "            else:\n",
    "                cardinal_list_new.append(cardinal_list[j])\n",
    "                cardinal_intervals_new.append(cardinal_intervals[j])\n",
    "            j = j + step\n",
    "        cardinal_list = cardinal_list_new\n",
    "        cardinal_intervals = cardinal_intervals_new\n",
    "\n",
    "        # now set pucker/stretch values based on the detected sound\n",
    "        for c in range(0, len(cardinal_list)):\n",
    "            if original_vowel_shape == cardinal_list[c] or cardinal_list[c] == 3:\n",
    "                continue\n",
    "            else:\n",
    "                max_prob = coarse_vowel_sounds_like_interp(xs[cardinal_intervals[c][0]:cardinal_intervals[c][1]+1])[:, cardinal_list[c]].max()\n",
    "                slider_ct_pts = control_direction_matrix_coarse[original_vowel_shape][cardinal_list[c]]\n",
    "                for s in range(0, int(len(slider_ct_pts)/3)):\n",
    "                    # get the name and attribute of the slider\n",
    "                    slider_name = slider_ct_pts[0 + 3*s]\n",
    "                    if slider_name == \"self\":\n",
    "                        slider_name = viseme_list[i]\n",
    "                    slider_attribute = slider_ct_pts[1 + 3*s]\n",
    "                    \n",
    "                    # add a starting keyframe and ending keyframe\n",
    "                    modification_sliders.append([slider_name, slider_attribute])\n",
    "                    # the start of this curve should be earlier, e.g. at 75% of the previous interval\n",
    "                    # however, if the detected modification is at the very beginning of the vowel, then it is\n",
    "                    # applied the same time as the beginning of the vowel\n",
    "                    if c == 0: \n",
    "#                         start_candidate = xs[cardinal_intervals[c][0]]-0.14\n",
    "#                         start = max(start_candidate, viseme_interval[i][0][0])\n",
    "                        start = viseme_interval[i][0][0]\n",
    "                    else:\n",
    "                        start_candidate = (xs[cardinal_intervals[c-1][1]] - xs[cardinal_intervals[c-1][0]]) * 0.6 + xs[cardinal_intervals[c-1][0]]\n",
    "                        start_candidate = min(start_candidate, xs[cardinal_intervals[c-1][1]]-0.12)\n",
    "                        start = max(start_candidate, xs[cardinal_intervals[c-1][0]])\n",
    "                        if np.abs(start - viseme_interval[i][1][0]) <= 0.2:\n",
    "                            start = viseme_interval[i][0][0]\n",
    "                    modification_ctrl_pts.append([start, 0])\n",
    "                    # add the end point of the curve. This would either at the end of the \n",
    "                    # prediction interval, or at the end of the vowel. \n",
    "                    modification_sliders.append([slider_name, slider_attribute])\n",
    "                    if c == len(cardinal_list) - 1:\n",
    "                        modification_ctrl_pts.append([xs[cardinal_intervals[c][1]], 0])\n",
    "                    else:\n",
    "                        modification_ctrl_pts.append([viseme_interval[i][-1][0], 0])        \n",
    "                    # add the peaks in the middle with the decay\n",
    "                    slider_range = slider_ct_pts[2 + 3*s]\n",
    "                    modification_sliders.append([slider_name, slider_attribute])\n",
    "                    print(slider_range)\n",
    "                    # with some anticipation \n",
    "                    modification_ctrl_pts.append([xs[cardinal_intervals[c][0]]-0.13, max_prob * (slider_range[1])])\n",
    "                    modification_sliders.append([slider_name, slider_attribute])\n",
    "                    end_p75 = (xs[cardinal_intervals[c][1]] - xs[cardinal_intervals[c][0]]) * 0.75 + xs[cardinal_intervals[c][0]]\n",
    "                    modification_ctrl_pts.append([end_p75, max_prob * (slider_range[1]) * 0.75])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output ={\"viseme\":[viseme_list_final_final, viseme_intervals_final_final],\n",
    "#         \"brow\":[brow_movement, brow_ctrl_points, finer_brow_raise_ctrl_points, finer_brow_furrow_ctrl_points],\n",
    "#         \"blink\":[eye_movement, eye_ctrl_points],\n",
    "        \"vowel_mod\": [modification_sliders, modification_ctrl_pts],\n",
    "        \"jaw\":[[0, 6]],\n",
    "        \"lip\":[[0, 6]], \n",
    "        \"vib\":vib_ctrl_pts}\n",
    "jsonoutput = json.dumps(output)\n",
    "with open(os.path.join(dir, file_name_template + \"_\" + output_template + '.json'), 'w') as outfile:\n",
    "    json.dump(jsonoutput, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visemenet",
   "language": "python",
   "name": "visemenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
